rust_fuzzer_test_input:
  209|  17.7k|            pub extern "C" fn rust_fuzzer_test_input(bytes: &[u8]) -> i32 {
  210|       |                // When `RUST_LIBFUZZER_DEBUG_PATH` is set, write the debug
  211|       |                // formatting of the input to that file. This is only intended for
  212|       |                // `cargo fuzz`'s use!
  213|       |
  214|       |                // `RUST_LIBFUZZER_DEBUG_PATH` is set in initialization.
  215|  17.7k|                if let Some(path) = $crate::RUST_LIBFUZZER_DEBUG_PATH.get() {
  216|       |                    use std::io::Write;
  217|      0|                    let mut file = std::fs::File::create(path)
  218|      0|                        .expect("failed to create `RUST_LIBFUZZER_DEBUG_PATH` file");
  219|      0|                    writeln!(&mut file, "{:?}", bytes)
  220|      0|                        .expect("failed to write to `RUST_LIBFUZZER_DEBUG_PATH` file");
  221|      0|                    return 0;
  222|  17.7k|                }
  223|  17.7k|
  224|  17.7k|                __libfuzzer_sys_run(bytes);
  225|  17.7k|                0
  226|       |            }
_RNvNvCs7FJOgx1BmQJ_18sparql_results_xml1__19___libfuzzer_sys_run:
  241|  17.7k|            fn __libfuzzer_sys_run($bytes: &[u8]) {
  242|  17.7k|                $body
  243|  17.7k|            }
LLVMFuzzerTestOneInput:
   58|  17.7k|pub fn test_input_wrap(data: *const u8, size: usize) -> i32 {
   59|  17.7k|    let test_input = ::std::panic::catch_unwind(|| unsafe {
   60|       |        let data_slice = ::std::slice::from_raw_parts(data, size);
   61|       |        rust_fuzzer_test_input(data_slice)
   62|  17.7k|    });
   63|  17.7k|
   64|  17.7k|    match test_input {
   65|  17.7k|        Ok(i) => i,
   66|       |        Err(_) => {
   67|       |            // hopefully the custom panic hook will be called before and abort the
   68|       |            // process before the stack frames are unwinded.
   69|      0|            ::std::process::abort();
   70|       |        }
   71|       |    }
   72|  17.7k|}
_RNCNvCsiqeAZnF9yJF_13libfuzzer_sys15test_input_wrap0B3_:
   59|  17.7k|    let test_input = ::std::panic::catch_unwind(|| unsafe {
   60|  17.7k|        let data_slice = ::std::slice::from_raw_parts(data, size);
   61|  17.7k|        rust_fuzzer_test_input(data_slice)
   62|  17.7k|    });
LLVMFuzzerInitialize:
   79|      2|pub fn initialize(_argc: *const isize, _argv: *const *const *const u8) -> isize {
   80|      2|    // Registers a panic hook that aborts the process before unwinding.
   81|      2|    // It is useful to abort before unwinding so that the fuzzer will then be
   82|      2|    // able to analyse the process stack frames to tell different bugs appart.
   83|      2|    //
   84|      2|    // HACK / FIXME: it would be better to use `-C panic=abort` but it's currently
   85|      2|    // impossible to build code using compiler plugins with this flag.
   86|      2|    // We will be able to remove this code when
   87|      2|    // https://github.com/rust-lang/cargo/issues/5423 is fixed.
   88|      2|    let default_hook = ::std::panic::take_hook();
   89|      2|    ::std::panic::set_hook(Box::new(move |panic_info| {
   90|       |        default_hook(panic_info);
   91|       |        ::std::process::abort();
   92|      2|    }));
   93|       |
   94|       |    // Initialize the `RUST_LIBFUZZER_DEBUG_PATH` cell with the path so it can be
   95|       |    // reused with little overhead.
   96|      2|    if let Ok(path) = std::env::var("RUST_LIBFUZZER_DEBUG_PATH") {
   97|      0|        RUST_LIBFUZZER_DEBUG_PATH
   98|      0|            .set(path)
   99|      0|            .expect("Since this is initialize it is only called once so can never fail");
  100|      2|    }
  101|      2|    0
  102|      2|}

_RINvMs3_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrNtB6_4Iter4nextNCNvXs3_NtBc_6memchrNtB1e_7Memchr2NtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4next0ECskRNNzwwh1bl_10sparesults:
 1044|  91.0k|    pub(crate) unsafe fn next(
 1045|  91.0k|        &mut self,
 1046|  91.0k|        mut find_raw: impl FnMut(*const u8, *const u8) -> Option<*const u8>,
 1047|  91.0k|    ) -> Option<usize> {
 1048|       |        // SAFETY: Pointers are derived directly from the same &[u8] haystack.
 1049|       |        // We only ever modify start/end corresponding to a matching offset
 1050|       |        // found between start and end. Thus all changes to start/end maintain
 1051|       |        // our safety requirements.
 1052|       |        //
 1053|       |        // The only other assumption we rely on is that the pointer returned
 1054|       |        // by `find_raw` satisfies `self.start <= found < self.end`, and that
 1055|       |        // safety contract is forwarded to the caller.
 1056|  91.0k|        let found = find_raw(self.start, self.end)?;
 1057|  90.1k|        let result = found.distance(self.original_start);
 1058|  90.1k|        self.start = found.add(1);
 1059|  90.1k|        Some(result)
 1060|  91.0k|    }
_RINvMs3_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrNtB6_4Iter4nextNCNvXs7_NtBc_6memchrNtB1e_7Memchr3NtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4next0ECskRNNzwwh1bl_10sparesults:
 1044|  8.71k|    pub(crate) unsafe fn next(
 1045|  8.71k|        &mut self,
 1046|  8.71k|        mut find_raw: impl FnMut(*const u8, *const u8) -> Option<*const u8>,
 1047|  8.71k|    ) -> Option<usize> {
 1048|       |        // SAFETY: Pointers are derived directly from the same &[u8] haystack.
 1049|       |        // We only ever modify start/end corresponding to a matching offset
 1050|       |        // found between start and end. Thus all changes to start/end maintain
 1051|       |        // our safety requirements.
 1052|       |        //
 1053|       |        // The only other assumption we rely on is that the pointer returned
 1054|       |        // by `find_raw` satisfies `self.start <= found < self.end`, and that
 1055|       |        // safety contract is forwarded to the caller.
 1056|  8.71k|        let found = find_raw(self.start, self.end)?;
 1057|  7.52k|        let result = found.distance(self.original_start);
 1058|  7.52k|        self.start = found.add(1);
 1059|  7.52k|        Some(result)
 1060|  8.71k|    }
_RINvMs3_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrNtB6_4Iter4nextNCNvXs_NtBc_6memchrNtB1d_6MemchrNtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4next0ECskRNNzwwh1bl_10sparesults:
 1044|  1.19M|    pub(crate) unsafe fn next(
 1045|  1.19M|        &mut self,
 1046|  1.19M|        mut find_raw: impl FnMut(*const u8, *const u8) -> Option<*const u8>,
 1047|  1.19M|    ) -> Option<usize> {
 1048|       |        // SAFETY: Pointers are derived directly from the same &[u8] haystack.
 1049|       |        // We only ever modify start/end corresponding to a matching offset
 1050|       |        // found between start and end. Thus all changes to start/end maintain
 1051|       |        // our safety requirements.
 1052|       |        //
 1053|       |        // The only other assumption we rely on is that the pointer returned
 1054|       |        // by `find_raw` satisfies `self.start <= found < self.end`, and that
 1055|       |        // safety contract is forwarded to the caller.
 1056|  1.19M|        let found = find_raw(self.start, self.end)?;
 1057|  1.19M|        let result = found.distance(self.original_start);
 1058|  1.19M|        self.start = found.add(1);
 1059|  1.19M|        Some(result)
 1060|  1.19M|    }
_RINvNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchr21search_slice_with_rawNCNvNtB8_6memchr6memchr0ECskRNNzwwh1bl_10sparesults:
 1125|   676k|pub(crate) unsafe fn search_slice_with_raw(
 1126|   676k|    haystack: &[u8],
 1127|   676k|    mut find_raw: impl FnMut(*const u8, *const u8) -> Option<*const u8>,
 1128|   676k|) -> Option<usize> {
 1129|   676k|    // SAFETY: We rely on `find_raw` to return a correct and valid pointer, but
 1130|   676k|    // otherwise, `start` and `end` are valid due to the guarantees provided by
 1131|   676k|    // a &[u8].
 1132|   676k|    let start = haystack.as_ptr();
 1133|   676k|    let end = start.add(haystack.len());
 1134|   676k|    let found = find_raw(start, end)?;
 1135|   672k|    Some(found.distance(start))
 1136|   676k|}
_RNvMs3_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrNtB5_4Iter3new:
 1027|   674k|    pub(crate) fn new(haystack: &'h [u8]) -> Iter<'h> {
 1028|   674k|        Iter {
 1029|   674k|            original_start: haystack.as_ptr(),
 1030|   674k|            start: haystack.as_ptr(),
 1031|   674k|            end: haystack.as_ptr().wrapping_add(haystack.len()),
 1032|   674k|            haystack: core::marker::PhantomData,
 1033|   674k|        }
 1034|   674k|    }
_RINvMs3_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrNtB6_4Iter4nextNCNvXs3_NtBc_6memchrNtB1e_7Memchr2NtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4next0ECsa7QYSr9aLYT_9quick_xml:
 1044|   180k|    pub(crate) unsafe fn next(
 1045|   180k|        &mut self,
 1046|   180k|        mut find_raw: impl FnMut(*const u8, *const u8) -> Option<*const u8>,
 1047|   180k|    ) -> Option<usize> {
 1048|       |        // SAFETY: Pointers are derived directly from the same &[u8] haystack.
 1049|       |        // We only ever modify start/end corresponding to a matching offset
 1050|       |        // found between start and end. Thus all changes to start/end maintain
 1051|       |        // our safety requirements.
 1052|       |        //
 1053|       |        // The only other assumption we rely on is that the pointer returned
 1054|       |        // by `find_raw` satisfies `self.start <= found < self.end`, and that
 1055|       |        // safety contract is forwarded to the caller.
 1056|   180k|        let found = find_raw(self.start, self.end)?;
 1057|   177k|        let result = found.distance(self.original_start);
 1058|   177k|        self.start = found.add(1);
 1059|   177k|        Some(result)
 1060|   180k|    }
_RNvMNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE7needle1B8_:
  117|   119k|    pub(crate) fn needle1(&self) -> u8 {
  118|   119k|        self.s1
  119|   119k|    }
_RNvMNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE3newB8_:
  111|  1.87M|    pub(crate) unsafe fn new(needle: u8) -> One<V> {
  112|  1.87M|        One { s1: needle, v1: V::splat(needle) }
  113|  1.87M|    }
_RNvMNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE8find_rawB8_:
  143|  40.2k|    pub(crate) unsafe fn find_raw(
  144|  40.2k|        &self,
  145|  40.2k|        start: *const u8,
  146|  40.2k|        end: *const u8,
  147|  40.2k|    ) -> Option<*const u8> {
  148|  40.2k|        // If we want to support vectors bigger than 256 bits, we probably
  149|  40.2k|        // need to move up to using a u64 for the masks used below. Currently
  150|  40.2k|        // they are 32 bits, which means we're SOL for vectors that need masks
  151|  40.2k|        // bigger than 32 bits. Overall unclear until there's a use case.
  152|  40.2k|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  153|       |
  154|  40.2k|        let topos = V::Mask::first_offset;
  155|  40.2k|        let len = end.distance(start);
  156|  40.2k|        debug_assert!(
  157|      0|            len >= V::BYTES,
  158|      0|            "haystack has length {}, but must be at least {}",
  159|       |            len,
  160|       |            V::BYTES
  161|       |        );
  162|       |
  163|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  164|       |        // of the haystack prior to where aligned loads can start.
  165|  40.2k|        if let Some(cur) = self.search_chunk(start, topos) {
  166|  38.2k|            return Some(cur);
  167|  1.94k|        }
  168|  1.94k|        // Set `cur` to the first V-aligned pointer greater than `start`.
  169|  1.94k|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  170|  1.94k|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  171|  1.94k|        if len >= Self::LOOP_SIZE {
  172|      0|            while cur <= end.sub(Self::LOOP_SIZE) {
  173|      0|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  174|       |
  175|      0|                let a = V::load_aligned(cur);
  176|      0|                let b = V::load_aligned(cur.add(1 * V::BYTES));
  177|      0|                let c = V::load_aligned(cur.add(2 * V::BYTES));
  178|      0|                let d = V::load_aligned(cur.add(3 * V::BYTES));
  179|      0|                let eqa = self.v1.cmpeq(a);
  180|      0|                let eqb = self.v1.cmpeq(b);
  181|      0|                let eqc = self.v1.cmpeq(c);
  182|      0|                let eqd = self.v1.cmpeq(d);
  183|      0|                let or1 = eqa.or(eqb);
  184|      0|                let or2 = eqc.or(eqd);
  185|      0|                let or3 = or1.or(or2);
  186|      0|                if or3.movemask_will_have_non_zero() {
  187|      0|                    let mask = eqa.movemask();
  188|      0|                    if mask.has_non_zero() {
  189|      0|                        return Some(cur.add(topos(mask)));
  190|      0|                    }
  191|      0|
  192|      0|                    let mask = eqb.movemask();
  193|      0|                    if mask.has_non_zero() {
  194|      0|                        return Some(cur.add(1 * V::BYTES).add(topos(mask)));
  195|      0|                    }
  196|      0|
  197|      0|                    let mask = eqc.movemask();
  198|      0|                    if mask.has_non_zero() {
  199|      0|                        return Some(cur.add(2 * V::BYTES).add(topos(mask)));
  200|      0|                    }
  201|      0|
  202|      0|                    let mask = eqd.movemask();
  203|      0|                    debug_assert!(mask.has_non_zero());
  204|      0|                    return Some(cur.add(3 * V::BYTES).add(topos(mask)));
  205|      0|                }
  206|      0|                cur = cur.add(Self::LOOP_SIZE);
  207|       |            }
  208|  1.94k|        }
  209|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  210|       |        // loads here, but I believe we are guaranteed that they are aligned
  211|       |        // since `cur` is aligned.
  212|  2.36k|        while cur <= end.sub(V::BYTES) {
  213|    897|            debug_assert!(end.distance(cur) >= V::BYTES);
  214|    897|            if let Some(cur) = self.search_chunk(cur, topos) {
  215|    480|                return Some(cur);
  216|    417|            }
  217|    417|            cur = cur.add(V::BYTES);
  218|       |        }
  219|       |        // Finally handle any remaining bytes less than the size of V. In this
  220|       |        // case, our pointer may indeed be unaligned and the load may overlap
  221|       |        // with the previous one. But that's okay since we know the previous
  222|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  223|  1.46k|        if cur < end {
  224|  1.38k|            debug_assert!(end.distance(cur) < V::BYTES);
  225|  1.38k|            cur = cur.sub(V::BYTES - end.distance(cur));
  226|  1.38k|            debug_assert_eq!(end.distance(cur), V::BYTES);
  227|  1.38k|            return self.search_chunk(cur, topos);
  228|     89|        }
  229|     89|        None
  230|  40.2k|    }
_RINvMNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB3_3OneNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE12search_chunkNvYNtNtB9_6vector16SensibleMoveMaskNtB24_8MoveMask12first_offsetEB9_:
  416|  42.5k|    unsafe fn search_chunk(
  417|  42.5k|        &self,
  418|  42.5k|        cur: *const u8,
  419|  42.5k|        mask_to_offset: impl Fn(V::Mask) -> usize,
  420|  42.5k|    ) -> Option<*const u8> {
  421|  42.5k|        let chunk = V::load_unaligned(cur);
  422|  42.5k|        let mask = self.v1.cmpeq(chunk).movemask();
  423|  42.5k|        if mask.has_non_zero() {
  424|  39.5k|            Some(cur.add(mask_to_offset(mask)))
  425|       |        } else {
  426|  2.90k|            None
  427|       |        }
  428|  42.5k|    }
_RNvMs_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE3newBa_:
  450|   271k|    pub(crate) unsafe fn new(needle1: u8, needle2: u8) -> Two<V> {
  451|   271k|        Two {
  452|   271k|            s1: needle1,
  453|   271k|            s2: needle2,
  454|   271k|            v1: V::splat(needle1),
  455|   271k|            v2: V::splat(needle2),
  456|   271k|        }
  457|   271k|    }
_RNvMs_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE7needle1Ba_:
  461|  41.9k|    pub(crate) fn needle1(&self) -> u8 {
  462|  41.9k|        self.s1
  463|  41.9k|    }
_RNvMs_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE7needle2Ba_:
  467|  37.1k|    pub(crate) fn needle2(&self) -> u8 {
  468|  37.1k|        self.s2
  469|  37.1k|    }
_RNvMs_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE8find_rawBa_:
  493|  11.5k|    pub(crate) unsafe fn find_raw(
  494|  11.5k|        &self,
  495|  11.5k|        start: *const u8,
  496|  11.5k|        end: *const u8,
  497|  11.5k|    ) -> Option<*const u8> {
  498|  11.5k|        // If we want to support vectors bigger than 256 bits, we probably
  499|  11.5k|        // need to move up to using a u64 for the masks used below. Currently
  500|  11.5k|        // they are 32 bits, which means we're SOL for vectors that need masks
  501|  11.5k|        // bigger than 32 bits. Overall unclear until there's a use case.
  502|  11.5k|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  503|       |
  504|  11.5k|        let topos = V::Mask::first_offset;
  505|  11.5k|        let len = end.distance(start);
  506|  11.5k|        debug_assert!(
  507|      0|            len >= V::BYTES,
  508|      0|            "haystack has length {}, but must be at least {}",
  509|       |            len,
  510|       |            V::BYTES
  511|       |        );
  512|       |
  513|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  514|       |        // of the haystack prior to where aligned loads can start.
  515|  11.5k|        if let Some(cur) = self.search_chunk(start, topos) {
  516|  11.2k|            return Some(cur);
  517|    267|        }
  518|    267|        // Set `cur` to the first V-aligned pointer greater than `start`.
  519|    267|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  520|    267|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  521|    267|        if len >= Self::LOOP_SIZE {
  522|      0|            while cur <= end.sub(Self::LOOP_SIZE) {
  523|      0|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  524|       |
  525|      0|                let a = V::load_aligned(cur);
  526|      0|                let b = V::load_aligned(cur.add(V::BYTES));
  527|      0|                let eqa1 = self.v1.cmpeq(a);
  528|      0|                let eqb1 = self.v1.cmpeq(b);
  529|      0|                let eqa2 = self.v2.cmpeq(a);
  530|      0|                let eqb2 = self.v2.cmpeq(b);
  531|      0|                let or1 = eqa1.or(eqb1);
  532|      0|                let or2 = eqa2.or(eqb2);
  533|      0|                let or3 = or1.or(or2);
  534|      0|                if or3.movemask_will_have_non_zero() {
  535|      0|                    let mask = eqa1.movemask().or(eqa2.movemask());
  536|      0|                    if mask.has_non_zero() {
  537|      0|                        return Some(cur.add(topos(mask)));
  538|      0|                    }
  539|      0|
  540|      0|                    let mask = eqb1.movemask().or(eqb2.movemask());
  541|      0|                    debug_assert!(mask.has_non_zero());
  542|      0|                    return Some(cur.add(V::BYTES).add(topos(mask)));
  543|      0|                }
  544|      0|                cur = cur.add(Self::LOOP_SIZE);
  545|       |            }
  546|    267|        }
  547|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  548|       |        // loads here, but I believe we are guaranteed that they are aligned
  549|       |        // since `cur` is aligned.
  550|    334|        while cur <= end.sub(V::BYTES) {
  551|    196|            debug_assert!(end.distance(cur) >= V::BYTES);
  552|    196|            if let Some(cur) = self.search_chunk(cur, topos) {
  553|    129|                return Some(cur);
  554|     67|            }
  555|     67|            cur = cur.add(V::BYTES);
  556|       |        }
  557|       |        // Finally handle any remaining bytes less than the size of V. In this
  558|       |        // case, our pointer may indeed be unaligned and the load may overlap
  559|       |        // with the previous one. But that's okay since we know the previous
  560|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  561|    138|        if cur < end {
  562|    130|            debug_assert!(end.distance(cur) < V::BYTES);
  563|    130|            cur = cur.sub(V::BYTES - end.distance(cur));
  564|    130|            debug_assert_eq!(end.distance(cur), V::BYTES);
  565|    130|            return self.search_chunk(cur, topos);
  566|      8|        }
  567|      8|        None
  568|  11.5k|    }
_RINvMs_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB5_3TwoNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE12search_chunkNvYNtNtBb_6vector16SensibleMoveMaskNtB26_8MoveMask12first_offsetEBb_:
  670|  11.8k|    unsafe fn search_chunk(
  671|  11.8k|        &self,
  672|  11.8k|        cur: *const u8,
  673|  11.8k|        mask_to_offset: impl Fn(V::Mask) -> usize,
  674|  11.8k|    ) -> Option<*const u8> {
  675|  11.8k|        let chunk = V::load_unaligned(cur);
  676|  11.8k|        let eq1 = self.v1.cmpeq(chunk);
  677|  11.8k|        let eq2 = self.v2.cmpeq(chunk);
  678|  11.8k|        let mask = eq1.or(eq2).movemask();
  679|  11.8k|        if mask.has_non_zero() {
  680|  11.5k|            let mask1 = eq1.movemask();
  681|  11.5k|            let mask2 = eq2.movemask();
  682|  11.5k|            Some(cur.add(mask_to_offset(mask1.or(mask2))))
  683|       |        } else {
  684|    350|            None
  685|       |        }
  686|  11.8k|    }
_RNvMs0_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE3newBb_:
  710|  8.71k|    pub(crate) unsafe fn new(
  711|  8.71k|        needle1: u8,
  712|  8.71k|        needle2: u8,
  713|  8.71k|        needle3: u8,
  714|  8.71k|    ) -> Three<V> {
  715|  8.71k|        Three {
  716|  8.71k|            s1: needle1,
  717|  8.71k|            s2: needle2,
  718|  8.71k|            s3: needle3,
  719|  8.71k|            v1: V::splat(needle1),
  720|  8.71k|            v2: V::splat(needle2),
  721|  8.71k|            v3: V::splat(needle3),
  722|  8.71k|        }
  723|  8.71k|    }
_RNvMs0_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE7needle1Bb_:
  727|  6.63k|    pub(crate) fn needle1(&self) -> u8 {
  728|  6.63k|        self.s1
  729|  6.63k|    }
_RNvMs0_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE7needle2Bb_:
  733|  6.09k|    pub(crate) fn needle2(&self) -> u8 {
  734|  6.09k|        self.s2
  735|  6.09k|    }
_RNvMs0_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE7needle3Bb_:
  739|  5.93k|    pub(crate) fn needle3(&self) -> u8 {
  740|  5.93k|        self.s3
  741|  5.93k|    }
_RNvMs0_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE8find_rawBb_:
  765|    716|    pub(crate) unsafe fn find_raw(
  766|    716|        &self,
  767|    716|        start: *const u8,
  768|    716|        end: *const u8,
  769|    716|    ) -> Option<*const u8> {
  770|    716|        // If we want to support vectors bigger than 256 bits, we probably
  771|    716|        // need to move up to using a u64 for the masks used below. Currently
  772|    716|        // they are 32 bits, which means we're SOL for vectors that need masks
  773|    716|        // bigger than 32 bits. Overall unclear until there's a use case.
  774|    716|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  775|       |
  776|    716|        let topos = V::Mask::first_offset;
  777|    716|        let len = end.distance(start);
  778|    716|        debug_assert!(
  779|      0|            len >= V::BYTES,
  780|      0|            "haystack has length {}, but must be at least {}",
  781|       |            len,
  782|       |            V::BYTES
  783|       |        );
  784|       |
  785|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  786|       |        // of the haystack prior to where aligned loads can start.
  787|    716|        if let Some(cur) = self.search_chunk(start, topos) {
  788|    526|            return Some(cur);
  789|    190|        }
  790|    190|        // Set `cur` to the first V-aligned pointer greater than `start`.
  791|    190|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  792|    190|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  793|    190|        if len >= Self::LOOP_SIZE {
  794|      0|            while cur <= end.sub(Self::LOOP_SIZE) {
  795|      0|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  796|       |
  797|      0|                let a = V::load_aligned(cur);
  798|      0|                let b = V::load_aligned(cur.add(V::BYTES));
  799|      0|                let eqa1 = self.v1.cmpeq(a);
  800|      0|                let eqb1 = self.v1.cmpeq(b);
  801|      0|                let eqa2 = self.v2.cmpeq(a);
  802|      0|                let eqb2 = self.v2.cmpeq(b);
  803|      0|                let eqa3 = self.v3.cmpeq(a);
  804|      0|                let eqb3 = self.v3.cmpeq(b);
  805|      0|                let or1 = eqa1.or(eqb1);
  806|      0|                let or2 = eqa2.or(eqb2);
  807|      0|                let or3 = eqa3.or(eqb3);
  808|      0|                let or4 = or1.or(or2);
  809|      0|                let or5 = or3.or(or4);
  810|      0|                if or5.movemask_will_have_non_zero() {
  811|      0|                    let mask = eqa1
  812|      0|                        .movemask()
  813|      0|                        .or(eqa2.movemask())
  814|      0|                        .or(eqa3.movemask());
  815|      0|                    if mask.has_non_zero() {
  816|      0|                        return Some(cur.add(topos(mask)));
  817|      0|                    }
  818|      0|
  819|      0|                    let mask = eqb1
  820|      0|                        .movemask()
  821|      0|                        .or(eqb2.movemask())
  822|      0|                        .or(eqb3.movemask());
  823|      0|                    debug_assert!(mask.has_non_zero());
  824|      0|                    return Some(cur.add(V::BYTES).add(topos(mask)));
  825|      0|                }
  826|      0|                cur = cur.add(Self::LOOP_SIZE);
  827|       |            }
  828|    190|        }
  829|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  830|       |        // loads here, but I believe we are guaranteed that they are aligned
  831|       |        // since `cur` is aligned.
  832|    251|        while cur <= end.sub(V::BYTES) {
  833|     69|            debug_assert!(end.distance(cur) >= V::BYTES);
  834|     69|            if let Some(cur) = self.search_chunk(cur, topos) {
  835|      8|                return Some(cur);
  836|     61|            }
  837|     61|            cur = cur.add(V::BYTES);
  838|       |        }
  839|       |        // Finally handle any remaining bytes less than the size of V. In this
  840|       |        // case, our pointer may indeed be unaligned and the load may overlap
  841|       |        // with the previous one. But that's okay since we know the previous
  842|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  843|    182|        if cur < end {
  844|    149|            debug_assert!(end.distance(cur) < V::BYTES);
  845|    149|            cur = cur.sub(V::BYTES - end.distance(cur));
  846|    149|            debug_assert_eq!(end.distance(cur), V::BYTES);
  847|    149|            return self.search_chunk(cur, topos);
  848|     33|        }
  849|     33|        None
  850|    716|    }
_RINvMs0_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB6_5ThreeNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iE12search_chunkNvYNtNtBc_6vector16SensibleMoveMaskNtB29_8MoveMask12first_offsetEBc_:
  962|    934|    unsafe fn search_chunk(
  963|    934|        &self,
  964|    934|        cur: *const u8,
  965|    934|        mask_to_offset: impl Fn(V::Mask) -> usize,
  966|    934|    ) -> Option<*const u8> {
  967|    934|        let chunk = V::load_unaligned(cur);
  968|    934|        let eq1 = self.v1.cmpeq(chunk);
  969|    934|        let eq2 = self.v2.cmpeq(chunk);
  970|    934|        let eq3 = self.v3.cmpeq(chunk);
  971|    934|        let mask = eq1.or(eq2).or(eq3).movemask();
  972|    934|        if mask.has_non_zero() {
  973|    606|            let mask1 = eq1.movemask();
  974|    606|            let mask2 = eq2.movemask();
  975|    606|            let mask3 = eq3.movemask();
  976|    606|            Some(cur.add(mask_to_offset(mask1.or(mask2).or(mask3))))
  977|       |        } else {
  978|    328|            None
  979|       |        }
  980|    934|    }
_RNvMNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iE3newB8_:
  111|  1.87M|    pub(crate) unsafe fn new(needle: u8) -> One<V> {
  112|  1.87M|        One { s1: needle, v1: V::splat(needle) }
  113|  1.87M|    }
_RNvMNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iE8find_rawB8_:
  143|  1.79M|    pub(crate) unsafe fn find_raw(
  144|  1.79M|        &self,
  145|  1.79M|        start: *const u8,
  146|  1.79M|        end: *const u8,
  147|  1.79M|    ) -> Option<*const u8> {
  148|  1.79M|        // If we want to support vectors bigger than 256 bits, we probably
  149|  1.79M|        // need to move up to using a u64 for the masks used below. Currently
  150|  1.79M|        // they are 32 bits, which means we're SOL for vectors that need masks
  151|  1.79M|        // bigger than 32 bits. Overall unclear until there's a use case.
  152|  1.79M|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  153|       |
  154|  1.79M|        let topos = V::Mask::first_offset;
  155|  1.79M|        let len = end.distance(start);
  156|  1.79M|        debug_assert!(
  157|      0|            len >= V::BYTES,
  158|      0|            "haystack has length {}, but must be at least {}",
  159|       |            len,
  160|       |            V::BYTES
  161|       |        );
  162|       |
  163|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  164|       |        // of the haystack prior to where aligned loads can start.
  165|  1.79M|        if let Some(cur) = self.search_chunk(start, topos) {
  166|  1.77M|            return Some(cur);
  167|  23.4k|        }
  168|  23.4k|        // Set `cur` to the first V-aligned pointer greater than `start`.
  169|  23.4k|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  170|  23.4k|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  171|  23.4k|        if len >= Self::LOOP_SIZE {
  172|  26.2k|            while cur <= end.sub(Self::LOOP_SIZE) {
  173|  24.8k|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  174|       |
  175|  24.8k|                let a = V::load_aligned(cur);
  176|  24.8k|                let b = V::load_aligned(cur.add(1 * V::BYTES));
  177|  24.8k|                let c = V::load_aligned(cur.add(2 * V::BYTES));
  178|  24.8k|                let d = V::load_aligned(cur.add(3 * V::BYTES));
  179|  24.8k|                let eqa = self.v1.cmpeq(a);
  180|  24.8k|                let eqb = self.v1.cmpeq(b);
  181|  24.8k|                let eqc = self.v1.cmpeq(c);
  182|  24.8k|                let eqd = self.v1.cmpeq(d);
  183|  24.8k|                let or1 = eqa.or(eqb);
  184|  24.8k|                let or2 = eqc.or(eqd);
  185|  24.8k|                let or3 = or1.or(or2);
  186|  24.8k|                if or3.movemask_will_have_non_zero() {
  187|  20.2k|                    let mask = eqa.movemask();
  188|  20.2k|                    if mask.has_non_zero() {
  189|  11.8k|                        return Some(cur.add(topos(mask)));
  190|  8.38k|                    }
  191|  8.38k|
  192|  8.38k|                    let mask = eqb.movemask();
  193|  8.38k|                    if mask.has_non_zero() {
  194|  6.98k|                        return Some(cur.add(1 * V::BYTES).add(topos(mask)));
  195|  1.40k|                    }
  196|  1.40k|
  197|  1.40k|                    let mask = eqc.movemask();
  198|  1.40k|                    if mask.has_non_zero() {
  199|  1.08k|                        return Some(cur.add(2 * V::BYTES).add(topos(mask)));
  200|    323|                    }
  201|    323|
  202|    323|                    let mask = eqd.movemask();
  203|    323|                    debug_assert!(mask.has_non_zero());
  204|    323|                    return Some(cur.add(3 * V::BYTES).add(topos(mask)));
  205|  4.60k|                }
  206|  4.60k|                cur = cur.add(Self::LOOP_SIZE);
  207|       |            }
  208|  1.84k|        }
  209|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  210|       |        // loads here, but I believe we are guaranteed that they are aligned
  211|       |        // since `cur` is aligned.
  212|  5.92k|        while cur <= end.sub(V::BYTES) {
  213|  3.98k|            debug_assert!(end.distance(cur) >= V::BYTES);
  214|  3.98k|            if let Some(cur) = self.search_chunk(cur, topos) {
  215|  1.25k|                return Some(cur);
  216|  2.72k|            }
  217|  2.72k|            cur = cur.add(V::BYTES);
  218|       |        }
  219|       |        // Finally handle any remaining bytes less than the size of V. In this
  220|       |        // case, our pointer may indeed be unaligned and the load may overlap
  221|       |        // with the previous one. But that's okay since we know the previous
  222|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  223|  1.93k|        if cur < end {
  224|  1.81k|            debug_assert!(end.distance(cur) < V::BYTES);
  225|  1.81k|            cur = cur.sub(V::BYTES - end.distance(cur));
  226|  1.81k|            debug_assert_eq!(end.distance(cur), V::BYTES);
  227|  1.81k|            return self.search_chunk(cur, topos);
  228|    121|        }
  229|    121|        None
  230|  1.79M|    }
_RINvMNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB3_3OneNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iE12search_chunkNvYNtNtB9_6vector16SensibleMoveMaskNtB24_8MoveMask12first_offsetEB9_:
  416|  1.80M|    unsafe fn search_chunk(
  417|  1.80M|        &self,
  418|  1.80M|        cur: *const u8,
  419|  1.80M|        mask_to_offset: impl Fn(V::Mask) -> usize,
  420|  1.80M|    ) -> Option<*const u8> {
  421|  1.80M|        let chunk = V::load_unaligned(cur);
  422|  1.80M|        let mask = self.v1.cmpeq(chunk).movemask();
  423|  1.80M|        if mask.has_non_zero() {
  424|  1.77M|            Some(cur.add(mask_to_offset(mask)))
  425|       |        } else {
  426|  27.6k|            None
  427|       |        }
  428|  1.80M|    }
_RNvMs_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iE3newBa_:
  450|   271k|    pub(crate) unsafe fn new(needle1: u8, needle2: u8) -> Two<V> {
  451|   271k|        Two {
  452|   271k|            s1: needle1,
  453|   271k|            s2: needle2,
  454|   271k|            v1: V::splat(needle1),
  455|   271k|            v2: V::splat(needle2),
  456|   271k|        }
  457|   271k|    }
_RNvMs_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iE8find_rawBa_:
  493|   236k|    pub(crate) unsafe fn find_raw(
  494|   236k|        &self,
  495|   236k|        start: *const u8,
  496|   236k|        end: *const u8,
  497|   236k|    ) -> Option<*const u8> {
  498|   236k|        // If we want to support vectors bigger than 256 bits, we probably
  499|   236k|        // need to move up to using a u64 for the masks used below. Currently
  500|   236k|        // they are 32 bits, which means we're SOL for vectors that need masks
  501|   236k|        // bigger than 32 bits. Overall unclear until there's a use case.
  502|   236k|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  503|       |
  504|   236k|        let topos = V::Mask::first_offset;
  505|   236k|        let len = end.distance(start);
  506|   236k|        debug_assert!(
  507|      0|            len >= V::BYTES,
  508|      0|            "haystack has length {}, but must be at least {}",
  509|       |            len,
  510|       |            V::BYTES
  511|       |        );
  512|       |
  513|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  514|       |        // of the haystack prior to where aligned loads can start.
  515|   236k|        if let Some(cur) = self.search_chunk(start, topos) {
  516|   231k|            return Some(cur);
  517|  5.32k|        }
  518|  5.32k|        // Set `cur` to the first V-aligned pointer greater than `start`.
  519|  5.32k|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  520|  5.32k|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  521|  5.32k|        if len >= Self::LOOP_SIZE {
  522|  5.69k|            while cur <= end.sub(Self::LOOP_SIZE) {
  523|  5.30k|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  524|       |
  525|  5.30k|                let a = V::load_aligned(cur);
  526|  5.30k|                let b = V::load_aligned(cur.add(V::BYTES));
  527|  5.30k|                let eqa1 = self.v1.cmpeq(a);
  528|  5.30k|                let eqb1 = self.v1.cmpeq(b);
  529|  5.30k|                let eqa2 = self.v2.cmpeq(a);
  530|  5.30k|                let eqb2 = self.v2.cmpeq(b);
  531|  5.30k|                let or1 = eqa1.or(eqb1);
  532|  5.30k|                let or2 = eqa2.or(eqb2);
  533|  5.30k|                let or3 = or1.or(or2);
  534|  5.30k|                if or3.movemask_will_have_non_zero() {
  535|  4.48k|                    let mask = eqa1.movemask().or(eqa2.movemask());
  536|  4.48k|                    if mask.has_non_zero() {
  537|  3.46k|                        return Some(cur.add(topos(mask)));
  538|  1.02k|                    }
  539|  1.02k|
  540|  1.02k|                    let mask = eqb1.movemask().or(eqb2.movemask());
  541|  1.02k|                    debug_assert!(mask.has_non_zero());
  542|  1.02k|                    return Some(cur.add(V::BYTES).add(topos(mask)));
  543|    825|                }
  544|    825|                cur = cur.add(Self::LOOP_SIZE);
  545|       |            }
  546|    453|        }
  547|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  548|       |        // loads here, but I believe we are guaranteed that they are aligned
  549|       |        // since `cur` is aligned.
  550|  1.00k|        while cur <= end.sub(V::BYTES) {
  551|    462|            debug_assert!(end.distance(cur) >= V::BYTES);
  552|    462|            if let Some(cur) = self.search_chunk(cur, topos) {
  553|    299|                return Some(cur);
  554|    163|            }
  555|    163|            cur = cur.add(V::BYTES);
  556|       |        }
  557|       |        // Finally handle any remaining bytes less than the size of V. In this
  558|       |        // case, our pointer may indeed be unaligned and the load may overlap
  559|       |        // with the previous one. But that's okay since we know the previous
  560|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  561|    545|        if cur < end {
  562|    528|            debug_assert!(end.distance(cur) < V::BYTES);
  563|    528|            cur = cur.sub(V::BYTES - end.distance(cur));
  564|    528|            debug_assert_eq!(end.distance(cur), V::BYTES);
  565|    528|            return self.search_chunk(cur, topos);
  566|     17|        }
  567|     17|        None
  568|   236k|    }
_RINvMs_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB5_3TwoNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iE12search_chunkNvYNtNtBb_6vector16SensibleMoveMaskNtB26_8MoveMask12first_offsetEBb_:
  670|   237k|    unsafe fn search_chunk(
  671|   237k|        &self,
  672|   237k|        cur: *const u8,
  673|   237k|        mask_to_offset: impl Fn(V::Mask) -> usize,
  674|   237k|    ) -> Option<*const u8> {
  675|   237k|        let chunk = V::load_unaligned(cur);
  676|   237k|        let eq1 = self.v1.cmpeq(chunk);
  677|   237k|        let eq2 = self.v2.cmpeq(chunk);
  678|   237k|        let mask = eq1.or(eq2).movemask();
  679|   237k|        if mask.has_non_zero() {
  680|   232k|            let mask1 = eq1.movemask();
  681|   232k|            let mask2 = eq2.movemask();
  682|   232k|            Some(cur.add(mask_to_offset(mask1.or(mask2))))
  683|       |        } else {
  684|  5.51k|            None
  685|       |        }
  686|   237k|    }
_RNvMs0_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iE3newBb_:
  710|  8.71k|    pub(crate) unsafe fn new(
  711|  8.71k|        needle1: u8,
  712|  8.71k|        needle2: u8,
  713|  8.71k|        needle3: u8,
  714|  8.71k|    ) -> Three<V> {
  715|  8.71k|        Three {
  716|  8.71k|            s1: needle1,
  717|  8.71k|            s2: needle2,
  718|  8.71k|            s3: needle3,
  719|  8.71k|            v1: V::splat(needle1),
  720|  8.71k|            v2: V::splat(needle2),
  721|  8.71k|            v3: V::splat(needle3),
  722|  8.71k|        }
  723|  8.71k|    }
_RNvMs0_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iE8find_rawBb_:
  765|  6.15k|    pub(crate) unsafe fn find_raw(
  766|  6.15k|        &self,
  767|  6.15k|        start: *const u8,
  768|  6.15k|        end: *const u8,
  769|  6.15k|    ) -> Option<*const u8> {
  770|  6.15k|        // If we want to support vectors bigger than 256 bits, we probably
  771|  6.15k|        // need to move up to using a u64 for the masks used below. Currently
  772|  6.15k|        // they are 32 bits, which means we're SOL for vectors that need masks
  773|  6.15k|        // bigger than 32 bits. Overall unclear until there's a use case.
  774|  6.15k|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  775|       |
  776|  6.15k|        let topos = V::Mask::first_offset;
  777|  6.15k|        let len = end.distance(start);
  778|  6.15k|        debug_assert!(
  779|      0|            len >= V::BYTES,
  780|      0|            "haystack has length {}, but must be at least {}",
  781|       |            len,
  782|       |            V::BYTES
  783|       |        );
  784|       |
  785|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  786|       |        // of the haystack prior to where aligned loads can start.
  787|  6.15k|        if let Some(cur) = self.search_chunk(start, topos) {
  788|  2.73k|            return Some(cur);
  789|  3.41k|        }
  790|  3.41k|        // Set `cur` to the first V-aligned pointer greater than `start`.
  791|  3.41k|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  792|  3.41k|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  793|  3.41k|        if len >= Self::LOOP_SIZE {
  794|  3.56k|            while cur <= end.sub(Self::LOOP_SIZE) {
  795|  3.40k|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  796|       |
  797|  3.40k|                let a = V::load_aligned(cur);
  798|  3.40k|                let b = V::load_aligned(cur.add(V::BYTES));
  799|  3.40k|                let eqa1 = self.v1.cmpeq(a);
  800|  3.40k|                let eqb1 = self.v1.cmpeq(b);
  801|  3.40k|                let eqa2 = self.v2.cmpeq(a);
  802|  3.40k|                let eqb2 = self.v2.cmpeq(b);
  803|  3.40k|                let eqa3 = self.v3.cmpeq(a);
  804|  3.40k|                let eqb3 = self.v3.cmpeq(b);
  805|  3.40k|                let or1 = eqa1.or(eqb1);
  806|  3.40k|                let or2 = eqa2.or(eqb2);
  807|  3.40k|                let or3 = eqa3.or(eqb3);
  808|  3.40k|                let or4 = or1.or(or2);
  809|  3.40k|                let or5 = or3.or(or4);
  810|  3.40k|                if or5.movemask_will_have_non_zero() {
  811|  3.05k|                    let mask = eqa1
  812|  3.05k|                        .movemask()
  813|  3.05k|                        .or(eqa2.movemask())
  814|  3.05k|                        .or(eqa3.movemask());
  815|  3.05k|                    if mask.has_non_zero() {
  816|  2.09k|                        return Some(cur.add(topos(mask)));
  817|    962|                    }
  818|    962|
  819|    962|                    let mask = eqb1
  820|    962|                        .movemask()
  821|    962|                        .or(eqb2.movemask())
  822|    962|                        .or(eqb3.movemask());
  823|    962|                    debug_assert!(mask.has_non_zero());
  824|    962|                    return Some(cur.add(V::BYTES).add(topos(mask)));
  825|    348|                }
  826|    348|                cur = cur.add(Self::LOOP_SIZE);
  827|       |            }
  828|    194|        }
  829|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  830|       |        // loads here, but I believe we are guaranteed that they are aligned
  831|       |        // since `cur` is aligned.
  832|    467|        while cur <= end.sub(V::BYTES) {
  833|    174|            debug_assert!(end.distance(cur) >= V::BYTES);
  834|    174|            if let Some(cur) = self.search_chunk(cur, topos) {
  835|     64|                return Some(cur);
  836|    110|            }
  837|    110|            cur = cur.add(V::BYTES);
  838|       |        }
  839|       |        // Finally handle any remaining bytes less than the size of V. In this
  840|       |        // case, our pointer may indeed be unaligned and the load may overlap
  841|       |        // with the previous one. But that's okay since we know the previous
  842|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  843|    293|        if cur < end {
  844|    272|            debug_assert!(end.distance(cur) < V::BYTES);
  845|    272|            cur = cur.sub(V::BYTES - end.distance(cur));
  846|    272|            debug_assert_eq!(end.distance(cur), V::BYTES);
  847|    272|            return self.search_chunk(cur, topos);
  848|     21|        }
  849|     21|        None
  850|  6.15k|    }
_RINvMs0_NtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchrINtB6_5ThreeNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iE12search_chunkNvYNtNtBc_6vector16SensibleMoveMaskNtB29_8MoveMask12first_offsetEBc_:
  962|  6.59k|    unsafe fn search_chunk(
  963|  6.59k|        &self,
  964|  6.59k|        cur: *const u8,
  965|  6.59k|        mask_to_offset: impl Fn(V::Mask) -> usize,
  966|  6.59k|    ) -> Option<*const u8> {
  967|  6.59k|        let chunk = V::load_unaligned(cur);
  968|  6.59k|        let eq1 = self.v1.cmpeq(chunk);
  969|  6.59k|        let eq2 = self.v2.cmpeq(chunk);
  970|  6.59k|        let eq3 = self.v3.cmpeq(chunk);
  971|  6.59k|        let mask = eq1.or(eq2).or(eq3).movemask();
  972|  6.59k|        if mask.has_non_zero() {
  973|  2.98k|            let mask1 = eq1.movemask();
  974|  2.98k|            let mask2 = eq2.movemask();
  975|  2.98k|            let mask3 = eq3.movemask();
  976|  2.98k|            Some(cur.add(mask_to_offset(mask1.or(mask2).or(mask3))))
  977|       |        } else {
  978|  3.61k|            None
  979|       |        }
  980|  6.59k|    }
_RINvNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchr16fwd_byte_by_byteNCNvMNtNtNtB6_6x86_644avx26memchrNtB1a_3One8find_raw0EB8_:
 1148|  35.3k|pub(crate) unsafe fn fwd_byte_by_byte<F: Fn(u8) -> bool>(
 1149|  35.3k|    start: *const u8,
 1150|  35.3k|    end: *const u8,
 1151|  35.3k|    confirm: F,
 1152|  35.3k|) -> Option<*const u8> {
 1153|  35.3k|    debug_assert!(start <= end);
 1154|  35.3k|    let mut ptr = start;
 1155|   126k|    while ptr < end {
 1156|   119k|        if confirm(*ptr) {
 1157|  28.0k|            return Some(ptr);
 1158|  91.2k|        }
 1159|  91.2k|        ptr = ptr.offset(1);
 1160|       |    }
 1161|  7.31k|    None
 1162|  35.3k|}
_RINvNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchr16fwd_byte_by_byteNCNvMs2_NtNtNtB6_6x86_644avx26memchrNtB1d_3Two8find_raw0EB8_:
 1148|  21.5k|pub(crate) unsafe fn fwd_byte_by_byte<F: Fn(u8) -> bool>(
 1149|  21.5k|    start: *const u8,
 1150|  21.5k|    end: *const u8,
 1151|  21.5k|    confirm: F,
 1152|  21.5k|) -> Option<*const u8> {
 1153|  21.5k|    debug_assert!(start <= end);
 1154|  21.5k|    let mut ptr = start;
 1155|  44.5k|    while ptr < end {
 1156|  41.9k|        if confirm(*ptr) {
 1157|  18.9k|            return Some(ptr);
 1158|  23.0k|        }
 1159|  23.0k|        ptr = ptr.offset(1);
 1160|       |    }
 1161|  2.56k|    None
 1162|  21.5k|}
_RINvNtNtNtCsgAmdbuUjTpV_6memchr4arch7generic6memchr16fwd_byte_by_byteNCNvMs6_NtNtNtB6_6x86_644avx26memchrNtB1d_5Three8find_raw0EB8_:
 1148|  1.80k|pub(crate) unsafe fn fwd_byte_by_byte<F: Fn(u8) -> bool>(
 1149|  1.80k|    start: *const u8,
 1150|  1.80k|    end: *const u8,
 1151|  1.80k|    confirm: F,
 1152|  1.80k|) -> Option<*const u8> {
 1153|  1.80k|    debug_assert!(start <= end);
 1154|  1.80k|    let mut ptr = start;
 1155|  7.56k|    while ptr < end {
 1156|  6.63k|        if confirm(*ptr) {
 1157|    876|            return Some(ptr);
 1158|  5.76k|        }
 1159|  5.76k|        ptr = ptr.offset(1);
 1160|       |    }
 1161|    932|    None
 1162|  1.80k|}

_RNvMNtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB2_3One13new_uncheckedBa_:
   69|  1.87M|    pub unsafe fn new_unchecked(needle: u8) -> One {
   70|  1.87M|        One {
   71|  1.87M|            sse2: generic::One::new(needle),
   72|  1.87M|            avx2: generic::One::new(needle),
   73|  1.87M|        }
   74|  1.87M|    }
_RNvMNtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB2_3One12is_availableBa_:
   86|      1|    pub fn is_available() -> bool {
   87|      1|        #[cfg(not(target_feature = "sse2"))]
   88|      1|        {
   89|      1|            false
   90|      1|        }
   91|      1|        #[cfg(target_feature = "sse2")]
   92|      1|        {
   93|      1|            #[cfg(target_feature = "avx2")]
   94|      1|            {
   95|      1|                true
   96|      1|            }
   97|      1|            #[cfg(not(target_feature = "avx2"))]
   98|      1|            {
   99|      1|                #[cfg(feature = "std")]
  100|      1|                {
  101|      1|                    std::is_x86_feature_detected!("avx2")
  102|       |                }
  103|       |                #[cfg(not(feature = "std"))]
  104|       |                {
  105|       |                    false
  106|       |                }
  107|       |            }
  108|       |        }
  109|      1|    }
_RNvMNtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB2_3One8find_rawBa_:
  179|  1.87M|    pub unsafe fn find_raw(
  180|  1.87M|        &self,
  181|  1.87M|        start: *const u8,
  182|  1.87M|        end: *const u8,
  183|  1.87M|    ) -> Option<*const u8> {
  184|  1.87M|        if start >= end {
  185|    714|            return None;
  186|  1.87M|        }
  187|  1.87M|        let len = end.distance(start);
  188|  1.87M|        if len < __m256i::BYTES {
  189|  75.5k|            return if len < __m128i::BYTES {
  190|       |                // SAFETY: We require the caller to pass valid start/end
  191|       |                // pointers.
  192|  35.3k|                generic::fwd_byte_by_byte(start, end, |b| {
  193|       |                    b == self.sse2.needle1()
  194|  35.3k|                })
  195|       |            } else {
  196|       |                // SAFETY: We require the caller to pass valid start/end
  197|       |                // pointers.
  198|  40.2k|                self.find_raw_sse2(start, end)
  199|       |            };
  200|  1.79M|        }
  201|  1.79M|        // SAFETY: Building a `One` means it's safe to call both 'sse2' and
  202|  1.79M|        // 'avx2' routines. Also, we've checked that our haystack is big
  203|  1.79M|        // enough to run on the vector routine. Pointer validity is caller's
  204|  1.79M|        // responsibility.
  205|  1.79M|        //
  206|  1.79M|        // Note that we could call `self.avx2.find_raw` directly here. But that
  207|  1.79M|        // means we'd have to annotate this routine with `target_feature`.
  208|  1.79M|        // Which is fine, because this routine is `unsafe` anyway and the
  209|  1.79M|        // `target_feature` obligation is met by virtue of building a `One`.
  210|  1.79M|        // The real problem is that a routine with a `target_feature`
  211|  1.79M|        // annotation generally can't be inlined into caller code unless
  212|  1.79M|        // the caller code has the same target feature annotations. Namely,
  213|  1.79M|        // the common case (at time of writing) is for calling code to not
  214|  1.79M|        // have the `avx2` target feature enabled *at compile time*. Without
  215|  1.79M|        // `target_feature` on this routine, it can be inlined which will
  216|  1.79M|        // handle some of the short-haystack cases above without touching the
  217|  1.79M|        // architecture specific code.
  218|  1.79M|        self.find_raw_avx2(start, end)
  219|  1.87M|    }
_RNCNvMNtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB4_3One8find_raw0Bc_:
  192|   119k|                generic::fwd_byte_by_byte(start, end, |b| {
  193|   119k|                    b == self.sse2.needle1()
  194|   119k|                })
_RNvMNtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB2_3One13find_raw_sse2Ba_:
  336|  40.2k|    unsafe fn find_raw_sse2(
  337|  40.2k|        &self,
  338|  40.2k|        start: *const u8,
  339|  40.2k|        end: *const u8,
  340|  40.2k|    ) -> Option<*const u8> {
  341|  40.2k|        self.sse2.find_raw(start, end)
  342|  40.2k|    }
_RNvMNtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB2_3One13find_raw_avx2Ba_:
  396|  1.79M|    unsafe fn find_raw_avx2(
  397|  1.79M|        &self,
  398|  1.79M|        start: *const u8,
  399|  1.79M|        end: *const u8,
  400|  1.79M|    ) -> Option<*const u8> {
  401|  1.79M|        self.avx2.find_raw(start, end)
  402|  1.79M|    }
_RNvMs2_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_3Two13new_uncheckedBd_:
  556|   271k|    pub unsafe fn new_unchecked(needle1: u8, needle2: u8) -> Two {
  557|   271k|        Two {
  558|   271k|            sse2: generic::Two::new(needle1, needle2),
  559|   271k|            avx2: generic::Two::new(needle1, needle2),
  560|   271k|        }
  561|   271k|    }
_RNvMs2_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_3Two12is_availableBd_:
  573|      1|    pub fn is_available() -> bool {
  574|      1|        #[cfg(not(target_feature = "sse2"))]
  575|      1|        {
  576|      1|            false
  577|      1|        }
  578|      1|        #[cfg(target_feature = "sse2")]
  579|      1|        {
  580|      1|            #[cfg(target_feature = "avx2")]
  581|      1|            {
  582|      1|                true
  583|      1|            }
  584|      1|            #[cfg(not(target_feature = "avx2"))]
  585|      1|            {
  586|      1|                #[cfg(feature = "std")]
  587|      1|                {
  588|      1|                    std::is_x86_feature_detected!("avx2")
  589|       |                }
  590|       |                #[cfg(not(feature = "std"))]
  591|       |                {
  592|       |                    false
  593|       |                }
  594|       |            }
  595|       |        }
  596|      1|    }
_RNvMs2_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_3Two8find_rawBd_:
  654|   271k|    pub unsafe fn find_raw(
  655|   271k|        &self,
  656|   271k|        start: *const u8,
  657|   271k|        end: *const u8,
  658|   271k|    ) -> Option<*const u8> {
  659|   271k|        if start >= end {
  660|  1.79k|            return None;
  661|   270k|        }
  662|   270k|        let len = end.distance(start);
  663|   270k|        if len < __m256i::BYTES {
  664|  33.0k|            return if len < __m128i::BYTES {
  665|       |                // SAFETY: We require the caller to pass valid start/end
  666|       |                // pointers.
  667|  21.5k|                generic::fwd_byte_by_byte(start, end, |b| {
  668|       |                    b == self.sse2.needle1() || b == self.sse2.needle2()
  669|  21.5k|                })
  670|       |            } else {
  671|       |                // SAFETY: We require the caller to pass valid start/end
  672|       |                // pointers.
  673|  11.5k|                self.find_raw_sse2(start, end)
  674|       |            };
  675|   236k|        }
  676|   236k|        // SAFETY: Building a `Two` means it's safe to call both 'sse2' and
  677|   236k|        // 'avx2' routines. Also, we've checked that our haystack is big
  678|   236k|        // enough to run on the vector routine. Pointer validity is caller's
  679|   236k|        // responsibility.
  680|   236k|        //
  681|   236k|        // Note that we could call `self.avx2.find_raw` directly here. But that
  682|   236k|        // means we'd have to annotate this routine with `target_feature`.
  683|   236k|        // Which is fine, because this routine is `unsafe` anyway and the
  684|   236k|        // `target_feature` obligation is met by virtue of building a `Two`.
  685|   236k|        // The real problem is that a routine with a `target_feature`
  686|   236k|        // annotation generally can't be inlined into caller code unless
  687|   236k|        // the caller code has the same target feature annotations. Namely,
  688|   236k|        // the common case (at time of writing) is for calling code to not
  689|   236k|        // have the `avx2` target feature enabled *at compile time*. Without
  690|   236k|        // `target_feature` on this routine, it can be inlined which will
  691|   236k|        // handle some of the short-haystack cases above without touching the
  692|   236k|        // architecture specific code.
  693|   236k|        self.find_raw_avx2(start, end)
  694|   271k|    }
_RNCNvMs2_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB7_3Two8find_raw0Bf_:
  667|  41.9k|                generic::fwd_byte_by_byte(start, end, |b| {
  668|  41.9k|                    b == self.sse2.needle1() || b == self.sse2.needle2()
  669|  41.9k|                })
_RNvMs2_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_3Two13find_raw_sse2Bd_:
  764|  11.5k|    unsafe fn find_raw_sse2(
  765|  11.5k|        &self,
  766|  11.5k|        start: *const u8,
  767|  11.5k|        end: *const u8,
  768|  11.5k|    ) -> Option<*const u8> {
  769|  11.5k|        self.sse2.find_raw(start, end)
  770|  11.5k|    }
_RNvMs2_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_3Two13find_raw_avx2Bd_:
  804|   236k|    unsafe fn find_raw_avx2(
  805|   236k|        &self,
  806|   236k|        start: *const u8,
  807|   236k|        end: *const u8,
  808|   236k|    ) -> Option<*const u8> {
  809|   236k|        self.avx2.find_raw(start, end)
  810|   236k|    }
_RNvMs6_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_5Three13new_uncheckedBd_:
  935|  8.71k|    pub unsafe fn new_unchecked(
  936|  8.71k|        needle1: u8,
  937|  8.71k|        needle2: u8,
  938|  8.71k|        needle3: u8,
  939|  8.71k|    ) -> Three {
  940|  8.71k|        Three {
  941|  8.71k|            sse2: generic::Three::new(needle1, needle2, needle3),
  942|  8.71k|            avx2: generic::Three::new(needle1, needle2, needle3),
  943|  8.71k|        }
  944|  8.71k|    }
_RNvMs6_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_5Three12is_availableBd_:
  956|      1|    pub fn is_available() -> bool {
  957|      1|        #[cfg(not(target_feature = "sse2"))]
  958|      1|        {
  959|      1|            false
  960|      1|        }
  961|      1|        #[cfg(target_feature = "sse2")]
  962|      1|        {
  963|      1|            #[cfg(target_feature = "avx2")]
  964|      1|            {
  965|      1|                true
  966|      1|            }
  967|      1|            #[cfg(not(target_feature = "avx2"))]
  968|      1|            {
  969|      1|                #[cfg(feature = "std")]
  970|      1|                {
  971|      1|                    std::is_x86_feature_detected!("avx2")
  972|       |                }
  973|       |                #[cfg(not(feature = "std"))]
  974|       |                {
  975|       |                    false
  976|       |                }
  977|       |            }
  978|       |        }
  979|      1|    }
_RNvMs6_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_5Three8find_rawBd_:
 1037|  8.71k|    pub unsafe fn find_raw(
 1038|  8.71k|        &self,
 1039|  8.71k|        start: *const u8,
 1040|  8.71k|        end: *const u8,
 1041|  8.71k|    ) -> Option<*const u8> {
 1042|  8.71k|        if start >= end {
 1043|     42|            return None;
 1044|  8.67k|        }
 1045|  8.67k|        let len = end.distance(start);
 1046|  8.67k|        if len < __m256i::BYTES {
 1047|  2.52k|            return if len < __m128i::BYTES {
 1048|       |                // SAFETY: We require the caller to pass valid start/end
 1049|       |                // pointers.
 1050|  1.80k|                generic::fwd_byte_by_byte(start, end, |b| {
 1051|       |                    b == self.sse2.needle1()
 1052|       |                        || b == self.sse2.needle2()
 1053|       |                        || b == self.sse2.needle3()
 1054|  1.80k|                })
 1055|       |            } else {
 1056|       |                // SAFETY: We require the caller to pass valid start/end
 1057|       |                // pointers.
 1058|    716|                self.find_raw_sse2(start, end)
 1059|       |            };
 1060|  6.15k|        }
 1061|  6.15k|        // SAFETY: Building a `Three` means it's safe to call both 'sse2' and
 1062|  6.15k|        // 'avx2' routines. Also, we've checked that our haystack is big
 1063|  6.15k|        // enough to run on the vector routine. Pointer validity is caller's
 1064|  6.15k|        // responsibility.
 1065|  6.15k|        //
 1066|  6.15k|        // Note that we could call `self.avx2.find_raw` directly here. But that
 1067|  6.15k|        // means we'd have to annotate this routine with `target_feature`.
 1068|  6.15k|        // Which is fine, because this routine is `unsafe` anyway and the
 1069|  6.15k|        // `target_feature` obligation is met by virtue of building a `Three`.
 1070|  6.15k|        // The real problem is that a routine with a `target_feature`
 1071|  6.15k|        // annotation generally can't be inlined into caller code unless
 1072|  6.15k|        // the caller code has the same target feature annotations. Namely,
 1073|  6.15k|        // the common case (at time of writing) is for calling code to not
 1074|  6.15k|        // have the `avx2` target feature enabled *at compile time*. Without
 1075|  6.15k|        // `target_feature` on this routine, it can be inlined which will
 1076|  6.15k|        // handle some of the short-haystack cases above without touching the
 1077|  6.15k|        // architecture specific code.
 1078|  6.15k|        self.find_raw_avx2(start, end)
 1079|  8.71k|    }
_RNCNvMs6_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB7_5Three8find_raw0Bf_:
 1050|  6.63k|                generic::fwd_byte_by_byte(start, end, |b| {
 1051|  6.63k|                    b == self.sse2.needle1()
 1052|  6.09k|                        || b == self.sse2.needle2()
 1053|  5.93k|                        || b == self.sse2.needle3()
 1054|  6.63k|                })
_RNvMs6_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_5Three13find_raw_sse2Bd_:
 1151|    716|    unsafe fn find_raw_sse2(
 1152|    716|        &self,
 1153|    716|        start: *const u8,
 1154|    716|        end: *const u8,
 1155|    716|    ) -> Option<*const u8> {
 1156|    716|        self.sse2.find_raw(start, end)
 1157|    716|    }
_RNvMs6_NtNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_644avx26memchrNtB5_5Three13find_raw_avx2Bd_:
 1191|  6.15k|    unsafe fn find_raw_avx2(
 1192|  6.15k|        &self,
 1193|  6.15k|        start: *const u8,
 1194|  6.15k|        end: *const u8,
 1195|  6.15k|    ) -> Option<*const u8> {
 1196|  6.15k|        self.avx2.find_raw(start, end)
 1197|  6.15k|    }

_RNvNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_646memchr10memchr_raw:
  174|  1.87M|pub(crate) fn memchr_raw(
  175|  1.87M|    n1: u8,
  176|  1.87M|    start: *const u8,
  177|  1.87M|    end: *const u8,
  178|  1.87M|) -> Option<*const u8> {
  179|  1.87M|    // SAFETY: We provide a valid function pointer type.
  180|  1.87M|    unsafe_ifunc!(
  181|  1.87M|        One,
  182|  1.87M|        find_raw,
  183|  1.87M|        unsafe fn(u8, *const u8, *const u8) -> Option<*const u8>,
  184|  1.87M|        Option<*const u8>,
  185|  1.87M|        start,
  186|  1.87M|        end,
  187|  1.87M|        n1
  188|  1.87M|    )
  189|  1.87M|}
_RNvNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_646memchr11memchr2_raw:
  220|   271k|pub(crate) fn memchr2_raw(
  221|   271k|    n1: u8,
  222|   271k|    n2: u8,
  223|   271k|    start: *const u8,
  224|   271k|    end: *const u8,
  225|   271k|) -> Option<*const u8> {
  226|   271k|    // SAFETY: We provide a valid function pointer type.
  227|   271k|    unsafe_ifunc!(
  228|   271k|        Two,
  229|   271k|        find_raw,
  230|   271k|        unsafe fn(u8, u8, *const u8, *const u8) -> Option<*const u8>,
  231|   271k|        Option<*const u8>,
  232|   271k|        start,
  233|   271k|        end,
  234|   271k|        n1,
  235|   271k|        n2
  236|   271k|    )
  237|   271k|}
_RNvNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_646memchr11memchr3_raw:
  270|  8.71k|pub(crate) fn memchr3_raw(
  271|  8.71k|    n1: u8,
  272|  8.71k|    n2: u8,
  273|  8.71k|    n3: u8,
  274|  8.71k|    start: *const u8,
  275|  8.71k|    end: *const u8,
  276|  8.71k|) -> Option<*const u8> {
  277|  8.71k|    // SAFETY: We provide a valid function pointer type.
  278|  8.71k|    unsafe_ifunc!(
  279|  8.71k|        Three,
  280|  8.71k|        find_raw,
  281|  8.71k|        unsafe fn(u8, u8, u8, *const u8, *const u8) -> Option<*const u8>,
  282|  8.71k|        Option<*const u8>,
  283|  8.71k|        start,
  284|  8.71k|        end,
  285|  8.71k|        n1,
  286|  8.71k|        n2,
  287|  8.71k|        n3
  288|  8.71k|    )
  289|  8.71k|}
_RNvNvNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_646memchr10memchr_raw9find_avx2:
   78|  1.87M|        unsafe fn find_avx2(
   79|  1.87M|            $($needle: u8),+,
   80|  1.87M|            $hay_start: *const u8,
   81|  1.87M|            $hay_end: *const u8,
   82|  1.87M|        ) -> $retty {
   83|       |            use crate::arch::x86_64::avx2::memchr::$memchrty;
   84|  1.87M|            $memchrty::new_unchecked($($needle),+)
   85|  1.87M|                .$memchrfind($hay_start, $hay_end)
   86|  1.87M|        }
_RNvNvNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_646memchr10memchr_raw6detect:
  109|      1|        unsafe fn detect(
  110|      1|            $($needle: u8),+,
  111|      1|            $hay_start: *const u8,
  112|      1|            $hay_end: *const u8,
  113|      1|        ) -> $retty {
  114|      1|            let fun = {
  115|       |                #[cfg(not(target_feature = "sse2"))]
  116|       |                {
  117|       |                    debug!(
  118|       |                        "no sse2 feature available, using fallback for {}",
  119|       |                        stringify!($memchrty),
  120|       |                    );
  121|       |                    find_fallback as RealFn
  122|       |                }
  123|       |                #[cfg(target_feature = "sse2")]
  124|       |                {
  125|       |                    use crate::arch::x86_64::{sse2, avx2};
  126|      1|                    if avx2::memchr::$memchrty::is_available() {
  127|       |                        debug!("chose AVX2 for {}", stringify!($memchrty));
  128|      1|                        find_avx2 as RealFn
  129|      0|                    } else if sse2::memchr::$memchrty::is_available() {
  130|       |                        debug!("chose SSE2 for {}", stringify!($memchrty));
  131|      0|                        find_sse2 as RealFn
  132|       |                    } else {
  133|       |                        debug!("chose fallback for {}", stringify!($memchrty));
  134|      0|                        find_fallback as RealFn
  135|       |                    }
  136|       |                }
  137|       |            };
  138|      1|            FN.store(fun as Fn, Ordering::Relaxed);
  139|      1|            // SAFETY: The only thing we need to uphold here is the
  140|      1|            // `#[target_feature]` requirements. Since we check is_available
  141|      1|            // above before using the corresponding implementation, we are
  142|      1|            // guaranteed to only call code that is supported on the current
  143|      1|            // CPU.
  144|      1|            fun($($needle),+, $hay_start, $hay_end)
  145|      1|        }
_RNvNvNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_646memchr11memchr2_raw9find_avx2:
   78|   271k|        unsafe fn find_avx2(
   79|   271k|            $($needle: u8),+,
   80|   271k|            $hay_start: *const u8,
   81|   271k|            $hay_end: *const u8,
   82|   271k|        ) -> $retty {
   83|       |            use crate::arch::x86_64::avx2::memchr::$memchrty;
   84|   271k|            $memchrty::new_unchecked($($needle),+)
   85|   271k|                .$memchrfind($hay_start, $hay_end)
   86|   271k|        }
_RNvNvNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_646memchr11memchr2_raw6detect:
  109|      1|        unsafe fn detect(
  110|      1|            $($needle: u8),+,
  111|      1|            $hay_start: *const u8,
  112|      1|            $hay_end: *const u8,
  113|      1|        ) -> $retty {
  114|      1|            let fun = {
  115|       |                #[cfg(not(target_feature = "sse2"))]
  116|       |                {
  117|       |                    debug!(
  118|       |                        "no sse2 feature available, using fallback for {}",
  119|       |                        stringify!($memchrty),
  120|       |                    );
  121|       |                    find_fallback as RealFn
  122|       |                }
  123|       |                #[cfg(target_feature = "sse2")]
  124|       |                {
  125|       |                    use crate::arch::x86_64::{sse2, avx2};
  126|      1|                    if avx2::memchr::$memchrty::is_available() {
  127|       |                        debug!("chose AVX2 for {}", stringify!($memchrty));
  128|      1|                        find_avx2 as RealFn
  129|      0|                    } else if sse2::memchr::$memchrty::is_available() {
  130|       |                        debug!("chose SSE2 for {}", stringify!($memchrty));
  131|      0|                        find_sse2 as RealFn
  132|       |                    } else {
  133|       |                        debug!("chose fallback for {}", stringify!($memchrty));
  134|      0|                        find_fallback as RealFn
  135|       |                    }
  136|       |                }
  137|       |            };
  138|      1|            FN.store(fun as Fn, Ordering::Relaxed);
  139|      1|            // SAFETY: The only thing we need to uphold here is the
  140|      1|            // `#[target_feature]` requirements. Since we check is_available
  141|      1|            // above before using the corresponding implementation, we are
  142|      1|            // guaranteed to only call code that is supported on the current
  143|      1|            // CPU.
  144|      1|            fun($($needle),+, $hay_start, $hay_end)
  145|      1|        }
_RNvNvNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_646memchr11memchr3_raw9find_avx2:
   78|  8.71k|        unsafe fn find_avx2(
   79|  8.71k|            $($needle: u8),+,
   80|  8.71k|            $hay_start: *const u8,
   81|  8.71k|            $hay_end: *const u8,
   82|  8.71k|        ) -> $retty {
   83|       |            use crate::arch::x86_64::avx2::memchr::$memchrty;
   84|  8.71k|            $memchrty::new_unchecked($($needle),+)
   85|  8.71k|                .$memchrfind($hay_start, $hay_end)
   86|  8.71k|        }
_RNvNvNtNtNtCsgAmdbuUjTpV_6memchr4arch6x86_646memchr11memchr3_raw6detect:
  109|      1|        unsafe fn detect(
  110|      1|            $($needle: u8),+,
  111|      1|            $hay_start: *const u8,
  112|      1|            $hay_end: *const u8,
  113|      1|        ) -> $retty {
  114|      1|            let fun = {
  115|       |                #[cfg(not(target_feature = "sse2"))]
  116|       |                {
  117|       |                    debug!(
  118|       |                        "no sse2 feature available, using fallback for {}",
  119|       |                        stringify!($memchrty),
  120|       |                    );
  121|       |                    find_fallback as RealFn
  122|       |                }
  123|       |                #[cfg(target_feature = "sse2")]
  124|       |                {
  125|       |                    use crate::arch::x86_64::{sse2, avx2};
  126|      1|                    if avx2::memchr::$memchrty::is_available() {
  127|       |                        debug!("chose AVX2 for {}", stringify!($memchrty));
  128|      1|                        find_avx2 as RealFn
  129|      0|                    } else if sse2::memchr::$memchrty::is_available() {
  130|       |                        debug!("chose SSE2 for {}", stringify!($memchrty));
  131|      0|                        find_sse2 as RealFn
  132|       |                    } else {
  133|       |                        debug!("chose fallback for {}", stringify!($memchrty));
  134|      0|                        find_fallback as RealFn
  135|       |                    }
  136|       |                }
  137|       |            };
  138|      1|            FN.store(fun as Fn, Ordering::Relaxed);
  139|      1|            // SAFETY: The only thing we need to uphold here is the
  140|      1|            // `#[target_feature]` requirements. Since we check is_available
  141|      1|            // above before using the corresponding implementation, we are
  142|      1|            // guaranteed to only call code that is supported on the current
  143|      1|            // CPU.
  144|      1|            fun($($needle),+, $hay_start, $hay_end)
  145|      1|        }

_RNvXNtCsgAmdbuUjTpV_6memchr3extPhNtB2_7Pointer8distanceB4_:
   21|  6.39M|    unsafe fn distance(self, origin: *const T) -> usize {
   22|  6.39M|        // TODO: Replace with `ptr::sub_ptr` once stabilized.
   23|  6.39M|        usize::try_from(self.offset_from(origin)).unwrap_unchecked()
   24|  6.39M|    }
_RNvXNtCsgAmdbuUjTpV_6memchr3extPhNtB2_7Pointer8as_usizeB4_:
   26|  34.6k|    fn as_usize(self) -> usize {
   27|  34.6k|        self as usize
   28|  34.6k|    }

_RNvMNtCsgAmdbuUjTpV_6memchr6memchrNtB2_6Memchr3newCskRNNzwwh1bl_10sparesults:
  300|   660k|    pub fn new(needle1: u8, haystack: &'h [u8]) -> Memchr<'h> {
  301|   660k|        Memchr {
  302|   660k|            needle1,
  303|   660k|            it: crate::arch::generic::memchr::Iter::new(haystack),
  304|   660k|        }
  305|   660k|    }
_RNvMs2_NtCsgAmdbuUjTpV_6memchr6memchrNtB5_7Memchr23newCskRNNzwwh1bl_10sparesults:
  377|  8.28k|    pub fn new(needle1: u8, needle2: u8, haystack: &'h [u8]) -> Memchr2<'h> {
  378|  8.28k|        Memchr2 {
  379|  8.28k|            needle1,
  380|  8.28k|            needle2,
  381|  8.28k|            it: crate::arch::generic::memchr::Iter::new(haystack),
  382|  8.28k|        }
  383|  8.28k|    }
_RNvMs6_NtCsgAmdbuUjTpV_6memchr6memchrNtB5_7Memchr33newCskRNNzwwh1bl_10sparesults:
  446|  2.23k|    pub fn new(
  447|  2.23k|        needle1: u8,
  448|  2.23k|        needle2: u8,
  449|  2.23k|        needle3: u8,
  450|  2.23k|        haystack: &'h [u8],
  451|  2.23k|    ) -> Memchr3<'h> {
  452|  2.23k|        Memchr3 {
  453|  2.23k|            needle1,
  454|  2.23k|            needle2,
  455|  2.23k|            needle3,
  456|  2.23k|            it: crate::arch::generic::memchr::Iter::new(haystack),
  457|  2.23k|        }
  458|  2.23k|    }
_RNvNtCsgAmdbuUjTpV_6memchr6memchr11memchr_iterCskRNNzwwh1bl_10sparesults:
  216|   660k|pub fn memchr_iter<'h>(needle: u8, haystack: &'h [u8]) -> Memchr<'h> {
  217|   660k|    Memchr::new(needle, haystack)
  218|   660k|}
_RNvNtCsgAmdbuUjTpV_6memchr6memchr12memchr2_iterCskRNNzwwh1bl_10sparesults:
  232|  8.28k|pub fn memchr2_iter<'h>(
  233|  8.28k|    needle1: u8,
  234|  8.28k|    needle2: u8,
  235|  8.28k|    haystack: &'h [u8],
  236|  8.28k|) -> Memchr2<'h> {
  237|  8.28k|    Memchr2::new(needle1, needle2, haystack)
  238|  8.28k|}
_RNvNtCsgAmdbuUjTpV_6memchr6memchr12memchr3_iterCskRNNzwwh1bl_10sparesults:
  256|  2.23k|pub fn memchr3_iter<'h>(
  257|  2.23k|    needle1: u8,
  258|  2.23k|    needle2: u8,
  259|  2.23k|    needle3: u8,
  260|  2.23k|    haystack: &'h [u8],
  261|  2.23k|) -> Memchr3<'h> {
  262|  2.23k|    Memchr3::new(needle1, needle2, needle3, haystack)
  263|  2.23k|}
_RNvNtCsgAmdbuUjTpV_6memchr6memchr6memchrCskRNNzwwh1bl_10sparesults:
   27|   676k|pub fn memchr(needle: u8, haystack: &[u8]) -> Option<usize> {
   28|   676k|    // SAFETY: memchr_raw, when a match is found, always returns a valid
   29|   676k|    // pointer between start and end.
   30|   676k|    unsafe {
   31|   676k|        generic::search_slice_with_raw(haystack, |start, end| {
   32|       |            memchr_raw(needle, start, end)
   33|   676k|        })
   34|   676k|    }
   35|   676k|}
_RNvXs3_NtCsgAmdbuUjTpV_6memchr6memchrNtB5_7Memchr2NtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4nextCskRNNzwwh1bl_10sparesults:
  390|  91.0k|    fn next(&mut self) -> Option<usize> {
  391|  91.0k|        // SAFETY: All of our implementations of memchr ensure that any
  392|  91.0k|        // pointers returns will fall within the start and end bounds, and this
  393|  91.0k|        // upholds the safety contract of `self.it.next`.
  394|  91.0k|        unsafe {
  395|  91.0k|            self.it.next(|s, e| memchr2_raw(self.needle1, self.needle2, s, e))
  396|  91.0k|        }
  397|  91.0k|    }
_RNvXs7_NtCsgAmdbuUjTpV_6memchr6memchrNtB5_7Memchr3NtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4nextCskRNNzwwh1bl_10sparesults:
  465|  8.71k|    fn next(&mut self) -> Option<usize> {
  466|  8.71k|        // SAFETY: All of our implementations of memchr ensure that any
  467|  8.71k|        // pointers returns will fall within the start and end bounds, and this
  468|  8.71k|        // upholds the safety contract of `self.it.next`.
  469|  8.71k|        unsafe {
  470|  8.71k|            self.it.next(|s, e| {
  471|       |                memchr3_raw(self.needle1, self.needle2, self.needle3, s, e)
  472|  8.71k|            })
  473|  8.71k|        }
  474|  8.71k|    }
_RNvXs_NtCsgAmdbuUjTpV_6memchr6memchrNtB4_6MemchrNtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4nextCskRNNzwwh1bl_10sparesults:
  312|  1.19M|    fn next(&mut self) -> Option<usize> {
  313|  1.19M|        // SAFETY: All of our implementations of memchr ensure that any
  314|  1.19M|        // pointers returns will fall within the start and end bounds, and this
  315|  1.19M|        // upholds the safety contract of `self.it.next`.
  316|  1.19M|        unsafe {
  317|  1.19M|            // NOTE: I attempted to define an enum of previously created
  318|  1.19M|            // searchers and then switch on those here instead of just
  319|  1.19M|            // calling `memchr_raw` (or `One::new(..).find_raw(..)`). But
  320|  1.19M|            // that turned out to have a fair bit of extra overhead when
  321|  1.19M|            // searching very small haystacks.
  322|  1.19M|            self.it.next(|s, e| memchr_raw(self.needle1, s, e))
  323|  1.19M|        }
  324|  1.19M|    }
_RNCNvXs3_NtCsgAmdbuUjTpV_6memchr6memchrNtB7_7Memchr2NtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4next0Csa7QYSr9aLYT_9quick_xml:
  395|   271k|            self.it.next(|s, e| memchr2_raw(self.needle1, self.needle2, s, e))
_RNCNvXs7_NtCsgAmdbuUjTpV_6memchr6memchrNtB7_7Memchr3NtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4next0Csa7QYSr9aLYT_9quick_xml:
  470|  8.71k|            self.it.next(|s, e| {
  471|  8.71k|                memchr3_raw(self.needle1, self.needle2, self.needle3, s, e)
  472|  8.71k|            })
_RNCNvXs_NtCsgAmdbuUjTpV_6memchr6memchrNtB6_6MemchrNtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4next0Csa7QYSr9aLYT_9quick_xml:
  322|  1.19M|            self.it.next(|s, e| memchr_raw(self.needle1, s, e))
_RNvMs2_NtCsgAmdbuUjTpV_6memchr6memchrNtB5_7Memchr23newCsa7QYSr9aLYT_9quick_xml:
  377|  3.76k|    pub fn new(needle1: u8, needle2: u8, haystack: &'h [u8]) -> Memchr2<'h> {
  378|  3.76k|        Memchr2 {
  379|  3.76k|            needle1,
  380|  3.76k|            needle2,
  381|  3.76k|            it: crate::arch::generic::memchr::Iter::new(haystack),
  382|  3.76k|        }
  383|  3.76k|    }
_RNvNtCsgAmdbuUjTpV_6memchr6memchr10memchr_rawCsa7QYSr9aLYT_9quick_xml:
  504|  1.19M|unsafe fn memchr_raw(
  505|  1.19M|    needle: u8,
  506|  1.19M|    start: *const u8,
  507|  1.19M|    end: *const u8,
  508|  1.19M|) -> Option<*const u8> {
  509|  1.19M|    #[cfg(target_arch = "x86_64")]
  510|  1.19M|    {
  511|  1.19M|        // x86_64 does CPU feature detection at runtime in order to use AVX2
  512|  1.19M|        // instructions even when the `avx2` feature isn't enabled at compile
  513|  1.19M|        // time. This function also handles using a fallback if neither AVX2
  514|  1.19M|        // nor SSE2 (unusual) are available.
  515|  1.19M|        crate::arch::x86_64::memchr::memchr_raw(needle, start, end)
  516|  1.19M|    }
  517|  1.19M|    #[cfg(all(target_arch = "wasm32", target_feature = "simd128"))]
  518|  1.19M|    {
  519|  1.19M|        crate::arch::wasm32::memchr::memchr_raw(needle, start, end)
  520|  1.19M|    }
  521|  1.19M|    #[cfg(target_arch = "aarch64")]
  522|  1.19M|    {
  523|  1.19M|        crate::arch::aarch64::memchr::memchr_raw(needle, start, end)
  524|  1.19M|    }
  525|  1.19M|    #[cfg(not(any(
  526|  1.19M|        target_arch = "x86_64",
  527|  1.19M|        all(target_arch = "wasm32", target_feature = "simd128"),
  528|  1.19M|        target_arch = "aarch64"
  529|  1.19M|    )))]
  530|  1.19M|    {
  531|  1.19M|        crate::arch::all::memchr::One::new(needle).find_raw(start, end)
  532|  1.19M|    }
  533|  1.19M|}
_RNvNtCsgAmdbuUjTpV_6memchr6memchr11memchr2_rawCsa7QYSr9aLYT_9quick_xml:
  574|   271k|unsafe fn memchr2_raw(
  575|   271k|    needle1: u8,
  576|   271k|    needle2: u8,
  577|   271k|    start: *const u8,
  578|   271k|    end: *const u8,
  579|   271k|) -> Option<*const u8> {
  580|   271k|    #[cfg(target_arch = "x86_64")]
  581|   271k|    {
  582|   271k|        crate::arch::x86_64::memchr::memchr2_raw(needle1, needle2, start, end)
  583|   271k|    }
  584|   271k|    #[cfg(all(target_arch = "wasm32", target_feature = "simd128"))]
  585|   271k|    {
  586|   271k|        crate::arch::wasm32::memchr::memchr2_raw(needle1, needle2, start, end)
  587|   271k|    }
  588|   271k|    #[cfg(target_arch = "aarch64")]
  589|   271k|    {
  590|   271k|        crate::arch::aarch64::memchr::memchr2_raw(needle1, needle2, start, end)
  591|   271k|    }
  592|   271k|    #[cfg(not(any(
  593|   271k|        target_arch = "x86_64",
  594|   271k|        all(target_arch = "wasm32", target_feature = "simd128"),
  595|   271k|        target_arch = "aarch64"
  596|   271k|    )))]
  597|   271k|    {
  598|   271k|        crate::arch::all::memchr::Two::new(needle1, needle2)
  599|   271k|            .find_raw(start, end)
  600|   271k|    }
  601|   271k|}
_RNvNtCsgAmdbuUjTpV_6memchr6memchr11memchr3_rawCsa7QYSr9aLYT_9quick_xml:
  646|  8.71k|unsafe fn memchr3_raw(
  647|  8.71k|    needle1: u8,
  648|  8.71k|    needle2: u8,
  649|  8.71k|    needle3: u8,
  650|  8.71k|    start: *const u8,
  651|  8.71k|    end: *const u8,
  652|  8.71k|) -> Option<*const u8> {
  653|  8.71k|    #[cfg(target_arch = "x86_64")]
  654|  8.71k|    {
  655|  8.71k|        crate::arch::x86_64::memchr::memchr3_raw(
  656|  8.71k|            needle1, needle2, needle3, start, end,
  657|  8.71k|        )
  658|  8.71k|    }
  659|  8.71k|    #[cfg(all(target_arch = "wasm32", target_feature = "simd128"))]
  660|  8.71k|    {
  661|  8.71k|        crate::arch::wasm32::memchr::memchr3_raw(
  662|  8.71k|            needle1, needle2, needle3, start, end,
  663|  8.71k|        )
  664|  8.71k|    }
  665|  8.71k|    #[cfg(target_arch = "aarch64")]
  666|  8.71k|    {
  667|  8.71k|        crate::arch::aarch64::memchr::memchr3_raw(
  668|  8.71k|            needle1, needle2, needle3, start, end,
  669|  8.71k|        )
  670|  8.71k|    }
  671|  8.71k|    #[cfg(not(any(
  672|  8.71k|        target_arch = "x86_64",
  673|  8.71k|        all(target_arch = "wasm32", target_feature = "simd128"),
  674|  8.71k|        target_arch = "aarch64"
  675|  8.71k|    )))]
  676|  8.71k|    {
  677|  8.71k|        crate::arch::all::memchr::Three::new(needle1, needle2, needle3)
  678|  8.71k|            .find_raw(start, end)
  679|  8.71k|    }
  680|  8.71k|}
_RNvNtCsgAmdbuUjTpV_6memchr6memchr12memchr2_iterCsa7QYSr9aLYT_9quick_xml:
  232|  3.76k|pub fn memchr2_iter<'h>(
  233|  3.76k|    needle1: u8,
  234|  3.76k|    needle2: u8,
  235|  3.76k|    haystack: &'h [u8],
  236|  3.76k|) -> Memchr2<'h> {
  237|  3.76k|    Memchr2::new(needle1, needle2, haystack)
  238|  3.76k|}
_RNvXs3_NtCsgAmdbuUjTpV_6memchr6memchrNtB5_7Memchr2NtNtNtNtCshZc3FwCJ069_4core4iter6traits8iterator8Iterator4nextCsa7QYSr9aLYT_9quick_xml:
  390|   180k|    fn next(&mut self) -> Option<usize> {
  391|   180k|        // SAFETY: All of our implementations of memchr ensure that any
  392|   180k|        // pointers returns will fall within the start and end bounds, and this
  393|   180k|        // upholds the safety contract of `self.it.next`.
  394|   180k|        unsafe {
  395|   180k|            self.it.next(|s, e| memchr2_raw(self.needle1, self.needle2, s, e))
  396|   180k|        }
  397|   180k|    }
_RNCNvNtCsgAmdbuUjTpV_6memchr6memchr6memchr0B5_:
   31|   676k|        generic::search_slice_with_raw(haystack, |start, end| {
   32|   676k|            memchr_raw(needle, start, end)
   33|   676k|        })
_RNvNtCsgAmdbuUjTpV_6memchr6memchr10memchr_rawB3_:
  504|   676k|unsafe fn memchr_raw(
  505|   676k|    needle: u8,
  506|   676k|    start: *const u8,
  507|   676k|    end: *const u8,
  508|   676k|) -> Option<*const u8> {
  509|   676k|    #[cfg(target_arch = "x86_64")]
  510|   676k|    {
  511|   676k|        // x86_64 does CPU feature detection at runtime in order to use AVX2
  512|   676k|        // instructions even when the `avx2` feature isn't enabled at compile
  513|   676k|        // time. This function also handles using a fallback if neither AVX2
  514|   676k|        // nor SSE2 (unusual) are available.
  515|   676k|        crate::arch::x86_64::memchr::memchr_raw(needle, start, end)
  516|   676k|    }
  517|   676k|    #[cfg(all(target_arch = "wasm32", target_feature = "simd128"))]
  518|   676k|    {
  519|   676k|        crate::arch::wasm32::memchr::memchr_raw(needle, start, end)
  520|   676k|    }
  521|   676k|    #[cfg(target_arch = "aarch64")]
  522|   676k|    {
  523|   676k|        crate::arch::aarch64::memchr::memchr_raw(needle, start, end)
  524|   676k|    }
  525|   676k|    #[cfg(not(any(
  526|   676k|        target_arch = "x86_64",
  527|   676k|        all(target_arch = "wasm32", target_feature = "simd128"),
  528|   676k|        target_arch = "aarch64"
  529|   676k|    )))]
  530|   676k|    {
  531|   676k|        crate::arch::all::memchr::One::new(needle).find_raw(start, end)
  532|   676k|    }
  533|   676k|}

_RNvYNtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iNtNtCsgAmdbuUjTpV_6memchr6vector6Vector27movemask_will_have_non_zeroBS_:
   63|  33.5k|    unsafe fn movemask_will_have_non_zero(self) -> bool {
   64|  33.5k|        self.movemask().has_non_zero()
   65|  33.5k|    }
_RNvMNtCsgAmdbuUjTpV_6memchr6vectorNtB2_16SensibleMoveMask14get_for_offset:
  126|  2.09M|    fn get_for_offset(self) -> u32 {
  127|  2.09M|        #[cfg(target_endian = "big")]
  128|  2.09M|        {
  129|  2.09M|            self.0.swap_bytes()
  130|  2.09M|        }
  131|  2.09M|        #[cfg(target_endian = "little")]
  132|  2.09M|        {
  133|  2.09M|            self.0
  134|  2.09M|        }
  135|  2.09M|    }
_RNvXs_NtCsgAmdbuUjTpV_6memchr6vectorNtB4_16SensibleMoveMaskNtB4_8MoveMask12has_non_zero:
  146|  2.17M|    fn has_non_zero(self) -> bool {
  147|  2.17M|        self.0 != 0
  148|  2.17M|    }
_RNvXs_NtCsgAmdbuUjTpV_6memchr6vectorNtB4_16SensibleMoveMaskNtB4_8MoveMask12first_offset:
  171|  2.09M|    fn first_offset(self) -> usize {
  172|  2.09M|        // We are dealing with little endian here (and if we aren't, we swap
  173|  2.09M|        // the bytes so we are in practice), where the most significant byte
  174|  2.09M|        // is at a higher address. That means the least significant bit that
  175|  2.09M|        // is set corresponds to the position of our first matching byte.
  176|  2.09M|        // That position corresponds to the number of zeros after the least
  177|  2.09M|        // significant bit.
  178|  2.09M|        self.get_for_offset().trailing_zeros() as usize
  179|  2.09M|    }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86sse2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iNtB4_6Vector8movemask:
  222|  80.1k|        unsafe fn movemask(self) -> SensibleMoveMask {
  223|  80.1k|            SensibleMoveMask(_mm_movemask_epi8(self) as u32)
  224|  80.1k|        }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86avx2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iNtB4_6Vector8movemask:
  271|  2.61M|        unsafe fn movemask(self) -> SensibleMoveMask {
  272|  2.61M|            SensibleMoveMask(_mm256_movemask_epi8(self) as u32)
  273|  2.61M|        }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86sse2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iNtB4_6Vector14load_unaligned:
  217|  55.3k|        unsafe fn load_unaligned(data: *const u8) -> __m128i {
  218|  55.3k|            _mm_loadu_si128(data as *const __m128i)
  219|  55.3k|        }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86sse2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iNtB4_6Vector5cmpeq:
  227|  69.0k|        unsafe fn cmpeq(self, vector2: Self) -> __m128i {
  228|  69.0k|            _mm_cmpeq_epi8(self, vector2)
  229|  69.0k|        }
_RNvXs_NtCsgAmdbuUjTpV_6memchr6vectorNtB4_16SensibleMoveMaskNtB4_8MoveMask2or:
  161|   264k|    fn or(self, other: SensibleMoveMask) -> SensibleMoveMask {
  162|   264k|        SensibleMoveMask(self.0 | other.0)
  163|   264k|    }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86sse2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iNtB4_6Vector5splat:
  207|  2.44M|        unsafe fn splat(byte: u8) -> __m128i {
  208|  2.44M|            _mm_set1_epi8(byte as i8)
  209|  2.44M|        }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86sse2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m128iNtB4_6Vector2or:
  237|  13.7k|        unsafe fn or(self, vector2: Self) -> __m128i {
  238|  13.7k|            _mm_or_si128(self, vector2)
  239|  13.7k|        }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86avx2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iNtB4_6Vector14load_unaligned:
  266|  2.04M|        unsafe fn load_unaligned(data: *const u8) -> __m256i {
  267|  2.04M|            _mm256_loadu_si256(data as *const __m256i)
  268|  2.04M|        }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86avx2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iNtB4_6Vector5cmpeq:
  276|  2.44M|        unsafe fn cmpeq(self, vector2: Self) -> __m256i {
  277|  2.44M|            _mm256_cmpeq_epi8(self, vector2)
  278|  2.44M|        }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86avx2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iNtB4_6Vector5splat:
  256|  2.44M|        unsafe fn splat(byte: u8) -> __m256i {
  257|  2.44M|            _mm256_set1_epi8(byte as i8)
  258|  2.44M|        }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86avx2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iNtB4_6Vector12load_aligned:
  261|   116k|        unsafe fn load_aligned(data: *const u8) -> __m256i {
  262|   116k|            _mm256_load_si256(data as *const __m256i)
  263|   116k|        }
_RNvXNtNtCsgAmdbuUjTpV_6memchr6vector7x86avx2NtNtNtCshZc3FwCJ069_4core9core_arch3x867___m256iNtB4_6Vector2or:
  286|   358k|        unsafe fn or(self, vector2: Self) -> __m256i {
  287|   358k|            _mm256_or_si256(self, vector2)
  288|   358k|        }

_RNvMs2_NtCsjdbBOGgcNBY_9once_cell3impINtB5_8OnceCellNtNtCs8f6x4lOZV33_5alloc6string6StringE14is_initializedCsiqeAZnF9yJF_13libfuzzer_sys:
   49|  17.7k|    pub(crate) fn is_initialized(&self) -> bool {
   50|  17.7k|        // An `Acquire` load is enough because that makes all the initialization
   51|  17.7k|        // operations visible to us, and, this being a fast path, weaker
   52|  17.7k|        // ordering helps with performance. This `Acquire` synchronizes with
   53|  17.7k|        // `SeqCst` operations on the slow path.
   54|  17.7k|        self.queue.load(Ordering::Acquire) == COMPLETE_PTR
   55|  17.7k|    }

_RNvMs4_NtCsjdbBOGgcNBY_9once_cell4syncINtB5_8OnceCellNtNtCs8f6x4lOZV33_5alloc6string6StringE3getCsiqeAZnF9yJF_13libfuzzer_sys:
  963|  17.7k|        pub fn get(&self) -> Option<&T> {
  964|  17.7k|            if self.0.is_initialized() {
  965|       |                // Safe b/c value is initialized.
  966|      0|                Some(unsafe { self.get_unchecked() })
  967|       |            } else {
  968|  17.7k|                None
  969|       |            }
  970|  17.7k|        }

_RNvMs_NtCsa7QYSr9aLYT_9quick_xml8encodingNtB4_7Decoder6decode:
   82|  5.88k|    pub fn decode<'b>(&self, bytes: &'b [u8]) -> Result<Cow<'b, str>> {
   83|       |        #[cfg(not(feature = "encoding"))]
   84|  5.88k|        let decoded = Ok(Cow::Borrowed(std::str::from_utf8(bytes)?));
   85|       |
   86|       |        #[cfg(feature = "encoding")]
   87|       |        let decoded = decode(bytes, self.encoding);
   88|       |
   89|  4.41k|        decoded
   90|  5.88k|    }
_RNvMs_NtCsa7QYSr9aLYT_9quick_xml8encodingNtB4_7Decoder10decode_cow:
  104|  4.83k|    pub(crate) fn decode_cow<'b>(&self, bytes: &Cow<'b, [u8]>) -> Result<Cow<'b, str>> {
  105|  4.83k|        match bytes {
  106|  4.83k|            Cow::Borrowed(bytes) => self.decode(bytes),
  107|       |            // Convert to owned, because otherwise Cow will be bound with wrong lifetime
  108|      0|            Cow::Owned(bytes) => Ok(self.decode(bytes)?.into_owned().into()),
  109|       |        }
  110|  4.83k|    }

_RNvXs6_NtCsa7QYSr9aLYT_9quick_xml6errorsNtB5_5ErrorINtNtCshZc3FwCJ069_4core7convert4FromNtNtNtBS_3str5error9Utf8ErrorE4fromB7_:
  235|  1.46k|    fn from(error: Utf8Error) -> Error {
  236|  1.46k|        Error::NonDecodable(Some(error))
  237|  1.46k|    }
_RNvXs8_NtCsa7QYSr9aLYT_9quick_xml6errorsNtB5_5ErrorINtNtCshZc3FwCJ069_4core7convert4FromNtNtB7_6escape11EscapeErrorE4fromB7_:
  251|    541|    fn from(error: EscapeError) -> Error {
  252|    541|        Error::EscapeError(error)
  253|    541|    }

_RINvNtCsa7QYSr9aLYT_9quick_xml6escape13unescape_withNvB2_25resolve_predefined_entityEB4_:
  249|  3.76k|pub fn unescape_with<'input, 'entity, F>(
  250|  3.76k|    raw: &'input str,
  251|  3.76k|    mut resolve_entity: F,
  252|  3.76k|) -> Result<Cow<'input, str>, EscapeError>
  253|  3.76k|where
  254|  3.76k|    // the lifetime of the output comes from a capture or is `'static`
  255|  3.76k|    F: FnMut(&str) -> Option<&'entity str>,
  256|  3.76k|{
  257|  3.76k|    let bytes = raw.as_bytes();
  258|  3.76k|    let mut unescaped = None;
  259|  3.76k|    let mut last_end = 0;
  260|  3.76k|    let mut iter = memchr2_iter(b'&', b';', bytes);
  261|  86.9k|    while let Some(start) = iter.by_ref().find(|p| bytes[*p] == b'&') {
  262|  83.6k|        match iter.next() {
  263|  83.3k|            Some(end) if bytes[end] == b';' => {
  264|  83.3k|                // append valid data
  265|  83.3k|                if unescaped.is_none() {
  266|  1.42k|                    unescaped = Some(String::with_capacity(raw.len()));
  267|  81.9k|                }
  268|  83.3k|                let unescaped = unescaped.as_mut().expect("initialized");
  269|  83.3k|                unescaped.push_str(&raw[last_end..start]);
  270|  83.3k|
  271|  83.3k|                // search for character correctness
  272|  83.3k|                let pat = &raw[start + 1..end];
  273|  83.3k|                if let Some(entity) = pat.strip_prefix('#') {
  274|  70.1k|                    let codepoint = parse_number(entity).map_err(EscapeError::InvalidCharRef)?;
  275|  70.0k|                    unescaped.push_str(codepoint.encode_utf8(&mut [0u8; 4]));
  276|  13.2k|                } else if let Some(value) = resolve_entity(pat) {
  277|  13.1k|                    unescaped.push_str(value);
  278|  13.1k|                } else {
  279|     94|                    return Err(EscapeError::UnrecognizedEntity(
  280|     94|                        start + 1..end,
  281|     94|                        pat.to_string(),
  282|     94|                    ));
  283|       |                }
  284|       |
  285|  83.1k|                last_end = end + 1;
  286|       |            }
  287|    322|            _ => return Err(EscapeError::UnterminatedEntity(start..raw.len())),
  288|       |        }
  289|       |    }
  290|       |
  291|  3.22k|    if let Some(mut unescaped) = unescaped {
  292|  1.08k|        if let Some(raw) = raw.get(last_end..) {
  293|  1.08k|            unescaped.push_str(raw);
  294|  1.08k|        }
  295|  1.08k|        Ok(Cow::Owned(unescaped))
  296|       |    } else {
  297|  2.13k|        Ok(Cow::Borrowed(raw))
  298|       |    }
  299|  3.76k|}
_RNCINvNtCsa7QYSr9aLYT_9quick_xml6escape13unescape_withNvB4_25resolve_predefined_entityE0B6_:
  261|  93.8k|    while let Some(start) = iter.by_ref().find(|p| bytes[*p] == b'&') {
_RNvNtCsa7QYSr9aLYT_9quick_xml6escape25resolve_predefined_entityB3_:
  307|  13.2k|pub const fn resolve_predefined_entity(entity: &str) -> Option<&'static str> {
  308|  13.2k|    #[cfg(not(feature = "escape-html"))]
  309|  13.2k|    {
  310|  13.2k|        resolve_xml_entity(entity)
  311|  13.2k|    }
  312|  13.2k|
  313|  13.2k|    #[cfg(feature = "escape-html")]
  314|  13.2k|    {
  315|  13.2k|        resolve_html5_entity(entity)
  316|  13.2k|    }
  317|  13.2k|}
_RNvNtCsa7QYSr9aLYT_9quick_xml6escape18resolve_xml_entity:
  337|  13.2k|pub const fn resolve_xml_entity(entity: &str) -> Option<&'static str> {
  338|       |    // match over strings are not allowed in const functions
  339|  13.2k|    let s = match entity.as_bytes() {
  340|  13.2k|        b"lt" => "<",
  341|  3.11k|        b"gt" => ">",
  342|  7.71k|        b"amp" => "&",
  343|  7.08k|        b"apos" => "'",
  344|    578|        b"quot" => "\"",
  345|     94|        _ => return None,
  346|       |    };
  347|  13.1k|    Some(s)
  348|  13.2k|}
_RNvNtCsa7QYSr9aLYT_9quick_xml6escape12parse_number:
 1819|  70.1k|fn parse_number(num: &str) -> Result<char, ParseCharRefError> {
 1820|  70.1k|    let code = if let Some(hex) = num.strip_prefix('x') {
 1821|  25.3k|        from_str_radix(hex, 16)?
 1822|       |    } else {
 1823|  44.8k|        from_str_radix(num, 10)?
 1824|       |    };
 1825|  70.0k|    if code == 0 {
 1826|      2|        return Err(ParseCharRefError::IllegalCharacter(code));
 1827|  70.0k|    }
 1828|  70.0k|    match std::char::from_u32(code) {
 1829|  70.0k|        Some(c) => Ok(c),
 1830|     14|        None => Err(ParseCharRefError::InvalidCodepoint(code)),
 1831|       |    }
 1832|  70.1k|}
_RNvNtCsa7QYSr9aLYT_9quick_xml6escape14from_str_radixB3_:
 1835|  70.1k|fn from_str_radix(src: &str, radix: u32) -> Result<u32, ParseCharRefError> {
 1836|  70.1k|    match src.as_bytes().first().copied() {
 1837|       |        // We should not allow sign numbers, but u32::from_str_radix will accept `+`.
 1838|       |        // We also handle `-` to be consistent in returned errors
 1839|     54|        Some(b'+') | Some(b'-') => Err(ParseCharRefError::UnexpectedSign),
 1840|  70.0k|        _ => u32::from_str_radix(src, radix).map_err(ParseCharRefError::InvalidNumber),
 1841|       |    }
 1842|  70.1k|}

_RNvMNtCsa7QYSr9aLYT_9quick_xml6eventsNtB2_10BytesStart10local_nameCskRNNzwwh1bl_10sparesults:
  203|    707|    pub fn local_name(&self) -> LocalName {
  204|    707|        self.name().into()
  205|    707|    }
_RNvMNtCsa7QYSr9aLYT_9quick_xml6eventsNtB2_10BytesStart4nameCskRNNzwwh1bl_10sparesults:
  194|  1.41k|    pub fn name(&self) -> QName {
  195|  1.41k|        QName(&self.buf[..self.name_len])
  196|  1.41k|    }
_RNvMNtCsa7QYSr9aLYT_9quick_xml6eventsNtB2_10BytesStart4wrapB4_:
  102|   622k|    pub(crate) const fn wrap(content: &'a [u8], name_len: usize) -> Self {
  103|   622k|        BytesStart {
  104|   622k|            buf: Cow::Borrowed(content),
  105|   622k|            name_len,
  106|   622k|        }
  107|   622k|    }
_RNvMNtCsa7QYSr9aLYT_9quick_xml6eventsNtB2_10BytesStart4nameB4_:
  194|    707|    pub fn name(&self) -> QName {
  195|    707|        QName(&self.buf[..self.name_len])
  196|    707|    }
_RINvMs7_NtCsa7QYSr9aLYT_9quick_xml6eventsNtB6_9BytesText4wrapRShEB8_:
  537|  46.4k|    pub(crate) fn wrap<C: Into<Cow<'a, [u8]>>>(content: C, decoder: Decoder) -> Self {
  538|  46.4k|        Self {
  539|  46.4k|            content: content.into(),
  540|  46.4k|            decoder,
  541|  46.4k|        }
  542|  46.4k|    }
_RNvMs7_NtCsa7QYSr9aLYT_9quick_xml6eventsNtB5_9BytesText8unescape:
  586|  4.83k|    pub fn unescape(&self) -> Result<Cow<'a, str>> {
  587|  4.83k|        self.unescape_with(resolve_predefined_entity)
  588|  4.83k|    }
_RINvMs7_NtCsa7QYSr9aLYT_9quick_xml6eventsNtB6_9BytesText13unescape_withNvNtB8_6escape25resolve_predefined_entityEB8_:
  594|  4.83k|    pub fn unescape_with<'entity>(
  595|  4.83k|        &self,
  596|  4.83k|        resolve_entity: impl FnMut(&str) -> Option<&'entity str>,
  597|  4.83k|    ) -> Result<Cow<'a, str>> {
  598|  4.83k|        let decoded = self.decoder.decode_cow(&self.content)?;
  599|       |
  600|  3.76k|        match unescape_with(&decoded, resolve_entity)? {
  601|       |            // Because result is borrowed, no replacements was done and we can use original string
  602|  2.13k|            Cow::Borrowed(_) => Ok(decoded),
  603|  1.08k|            Cow::Owned(s) => Ok(s.into()),
  604|       |        }
  605|  4.83k|    }
_RNvXs9_NtCsa7QYSr9aLYT_9quick_xml6eventsNtB5_9BytesTextNtNtNtCshZc3FwCJ069_4core3ops5deref5Deref5deref:
  638|  6.25k|    fn deref(&self) -> &[u8] {
  639|  6.25k|        &self.content
  640|  6.25k|    }
_RINvMsa_NtCsa7QYSr9aLYT_9quick_xml6eventsNtB6_10BytesCData4wrapRShEB8_:
  692|      5|    pub(crate) fn wrap<C: Into<Cow<'a, [u8]>>>(content: C, decoder: Decoder) -> Self {
  693|      5|        Self {
  694|      5|            content: content.into(),
  695|      5|            decoder,
  696|      5|        }
  697|      5|    }
_RNvMsd_NtCsa7QYSr9aLYT_9quick_xml6eventsNtB5_7BytesPI4wrapB7_:
  872|   461k|    pub(crate) const fn wrap(content: &'a [u8], target_len: usize) -> Self {
  873|   461k|        Self {
  874|   461k|            content: BytesStart::wrap(content, target_len),
  875|   461k|        }
  876|   461k|    }
_RNvMsg_NtCsa7QYSr9aLYT_9quick_xml6eventsNtB5_9BytesDecl10from_start:
 1089|   160k|    pub const fn from_start(start: BytesStart<'a>) -> Self {
 1090|   160k|        Self { content: start }
 1091|   160k|    }

_RNvMNtCsa7QYSr9aLYT_9quick_xml4nameNtB2_5QName5index:
  110|    707|    fn index(&self) -> Option<usize> {
  111|    707|        memchr(b':', self.0)
  112|    707|    }
_RNvXs0_NtCsa7QYSr9aLYT_9quick_xml4nameNtB5_5QNameINtNtCshZc3FwCJ069_4core7convert5AsRefShE6as_refCskRNNzwwh1bl_10sparesults:
  123|    707|    fn as_ref(&self) -> &[u8] {
  124|    707|        self.0
  125|    707|    }
_RNvXs3_NtCsa7QYSr9aLYT_9quick_xml4nameNtB5_9LocalNameINtNtCshZc3FwCJ069_4core7convert5AsRefShE6as_refCskRNNzwwh1bl_10sparesults:
  153|    707|    fn as_ref(&self) -> &[u8] {
  154|    707|        self.0
  155|    707|    }
_RNvXs4_NtCsa7QYSr9aLYT_9quick_xml4nameNtB5_9LocalNameINtNtCshZc3FwCJ069_4core7convert4FromNtB5_5QNameE4fromCskRNNzwwh1bl_10sparesults:
  172|    707|    fn from(name: QName<'a>) -> Self {
  173|    707|        Self(name.index().map_or(name.0, |i| &name.0[i + 1..]))
  174|    707|    }
_RNCNvXs4_NtCsa7QYSr9aLYT_9quick_xml4nameNtB7_9LocalNameINtNtCshZc3FwCJ069_4core7convert4FromNtB7_5QNameE4from0CskRNNzwwh1bl_10sparesults:
  173|      6|        Self(name.index().map_or(name.0, |i| &name.0[i + 1..]))
_RNvXs0_NtCsa7QYSr9aLYT_9quick_xml4nameNtB5_5QNameINtNtCshZc3FwCJ069_4core7convert5AsRefShE6as_refB7_:
  123|    707|    fn as_ref(&self) -> &[u8] {
  124|    707|        self.0
  125|    707|    }

_RNvXNtNtCsa7QYSr9aLYT_9quick_xml6parser7elementNtB2_13ElementParserNtB4_6Parser4feedCskRNNzwwh1bl_10sparesults:
   57|  2.23k|    fn feed(&mut self, bytes: &[u8]) -> Option<usize> {
   58|  7.52k|        for i in memchr::memchr3_iter(b'>', b'\'', b'"', bytes) {
   59|  7.52k|            *self = match (*self, bytes[i]) {
   60|       |                // only allowed to match `>` while we are in state `Outside`
   61|  1.04k|                (Self::Outside, b'>') => return Some(i),
   62|  1.73k|                (Self::Outside, b'\'') => Self::SingleQ,
   63|    440|                (Self::Outside, b'\"') => Self::DoubleQ,
   64|       |
   65|       |                // the only end_byte that gets us out if the same character
   66|  1.97k|                (Self::SingleQ, b'\'') | (Self::DoubleQ, b'"') => Self::Outside,
   67|       |
   68|       |                // all other bytes: no state change
   69|  2.33k|                _ => continue,
   70|       |            };
   71|       |        }
   72|  1.19k|        None
   73|  2.23k|    }
_RNvXNtNtCsa7QYSr9aLYT_9quick_xml6parser7elementNtB2_13ElementParserNtB4_6Parser9eof_errorCskRNNzwwh1bl_10sparesults:
   76|  1.19k|    fn eof_error() -> SyntaxError {
   77|  1.19k|        SyntaxError::UnclosedTag
   78|  1.19k|    }

_RNvXNtNtCsa7QYSr9aLYT_9quick_xml6parser2piNtB2_8PiParserNtB4_6Parser4feedCskRNNzwwh1bl_10sparesults:
   61|   627k|    fn feed(&mut self, bytes: &[u8]) -> Option<usize> {
   62|  1.13M|        for i in memchr::memchr_iter(b'>', bytes) {
   63|  1.13M|            match i {
   64|      0|                0 if self.0 => return Some(0),
   65|       |                // If the previous byte is `?`, then we found `?>`
   66|  1.13M|                i if i > 0 && bytes[i - 1] == b'?' => return Some(i),
   67|   509k|                _ => {}
   68|       |            }
   69|       |        }
   70|  5.28k|        self.0 = bytes.last().copied() == Some(b'?');
   71|  5.28k|        None
   72|   627k|    }
_RNvXNtNtCsa7QYSr9aLYT_9quick_xml6parser2piNtB2_8PiParserNtB4_6Parser9eof_errorCskRNNzwwh1bl_10sparesults:
   75|  5.28k|    fn eof_error() -> SyntaxError {
   76|  5.28k|        SyntaxError::UnclosedPIOrXmlDecl
   77|  5.28k|    }

_RNvMs_NtNtCsa7QYSr9aLYT_9quick_xml6reader15buffered_readerINtB6_6ReaderRShE15read_event_intoCskRNNzwwh1bl_10sparesults:
  293|   678k|    pub fn read_event_into<'b>(&mut self, buf: &'b mut Vec<u8>) -> Result<Event<'b>> {
  294|   678k|        self.read_event_impl(buf)
  295|   678k|    }
_RINvXNtNtCsa7QYSr9aLYT_9quick_xml6reader15buffered_readerRShINtB5_9XmlSourceQINtNtCs8f6x4lOZV33_5alloc3vec3VechEE9read_withNtNtNtB7_6parser2pi8PiParserECskRNNzwwh1bl_10sparesults:
  105|   627k|        $($async)? fn read_with<$($lf,)? P: Parser>(
  106|   627k|            &mut self,
  107|   627k|            mut parser: P,
  108|   627k|            buf: &'b mut Vec<u8>,
  109|   627k|            position: &mut u64,
  110|   627k|        ) -> Result<&'b [u8]> {
  111|   627k|            let mut read = 0;
  112|   627k|            let start = buf.len();
  113|       |            loop {
  114|   632k|                let available = match self $(.$reader)? .fill_buf() $(.$await)? {
  115|   632k|                    Ok(n) if n.is_empty() => break,
  116|   627k|                    Ok(n) => n,
  117|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
  118|      0|                    Err(e) => {
  119|      0|                        *position += read;
  120|      0|                        return Err(Error::Io(e.into()));
  121|       |                    }
  122|       |                };
  123|       |
  124|   627k|                if let Some(i) = parser.feed(available) {
  125|   621k|                    buf.extend_from_slice(&available[..i]);
  126|   621k|
  127|   621k|                    // +1 for `>` which we do not include
  128|   621k|                    self $(.$reader)? .consume(i + 1);
  129|   621k|                    read += i as u64 + 1;
  130|   621k|
  131|   621k|                    *position += read;
  132|   621k|                    return Ok(&buf[start..]);
  133|  5.28k|                }
  134|  5.28k|
  135|  5.28k|                // The `>` symbol not yet found, continue reading
  136|  5.28k|                buf.extend_from_slice(available);
  137|  5.28k|
  138|  5.28k|                let used = available.len();
  139|  5.28k|                self $(.$reader)? .consume(used);
  140|  5.28k|                read += used as u64;
  141|       |            }
  142|       |
  143|  5.28k|            *position += read;
  144|  5.28k|            Err(Error::Syntax(P::eof_error()))
  145|   627k|        }
_RINvXNtNtCsa7QYSr9aLYT_9quick_xml6reader15buffered_readerRShINtB5_9XmlSourceQINtNtCs8f6x4lOZV33_5alloc3vec3VechEE9read_withNtNtNtB7_6parser7element13ElementParserECskRNNzwwh1bl_10sparesults:
  105|  2.23k|        $($async)? fn read_with<$($lf,)? P: Parser>(
  106|  2.23k|            &mut self,
  107|  2.23k|            mut parser: P,
  108|  2.23k|            buf: &'b mut Vec<u8>,
  109|  2.23k|            position: &mut u64,
  110|  2.23k|        ) -> Result<&'b [u8]> {
  111|  2.23k|            let mut read = 0;
  112|  2.23k|            let start = buf.len();
  113|       |            loop {
  114|  3.42k|                let available = match self $(.$reader)? .fill_buf() $(.$await)? {
  115|  3.42k|                    Ok(n) if n.is_empty() => break,
  116|  2.23k|                    Ok(n) => n,
  117|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
  118|      0|                    Err(e) => {
  119|      0|                        *position += read;
  120|      0|                        return Err(Error::Io(e.into()));
  121|       |                    }
  122|       |                };
  123|       |
  124|  2.23k|                if let Some(i) = parser.feed(available) {
  125|  1.04k|                    buf.extend_from_slice(&available[..i]);
  126|  1.04k|
  127|  1.04k|                    // +1 for `>` which we do not include
  128|  1.04k|                    self $(.$reader)? .consume(i + 1);
  129|  1.04k|                    read += i as u64 + 1;
  130|  1.04k|
  131|  1.04k|                    *position += read;
  132|  1.04k|                    return Ok(&buf[start..]);
  133|  1.19k|                }
  134|  1.19k|
  135|  1.19k|                // The `>` symbol not yet found, continue reading
  136|  1.19k|                buf.extend_from_slice(available);
  137|  1.19k|
  138|  1.19k|                let used = available.len();
  139|  1.19k|                self $(.$reader)? .consume(used);
  140|  1.19k|                read += used as u64;
  141|       |            }
  142|       |
  143|  1.19k|            *position += read;
  144|  1.19k|            Err(Error::Syntax(P::eof_error()))
  145|  2.23k|        }
_RNCNvXNtNtCsa7QYSr9aLYT_9quick_xml6reader15buffered_readerRShINtB6_9XmlSourceQINtNtCs8f6x4lOZV33_5alloc3vec3VechEE15skip_whitespace0CskRNNzwwh1bl_10sparesults:
  203|   966k|                        let count = n.iter().position(|b| !is_whitespace(*b)).unwrap_or(n.len());
_RNvXNtNtCsa7QYSr9aLYT_9quick_xml6reader15buffered_readerRShINtB4_9XmlSourceQINtNtCs8f6x4lOZV33_5alloc3vec3VechEE15remove_utf8_bomCskRNNzwwh1bl_10sparesults:
   19|  17.7k|        $($async)? fn remove_utf8_bom(&mut self) -> io::Result<()> {
   20|       |            use crate::encoding::UTF8_BOM;
   21|       |
   22|       |            loop {
   23|  17.7k|                break match self $(.$reader)? .fill_buf() $(.$await)? {
   24|  17.7k|                    Ok(n) => {
   25|  17.7k|                        if n.starts_with(UTF8_BOM) {
   26|    404|                            self $(.$reader)? .consume(UTF8_BOM.len());
   27|  17.3k|                        }
   28|  17.7k|                        Ok(())
   29|       |                    },
   30|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
   31|      0|                    Err(e) => Err(e),
   32|       |                };
   33|       |            }
   34|  17.7k|        }
_RNvXNtNtCsa7QYSr9aLYT_9quick_xml6reader15buffered_readerRShINtB4_9XmlSourceQINtNtCs8f6x4lOZV33_5alloc3vec3VechEE15skip_whitespaceCskRNNzwwh1bl_10sparesults:
  199|   678k|        $($async)? fn skip_whitespace(&mut self, position: &mut u64) -> io::Result<()> {
  200|       |            loop {
  201|   791k|                break match self $(.$reader)? .fill_buf() $(.$await)? {
  202|   791k|                    Ok(n) => {
  203|   791k|                        let count = n.iter().position(|b| !is_whitespace(*b)).unwrap_or(n.len());
  204|   791k|                        if count > 0 {
  205|   113k|                            self $(.$reader)? .consume(count);
  206|   113k|                            *position += count as u64;
  207|   113k|                            continue;
  208|       |                        } else {
  209|   678k|                            Ok(())
  210|       |                        }
  211|       |                    }
  212|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
  213|      0|                    Err(e) => Err(e),
  214|       |                };
  215|       |            }
  216|   678k|        }
_RNvXNtNtCsa7QYSr9aLYT_9quick_xml6reader15buffered_readerRShINtB4_9XmlSourceQINtNtCs8f6x4lOZV33_5alloc3vec3VechEE17read_bang_elementCskRNNzwwh1bl_10sparesults:
  148|  41.6k|        $($async)? fn read_bang_element $(<$lf>)? (
  149|  41.6k|            &mut self,
  150|  41.6k|            buf: &'b mut Vec<u8>,
  151|  41.6k|            position: &mut u64,
  152|  41.6k|        ) -> Result<(BangType, &'b [u8])> {
  153|  41.6k|            // Peeked one bang ('!') before being called, so it's guaranteed to
  154|  41.6k|            // start with it.
  155|  41.6k|            let start = buf.len();
  156|  41.6k|            let mut read = 1;
  157|  41.6k|            buf.push(b'!');
  158|  41.6k|            self $(.$reader)? .consume(1);
  159|       |
  160|  41.6k|            let mut bang_type = BangType::new(self.peek_one() $(.$await)? ?)?;
  161|       |
  162|       |            loop {
  163|  42.8k|                match self $(.$reader)? .fill_buf() $(.$await)? {
  164|       |                    // Note: Do not update position, so the error points to
  165|       |                    // somewhere sane rather than at the EOF
  166|  42.8k|                    Ok(n) if n.is_empty() => break,
  167|  41.5k|                    Ok(available) => {
  168|       |                        // We only parse from start because we don't want to consider
  169|       |                        // whatever is in the buffer before the bang element
  170|  41.5k|                        if let Some((consumed, used)) = bang_type.parse(&buf[start..], available) {
  171|  40.3k|                            buf.extend_from_slice(consumed);
  172|  40.3k|
  173|  40.3k|                            self $(.$reader)? .consume(used);
  174|  40.3k|                            read += used as u64;
  175|  40.3k|
  176|  40.3k|                            *position += read;
  177|  40.3k|                            return Ok((bang_type, &buf[start..]));
  178|  1.21k|                        } else {
  179|  1.21k|                            buf.extend_from_slice(available);
  180|  1.21k|
  181|  1.21k|                            let used = available.len();
  182|  1.21k|                            self $(.$reader)? .consume(used);
  183|  1.21k|                            read += used as u64;
  184|  1.21k|                        }
  185|       |                    }
  186|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
  187|      0|                    Err(e) => {
  188|      0|                        *position += read;
  189|      0|                        return Err(Error::Io(e.into()));
  190|       |                    }
  191|       |                }
  192|       |            }
  193|       |
  194|  1.21k|            *position += read;
  195|  1.21k|            Err(bang_type.to_err())
  196|  41.6k|        }
_RNvXNtNtCsa7QYSr9aLYT_9quick_xml6reader15buffered_readerRShINtB4_9XmlSourceQINtNtCs8f6x4lOZV33_5alloc3vec3VechEE8peek_oneCskRNNzwwh1bl_10sparesults:
  219|   712k|        $($async)? fn peek_one(&mut self) -> io::Result<Option<u8>> {
  220|       |            loop {
  221|   712k|                break match self $(.$reader)? .fill_buf() $(.$await)? {
  222|   712k|                    Ok(n) => Ok(n.first().cloned()),
  223|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
  224|      0|                    Err(e) => Err(e),
  225|       |                };
  226|       |            }
  227|   712k|        }
_RNvXNtNtCsa7QYSr9aLYT_9quick_xml6reader15buffered_readerRShINtB4_9XmlSourceQINtNtCs8f6x4lOZV33_5alloc3vec3VechEE9read_textCskRNNzwwh1bl_10sparesults:
   54|   678k|        $($async)? fn read_text $(<$lf>)? (
   55|   678k|            &mut self,
   56|   678k|            buf: &'b mut Vec<u8>,
   57|   678k|            position: &mut u64,
   58|   678k|        ) -> ReadTextResult<'b, &'b mut Vec<u8>> {
   59|   678k|            let mut read = 0;
   60|   678k|            let start = buf.len();
   61|       |            loop {
   62|   682k|                let available = match self $(.$reader)? .fill_buf() $(.$await)? {
   63|   682k|                    Ok(n) if n.is_empty() => break,
   64|   676k|                    Ok(n) => n,
   65|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
   66|      0|                    Err(e) => {
   67|      0|                        *position += read;
   68|      0|                        return ReadTextResult::Err(e);
   69|       |                    }
   70|       |                };
   71|       |
   72|   676k|                match memchr::memchr(b'<', available) {
   73|       |                    // Special handling is needed only on the first iteration.
   74|       |                    // On next iterations we already read something and should emit Text event
   75|   671k|                    Some(0) if read == 0 => {
   76|   671k|                        self $(.$reader)? .consume(1);
   77|   671k|                        *position += 1;
   78|   671k|                        return ReadTextResult::Markup(buf);
   79|       |                    }
   80|    931|                    Some(i) => {
   81|    931|                        buf.extend_from_slice(&available[..i]);
   82|    931|
   83|    931|                        let used = i + 1;
   84|    931|                        self $(.$reader)? .consume(used);
   85|    931|                        read += used as u64;
   86|    931|
   87|    931|                        *position += read;
   88|    931|                        return ReadTextResult::UpToMarkup(&buf[start..]);
   89|       |                    }
   90|  3.90k|                    None => {
   91|  3.90k|                        buf.extend_from_slice(available);
   92|  3.90k|
   93|  3.90k|                        let used = available.len();
   94|  3.90k|                        self $(.$reader)? .consume(used);
   95|  3.90k|                        read += used as u64;
   96|  3.90k|                    }
   97|       |                }
   98|       |            }
   99|       |
  100|  6.25k|            *position += read;
  101|  6.25k|            ReadTextResult::UpToEof(&buf[start..])
  102|   678k|        }

_RNvMNtCsa7QYSr9aLYT_9quick_xml6readerNtB2_6Config9trim_textCskRNNzwwh1bl_10sparesults:
  195|  17.7k|    pub fn trim_text(&mut self, trim: bool) {
  196|  17.7k|        self.trim_text_start = trim;
  197|  17.7k|        self.trim_text_end = trim;
  198|  17.7k|    }
_RNvMs6_NtCsa7QYSr9aLYT_9quick_xml6readerNtB5_8BangType6to_errCskRNNzwwh1bl_10sparesults:
 1104|  1.21k|    const fn to_err(&self) -> Error {
 1105|  1.21k|        match self {
 1106|     82|            Self::CData => Error::Syntax(SyntaxError::UnclosedCData),
 1107|    260|            Self::Comment => Error::Syntax(SyntaxError::UnclosedComment),
 1108|    875|            Self::DocType(_) => Error::Syntax(SyntaxError::UnclosedDoctype),
 1109|       |        }
 1110|  1.21k|    }
_RINvMs5_NtCsa7QYSr9aLYT_9quick_xml6readerINtB6_6ReaderRShE15read_event_implQINtNtCs8f6x4lOZV33_5alloc3vec3VechEECskRNNzwwh1bl_10sparesults:
  897|   678k|    fn read_event_impl<'i, B>(&mut self, mut buf: B) -> Result<Event<'i>>
  898|   678k|    where
  899|   678k|        R: XmlSource<'i, B>,
  900|   678k|    {
  901|  1.36M|        read_event_impl!(self, buf, self.reader, read_until_close)
  902|   678k|    }
_RINvMs5_NtCsa7QYSr9aLYT_9quick_xml6readerINtB6_6ReaderRShE16read_until_closeQINtNtCs8f6x4lOZV33_5alloc3vec3VechEECskRNNzwwh1bl_10sparesults:
  906|   671k|    fn read_until_close<'i, B>(&mut self, buf: B) -> Result<Event<'i>>
  907|   671k|    where
  908|   671k|        R: XmlSource<'i, B>,
  909|   671k|    {
  910|   671k|        read_until_close!(self, buf, self.reader)
  911|   671k|    }
_RNvMs6_NtCsa7QYSr9aLYT_9quick_xml6readerNtB5_8BangType3new:
 1027|  41.6k|    const fn new(byte: Option<u8>) -> Result<Self> {
 1028|  41.6k|        Ok(match byte {
 1029|     95|            Some(b'[') => Self::CData,
 1030|  33.2k|            Some(b'-') => Self::Comment,
 1031|  8.28k|            Some(b'D') | Some(b'd') => Self::DocType(0),
 1032|     36|            _ => return Err(Error::Syntax(SyntaxError::InvalidBangMarkup)),
 1033|       |        })
 1034|  41.6k|    }
_RNvMs6_NtCsa7QYSr9aLYT_9quick_xml6readerNtB5_8BangType5parse:
 1043|  41.5k|    fn parse<'b>(&mut self, buf: &[u8], chunk: &'b [u8]) -> Option<(&'b [u8], usize)> {
 1044|  41.5k|        match self {
 1045|       |            Self::Comment => {
 1046|  60.4k|                for i in memchr::memchr_iter(b'>', chunk) {
 1047|       |                    // Need to read at least 6 symbols (`!---->`) for properly finished comment
 1048|       |                    // <!----> - XML comment
 1049|       |                    //  012345 - i
 1050|  60.4k|                    if buf.len() + i > 4 {
 1051|  33.9k|                        if chunk[..i].ends_with(b"--") {
 1052|       |                            // We cannot strip last `--` from the buffer because we need it in case of
 1053|       |                            // check_comments enabled option. XML standard requires that comment
 1054|       |                            // will not end with `--->` sequence because this is a special case of
 1055|       |                            // `--` in the comment (https://www.w3.org/TR/xml11/#sec-comments)
 1056|  32.9k|                            return Some((&chunk[..i], i + 1)); // +1 for `>`
 1057|  1.01k|                        }
 1058|  1.01k|                        // End sequence `-|->` was splitted at |
 1059|  1.01k|                        //        buf --/   \-- chunk
 1060|  1.01k|                        if i == 1 && buf.ends_with(b"-") && chunk[0] == b'-' {
 1061|      0|                            return Some((&chunk[..i], i + 1)); // +1 for `>`
 1062|  1.01k|                        }
 1063|  1.01k|                        // End sequence `--|>` was splitted at |
 1064|  1.01k|                        //         buf --/   \-- chunk
 1065|  1.01k|                        if i == 0 && buf.ends_with(b"--") {
 1066|      0|                            return Some((&[], i + 1)); // +1 for `>`
 1067|  1.01k|                        }
 1068|  26.4k|                    }
 1069|       |                }
 1070|       |            }
 1071|       |            Self::CData => {
 1072|  1.74k|                for i in memchr::memchr_iter(b'>', chunk) {
 1073|  1.74k|                    if chunk[..i].ends_with(b"]]") {
 1074|     13|                        return Some((&chunk[..i], i + 1)); // +1 for `>`
 1075|  1.73k|                    }
 1076|  1.73k|                    // End sequence `]|]>` was splitted at |
 1077|  1.73k|                    //        buf --/   \-- chunk
 1078|  1.73k|                    if i == 1 && buf.ends_with(b"]") && chunk[0] == b']' {
 1079|      0|                        return Some((&chunk[..i], i + 1)); // +1 for `>`
 1080|  1.73k|                    }
 1081|  1.73k|                    // End sequence `]]|>` was splitted at |
 1082|  1.73k|                    //         buf --/   \-- chunk
 1083|  1.73k|                    if i == 0 && buf.ends_with(b"]]") {
 1084|      0|                        return Some((&[], i + 1)); // +1 for `>`
 1085|  1.73k|                    }
 1086|       |                }
 1087|       |            }
 1088|  8.28k|            Self::DocType(ref mut balance) => {
 1089|  90.1k|                for i in memchr::memchr2_iter(b'<', b'>', chunk) {
 1090|  90.1k|                    if chunk[i] == b'<' {
 1091|  42.8k|                        *balance += 1;
 1092|  42.8k|                    } else {
 1093|  47.3k|                        if *balance == 0 {
 1094|  7.41k|                            return Some((&chunk[..i], i + 1)); // +1 for `>`
 1095|  39.9k|                        }
 1096|  39.9k|                        *balance -= 1;
 1097|       |                    }
 1098|       |                }
 1099|       |            }
 1100|       |        }
 1101|  1.21k|        None
 1102|  41.5k|    }
_RNvXs_NtCsa7QYSr9aLYT_9quick_xml6readerNtB4_6ConfigNtNtCshZc3FwCJ069_4core7default7Default7default:
  211|  17.7k|    fn default() -> Self {
  212|  17.7k|        Self {
  213|  17.7k|            allow_unmatched_ends: false,
  214|  17.7k|            check_comments: false,
  215|  17.7k|            check_end_names: true,
  216|  17.7k|            expand_empty_elements: false,
  217|  17.7k|            trim_markup_names_in_closing_tags: true,
  218|  17.7k|            trim_text_start: false,
  219|  17.7k|            trim_text_end: false,
  220|  17.7k|        }
  221|  17.7k|    }
_RNvMs3_NtCsa7QYSr9aLYT_9quick_xml6readerINtB5_6ReaderRShE11from_readerB7_:
  697|  17.7k|    pub fn from_reader(reader: R) -> Self {
  698|  17.7k|        Self {
  699|  17.7k|            reader,
  700|  17.7k|            state: ReaderState::default(),
  701|  17.7k|        }
  702|  17.7k|    }
_RNvMs3_NtCsa7QYSr9aLYT_9quick_xml6readerINtB5_6ReaderRShE10config_mutB7_:
  710|  17.7k|    pub fn config_mut(&mut self) -> &mut Config {
  711|  17.7k|        &mut self.state.config
  712|  17.7k|    }
_RNvMs4_NtCsa7QYSr9aLYT_9quick_xml6readerINtB5_6ReaderRShE7decoderB7_:
  827|  17.7k|    pub const fn decoder(&self) -> Decoder {
  828|  17.7k|        self.state.decoder()
  829|  17.7k|    }
_RNvMs6_NtCsa7QYSr9aLYT_9quick_xml6readerNtB5_8BangType6to_errB7_:
 1104|  1.09k|    const fn to_err(&self) -> Error {
 1105|  1.09k|        match self {
 1106|      8|            Self::CData => Error::Syntax(SyntaxError::UnclosedCData),
 1107|     14|            Self::Comment => Error::Syntax(SyntaxError::UnclosedComment),
 1108|  1.07k|            Self::DocType(_) => Error::Syntax(SyntaxError::UnclosedDoctype),
 1109|       |        }
 1110|  1.09k|    }

_RNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB2_11ReaderState9emit_text:
   60|  7.18k|    pub fn emit_text<'b>(&mut self, bytes: &'b [u8]) -> BytesText<'b> {
   61|  7.18k|        let mut content = bytes;
   62|  7.18k|
   63|  7.18k|        if self.config.trim_text_end {
   64|  7.18k|            // Skip the ending '<'
   65|  7.18k|            let len = bytes
   66|  7.18k|                .iter()
   67|  7.18k|                .rposition(|&b| !is_whitespace(b))
   68|  7.18k|                .map_or(0, |p| p + 1);
   69|  7.18k|            content = &bytes[..len];
   70|  7.18k|        }
   71|  7.18k|        BytesText::wrap(content, self.decoder())
   72|  7.18k|    }
_RNCNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB4_11ReaderState9emit_text0B8_:
   67|  5.89k|                .rposition(|&b| !is_whitespace(b))
_RNCNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB4_11ReaderState9emit_texts_0B8_:
   68|  4.83k|                .map_or(0, |p| p + 1);
_RNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB2_11ReaderState9emit_bang:
   81|  40.3k|    pub fn emit_bang<'b>(&mut self, bang_type: BangType, buf: &'b [u8]) -> Result<Event<'b>> {
   82|  40.3k|        debug_assert_eq!(
   83|      0|            buf.first(),
   84|       |            Some(&b'!'),
   85|      0|            "CDATA, comment or DOCTYPE should start from '!'"
   86|       |        );
   87|       |
   88|  40.3k|        let uncased_starts_with = |string: &[u8], prefix: &[u8]| {
   89|       |            string.len() >= prefix.len() && string[..prefix.len()].eq_ignore_ascii_case(prefix)
   90|       |        };
   91|       |
   92|  40.3k|        let len = buf.len();
   93|     13|        match bang_type {
   94|  32.9k|            BangType::Comment if buf.starts_with(b"!--") => {
   95|  32.9k|                debug_assert!(buf.ends_with(b"--"));
   96|  32.9k|                if self.config.check_comments {
   97|       |                    // search if '--' not in comments
   98|      0|                    let mut haystack = &buf[3..len - 2];
   99|      0|                    let mut off = 0;
  100|      0|                    while let Some(p) = memchr::memchr(b'-', haystack) {
  101|      0|                        off += p + 1;
  102|      0|                        // if next byte after `-` is also `-`, return an error
  103|      0|                        if buf[3 + off] == b'-' {
  104|       |                            // Explanation of the magic:
  105|       |                            //
  106|       |                            // - `self.offset`` just after `>`,
  107|       |                            // - `buf` contains `!-- con--tent --`
  108|       |                            // - `p` is counted from byte after `<!--`
  109|       |                            //
  110|       |                            // <!-- con--tent -->:
  111|       |                            //  ~~~~~~~~~~~~~~~~ : - buf
  112|       |                            //   : ===========   : - zone of search (possible values of `p`)
  113|       |                            //   : |---p         : - p is counted from | (| is 0)
  114|       |                            //   : :   :         ^ - self.offset
  115|       |                            //   ^ :   :           - self.offset - len
  116|       |                            //     ^   :           - self.offset - len + 2
  117|       |                            //         ^           - self.offset - len + 2 + p
  118|      0|                            self.last_error_offset = self.offset - len as u64 + 2 + p as u64;
  119|      0|                            return Err(Error::IllFormed(IllFormedError::DoubleHyphenInComment));
  120|      0|                        }
  121|      0|                        // Continue search after single `-` (+1 to skip it)
  122|      0|                        haystack = &haystack[p + 1..];
  123|       |                    }
  124|  32.9k|                }
  125|  32.9k|                Ok(Event::Comment(BytesText::wrap(
  126|  32.9k|                    // Cut of `!--` and `--` from start and end
  127|  32.9k|                    &buf[3..len - 2],
  128|  32.9k|                    self.decoder(),
  129|  32.9k|                )))
  130|       |            }
  131|       |            // XML requires uppercase only:
  132|       |            // https://www.w3.org/TR/xml11/#sec-cdata-sect
  133|       |            // Even HTML5 required uppercase only:
  134|       |            // https://html.spec.whatwg.org/multipage/parsing.html#markup-declaration-open-state
  135|     13|            BangType::CData if buf.starts_with(b"![CDATA[") => {
  136|      5|                debug_assert!(buf.ends_with(b"]]"));
  137|      5|                Ok(Event::CData(BytesCData::wrap(
  138|      5|                    // Cut of `![CDATA[` and `]]` from start and end
  139|      5|                    &buf[8..len - 2],
  140|      5|                    self.decoder(),
  141|      5|                )))
  142|       |            }
  143|       |            // XML requires uppercase only, but we will check that on validation stage:
  144|       |            // https://www.w3.org/TR/xml11/#sec-prolog-dtd
  145|       |            // HTML5 allows mixed case for doctype declarations:
  146|       |            // https://html.spec.whatwg.org/multipage/parsing.html#markup-declaration-open-state
  147|  7.41k|            BangType::DocType(0) if uncased_starts_with(buf, b"!DOCTYPE") => {
  148|  6.33k|                match buf[8..].iter().position(|&b| !is_whitespace(b)) {
  149|  6.30k|                    Some(start) => Ok(Event::DocType(BytesText::wrap(
  150|  6.30k|                        // Cut of `!DOCTYPE` and any number of spaces from start
  151|  6.30k|                        &buf[8 + start..],
  152|  6.30k|                        self.decoder(),
  153|  6.30k|                    ))),
  154|       |                    None => {
  155|       |                        // Because we here, we at least read `<!DOCTYPE>` and offset after `>`.
  156|       |                        // We want report error at place where name is expected - this is just
  157|       |                        // before `>`
  158|     34|                        self.last_error_offset = self.offset - 1;
  159|     34|                        return Err(Error::IllFormed(IllFormedError::MissingDoctypeName));
  160|       |                    }
  161|       |                }
  162|       |            }
  163|       |            _ => {
  164|       |                // <!....>
  165|       |                //  ^^^^^ - `buf` does not contain `<` and `>`, but `self.offset` is after `>`.
  166|       |                // ^------- We report error at that position, so we need to subtract 2 and buf len
  167|  1.09k|                self.last_error_offset = self.offset - len as u64 - 2;
  168|  1.09k|                Err(bang_type.to_err())
  169|       |            }
  170|       |        }
  171|  40.3k|    }
_RNCNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB4_11ReaderState9emit_bang0B8_:
   88|  7.41k|        let uncased_starts_with = |string: &[u8], prefix: &[u8]| {
   89|  7.41k|            string.len() >= prefix.len() && string[..prefix.len()].eq_ignore_ascii_case(prefix)
   90|  7.41k|        };
_RNCNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB4_11ReaderState9emit_bangs_0B8_:
  148|  8.54k|                match buf[8..].iter().position(|&b| !is_whitespace(b)) {
_RNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB2_11ReaderState8emit_end:
  177|    335|    pub fn emit_end<'b>(&mut self, buf: &'b [u8]) -> Result<Event<'b>> {
  178|    335|        debug_assert_eq!(
  179|      0|            buf.first(),
  180|       |            Some(&b'/'),
  181|      0|            "closing tag should start from '/'"
  182|       |        );
  183|       |
  184|       |        // Strip the `/` character. `content` contains data between `</` and `>`
  185|    335|        let content = &buf[1..];
  186|       |        // XML standard permits whitespaces after the markup name in closing tags.
  187|       |        // Let's strip them from the buffer before comparing tag names.
  188|    335|        let name = if self.config.trim_markup_names_in_closing_tags {
  189|    335|            if let Some(pos_end_name) = content.iter().rposition(|&b| !is_whitespace(b)) {
  190|    231|                &content[..pos_end_name + 1]
  191|       |            } else {
  192|    104|                content
  193|       |            }
  194|       |        } else {
  195|      0|            content
  196|       |        };
  197|       |
  198|    335|        let decoder = self.decoder();
  199|    335|
  200|    335|        // Get the index in self.opened_buffer of the name of the last opened tag
  201|    335|        match self.opened_starts.pop() {
  202|      0|            Some(start) => {
  203|      0|                if self.config.check_end_names {
  204|      0|                    let expected = &self.opened_buffer[start..];
  205|      0|                    if name != expected {
  206|      0|                        let expected = decoder.decode(expected).unwrap_or_default().into_owned();
  207|      0|                        // #513: In order to allow error recovery we should drop content of the buffer
  208|      0|                        self.opened_buffer.truncate(start);
  209|      0|
  210|      0|                        // Report error at start of the end tag at `<` character
  211|      0|                        // -2 for `<` and `>`
  212|      0|                        self.last_error_offset = self.offset - buf.len() as u64 - 2;
  213|      0|                        return Err(Error::IllFormed(IllFormedError::MismatchedEndTag {
  214|      0|                            expected,
  215|      0|                            found: decoder.decode(name).unwrap_or_default().into_owned(),
  216|      0|                        }));
  217|      0|                    }
  218|      0|                }
  219|       |
  220|      0|                self.opened_buffer.truncate(start);
  221|       |            }
  222|       |            None => {
  223|    335|                if !self.config.allow_unmatched_ends {
  224|       |                    // Report error at start of the end tag at `<` character
  225|       |                    // -2 for `<` and `>`
  226|    335|                    self.last_error_offset = self.offset - buf.len() as u64 - 2;
  227|    335|                    return Err(Error::IllFormed(IllFormedError::UnmatchedEndTag(
  228|    335|                        decoder.decode(name).unwrap_or_default().into_owned(),
  229|    335|                    )));
  230|      0|                }
  231|       |            }
  232|       |        }
  233|       |
  234|      0|        Ok(Event::End(BytesEnd::wrap(name.into())))
  235|    335|    }
_RNCNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB4_11ReaderState8emit_end0B8_:
  189|  11.9k|            if let Some(pos_end_name) = content.iter().rposition(|&b| !is_whitespace(b)) {
_RNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB2_11ReaderState18emit_question_mark:
  241|   621k|    pub fn emit_question_mark<'b>(&mut self, buf: &'b [u8]) -> Result<Event<'b>> {
  242|   621k|        debug_assert!(buf.len() > 0);
  243|   621k|        debug_assert_eq!(buf[0], b'?');
  244|       |
  245|   621k|        let len = buf.len();
  246|   621k|        // We accept at least <??>
  247|   621k|        //                     ~~ - len = 2
  248|   621k|        if len > 1 && buf[len - 1] == b'?' {
  249|       |            // Cut of `?` and `?` from start and end
  250|   621k|            let content = &buf[1..len - 1];
  251|   621k|            let len = content.len();
  252|   621k|
  253|   621k|            if content.starts_with(b"xml") && (len == 3 || is_whitespace(content[3])) {
  254|   160k|                let event = BytesDecl::from_start(BytesStart::wrap(content, 3));
  255|   160k|
  256|   160k|                // Try getting encoding from the declaration event
  257|   160k|                #[cfg(feature = "encoding")]
  258|   160k|                if self.encoding.can_be_refined() {
  259|   160k|                    if let Some(encoding) = event.encoder() {
  260|   160k|                        self.encoding = EncodingRef::XmlDetected(encoding);
  261|   160k|                    }
  262|   160k|                }
  263|   160k|
  264|   160k|                Ok(Event::Decl(event))
  265|       |            } else {
  266|   461k|                Ok(Event::PI(BytesPI::wrap(content, name_len(content))))
  267|       |            }
  268|       |        } else {
  269|       |            // <?....EOF
  270|       |            //  ^^^^^ - `buf` does not contains `<`, but we want to report error at `<`,
  271|       |            //          so we move offset to it (-2 for `<` and `>`)
  272|    395|            self.last_error_offset = self.offset - len as u64 - 2;
  273|    395|            Err(Error::Syntax(SyntaxError::UnclosedPIOrXmlDecl))
  274|       |        }
  275|   621k|    }
_RNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB2_11ReaderState10emit_start:
  281|    707|    pub fn emit_start<'b>(&mut self, content: &'b [u8]) -> Event<'b> {
  282|    707|        if let Some(content) = content.strip_suffix(b"/") {
  283|       |            // This is self-closed tag `<something/>`
  284|     39|            let event = BytesStart::wrap(content, name_len(content));
  285|     39|
  286|     39|            if self.config.expand_empty_elements {
  287|     39|                self.state = ParseState::InsideEmpty;
  288|     39|                self.opened_starts.push(self.opened_buffer.len());
  289|     39|                self.opened_buffer.extend(event.name().as_ref());
  290|     39|                Event::Start(event)
  291|       |            } else {
  292|      0|                Event::Empty(event)
  293|       |            }
  294|       |        } else {
  295|    668|            let event = BytesStart::wrap(content, name_len(content));
  296|    668|
  297|    668|            // #514: Always store names event when .check_end_names == false,
  298|    668|            // because checks can be temporary disabled and when they would be
  299|    668|            // enabled, we should have that information
  300|    668|            self.opened_starts.push(self.opened_buffer.len());
  301|    668|            self.opened_buffer.extend(event.name().as_ref());
  302|    668|            Event::Start(event)
  303|       |        }
  304|    707|    }
_RNvMNtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB2_11ReaderState7decoder:
  324|  64.5k|    pub const fn decoder(&self) -> Decoder {
  325|  64.5k|        Decoder {
  326|  64.5k|            #[cfg(feature = "encoding")]
  327|  64.5k|            encoding: self.encoding.encoding(),
  328|  64.5k|        }
  329|  64.5k|    }
_RNvXs_NtNtCsa7QYSr9aLYT_9quick_xml6reader5stateNtB4_11ReaderStateNtNtCshZc3FwCJ069_4core7default7Default7default:
  333|  17.7k|    fn default() -> Self {
  334|  17.7k|        Self {
  335|  17.7k|            offset: 0,
  336|  17.7k|            last_error_offset: 0,
  337|  17.7k|            state: ParseState::Init,
  338|  17.7k|            config: Config::default(),
  339|  17.7k|            opened_buffer: Vec::new(),
  340|  17.7k|            opened_starts: Vec::new(),
  341|  17.7k|
  342|  17.7k|            #[cfg(feature = "encoding")]
  343|  17.7k|            encoding: EncodingRef::Implicit(UTF_8),
  344|  17.7k|        }
  345|  17.7k|    }

_RNvNtCsa7QYSr9aLYT_9quick_xml5utils13is_whitespaceCskRNNzwwh1bl_10sparesults:
  278|   966k|pub const fn is_whitespace(b: u8) -> bool {
  279|   966k|    matches!(b, b' ' | b'\r' | b'\n' | b'\t')
  280|   966k|}
_RNvNtCsa7QYSr9aLYT_9quick_xml5utils13is_whitespaceB3_:
  278|  4.01M|pub const fn is_whitespace(b: u8) -> bool {
  279|  4.01M|    matches!(b, b' ' | b'\r' | b'\n' | b'\t')
  280|  4.01M|}
_RNvNtCsa7QYSr9aLYT_9quick_xml5utils8name_lenB3_:
  287|   462k|pub const fn name_len(mut bytes: &[u8]) -> usize {
  288|   462k|    // Note: A pattern matching based approach (instead of indexing) allows
  289|   462k|    // making the function const.
  290|   462k|    let mut len = 0;
  291|  3.80M|    while let [first, rest @ ..] = bytes {
  292|  3.64M|        if is_whitespace(*first) {
  293|   296k|            break;
  294|  3.34M|        }
  295|  3.34M|        len += 1;
  296|  3.34M|        bytes = rest;
  297|       |    }
  298|   462k|    len
  299|   462k|}

_RNvNtCs6XCKy1Webvf_13oxigraph_fuzz13result_format18fuzz_result_format:
    6|  17.7k|pub fn fuzz_result_format(format: QueryResultsFormat, data: &[u8]) {
    7|  17.7k|    let Ok(reader) = QueryResultsParser::from_format(format).for_slice(data) else {
    8|  17.7k|        return;
    9|       |    };
   10|      0|    match reader {
   11|      0|        SliceQueryResultsParserOutput::Solutions(solutions) => {
   12|      0|            let Ok(solutions) = solutions.collect::<Result<Vec<_>, _>>() else {
   13|      0|                return;
   14|       |            };
   15|       |
   16|       |            // We try to write again
   17|      0|            let mut serializer = QueryResultsSerializer::from_format(format)
   18|      0|                .serialize_solutions_to_writer(
   19|      0|                    Vec::new(),
   20|      0|                    solutions
   21|      0|                        .first()
   22|      0|                        .map_or_else(Vec::new, |s| s.variables().to_vec()),
   23|      0|                )
   24|      0|                .unwrap();
   25|      0|            for solution in &solutions {
   26|      0|                serializer.serialize(solution).unwrap();
   27|      0|            }
   28|      0|            let serialized = serializer.finish().unwrap();
   29|       |
   30|       |            // And to parse again
   31|      0|            if let SliceQueryResultsParserOutput::Solutions(roundtrip_solutions) =
   32|      0|                QueryResultsParser::from_format(format)
   33|      0|                    .for_slice(&serialized)
   34|      0|                    .with_context(|| format!("Parsing {:?}", String::from_utf8_lossy(&serialized)))
   35|      0|                    .unwrap()
   36|       |            {
   37|      0|                assert_eq!(
   38|      0|                    roundtrip_solutions
   39|      0|                        .collect::<Result<Vec<_>, _>>()
   40|      0|                        .with_context(|| format!("Parsing {serialized:?}"))
   41|      0|                        .unwrap(),
   42|      0|                    solutions
   43|      0|                )
   44|      0|            }
   45|       |        }
   46|      0|        SliceQueryResultsParserOutput::Boolean(value) => {
   47|      0|            // We try to write again
   48|      0|            let mut serialized = Vec::new();
   49|      0|            QueryResultsSerializer::from_format(format)
   50|      0|                .serialize_boolean_to_writer(&mut serialized, value)
   51|      0|                .unwrap();
   52|       |
   53|       |            // And to parse again
   54|      0|            if let SliceQueryResultsParserOutput::Boolean(roundtrip_value) =
   55|      0|                QueryResultsParser::from_format(format)
   56|      0|                    .for_slice(&serialized)
   57|      0|                    .unwrap()
   58|       |            {
   59|      0|                assert_eq!(roundtrip_value, value)
   60|      0|            }
   61|       |        }
   62|       |    }
   63|  17.7k|}

_RINvMs2_NtCskRNNzwwh1bl_10sparesults5errorNtB6_23QueryResultsSyntaxError3msgNtNtCs8f6x4lOZV33_5alloc6string6StringEB8_:
   86|  3.63k|    pub(crate) fn msg(msg: impl Into<String>) -> Self {
   87|  3.63k|        Self(SyntaxErrorKind::Msg {
   88|  3.63k|            msg: msg.into(),
   89|  3.63k|            location: None,
   90|  3.63k|        })
   91|  3.63k|    }
_RINvMs2_NtCskRNNzwwh1bl_10sparesults5errorNtB6_23QueryResultsSyntaxError3msgReEB8_:
   86|  2.35k|    pub(crate) fn msg(msg: impl Into<String>) -> Self {
   87|  2.35k|        Self(SyntaxErrorKind::Msg {
   88|  2.35k|            msg: msg.into(),
   89|  2.35k|            location: None,
   90|  2.35k|        })
   91|  2.35k|    }
_RNvXs0_NtCskRNNzwwh1bl_10sparesults5errorNtB5_22QueryResultsParseErrorINtNtCshZc3FwCJ069_4core7convert4FromNtNtCsa7QYSr9aLYT_9quick_xml6errors5ErrorE4fromB7_:
   42|  11.7k|    fn from(error: quick_xml::Error) -> Self {
   43|  11.7k|        match error {
   44|      0|            quick_xml::Error::Io(error) => {
   45|      0|                Self::Io(Arc::try_unwrap(error).unwrap_or_else(|e| io::Error::new(e.kind(), e)))
   46|       |            }
   47|  11.7k|            _ => Self::Syntax(QueryResultsSyntaxError(SyntaxErrorKind::Xml(error))),
   48|       |        }
   49|  11.7k|    }

_RNvMNtCskRNNzwwh1bl_10sparesults6parserNtB2_18QueryResultsParser11from_formatCs6XCKy1Webvf_13oxigraph_fuzz:
   65|  17.7k|    pub fn from_format(format: QueryResultsFormat) -> Self {
   66|  17.7k|        Self { format }
   67|  17.7k|    }
_RNvMNtCskRNNzwwh1bl_10sparesults6parserNtB2_18QueryResultsParser9for_slice:
  234|  17.7k|    pub fn for_slice(
  235|  17.7k|        self,
  236|  17.7k|        slice: &[u8],
  237|  17.7k|    ) -> Result<SliceQueryResultsParserOutput<'_>, QueryResultsSyntaxError> {
  238|  17.7k|        Ok(match self.format {
  239|  17.7k|            QueryResultsFormat::Xml => match SliceXmlQueryResultsParserOutput::read(slice)? {
  240|      0|                SliceXmlQueryResultsParserOutput::Boolean(r) => SliceQueryResultsParserOutput::Boolean(r),
  241|       |                SliceXmlQueryResultsParserOutput::Solutions {
  242|      0|                    solutions,
  243|      0|                    variables,
  244|      0|                } => SliceQueryResultsParserOutput::Solutions(SliceSolutionsParser {
  245|      0|                    variables: variables.into(),
  246|      0|                    solutions: SliceSolutionsParserKind::Xml(solutions),
  247|      0|                }),
  248|       |            },
  249|      0|            QueryResultsFormat::Json => match SliceJsonQueryResultsParserOutput::read(slice)? {
  250|      0|                SliceJsonQueryResultsParserOutput::Boolean(r) => SliceQueryResultsParserOutput::Boolean(r),
  251|       |                SliceJsonQueryResultsParserOutput::Solutions {
  252|      0|                    solutions,
  253|      0|                    variables,
  254|      0|                } => SliceQueryResultsParserOutput::Solutions(SliceSolutionsParser {
  255|      0|                    variables: variables.into(),
  256|      0|                    solutions: SliceSolutionsParserKind::Json(solutions),
  257|      0|                }),
  258|       |            },
  259|      0|            QueryResultsFormat::Csv => return Err(QueryResultsSyntaxError::msg("CSV SPARQL results syntax is lossy and can't be parsed to a proper RDF representation")),
  260|      0|            QueryResultsFormat::Tsv => match SliceTsvQueryResultsParserOutput::read(slice)? {
  261|      0|                SliceTsvQueryResultsParserOutput::Boolean(r) => SliceQueryResultsParserOutput::Boolean(r),
  262|       |                SliceTsvQueryResultsParserOutput::Solutions {
  263|      0|                    solutions,
  264|      0|                    variables,
  265|      0|                } => SliceQueryResultsParserOutput::Solutions(SliceSolutionsParser {
  266|      0|                    variables: variables.into(),
  267|      0|                    solutions: SliceSolutionsParserKind::Tsv(solutions),
  268|      0|                }),
  269|       |            },
  270|       |        })
  271|  17.7k|    }

_RNvMs2_NtCskRNNzwwh1bl_10sparesults3xmlNtB5_32SliceXmlQueryResultsParserOutput4read:
  363|  17.7k|    pub fn read(slice: &'a [u8]) -> Result<Self, QueryResultsSyntaxError> {
  364|  17.7k|        Self::do_read(slice).map_err(|e| match e {
  365|       |            QueryResultsParseError::Syntax(e) => e,
  366|       |            QueryResultsParseError::Io(e) => {
  367|       |                unreachable!("I/O error are not possible for slice but found {e}")
  368|       |            }
  369|  17.7k|        })
  370|  17.7k|    }
_RNvMs2_NtCskRNNzwwh1bl_10sparesults3xmlNtB5_32SliceXmlQueryResultsParserOutput7do_read:
  372|  17.7k|    fn do_read(slice: &'a [u8]) -> Result<Self, QueryResultsParseError> {
  373|  17.7k|        let mut reader = Reader::from_reader(slice);
  374|  17.7k|        XmlInnerQueryResultsParser::set_options(reader.config_mut());
  375|  17.7k|        let mut reader_buffer = Vec::new();
  376|  17.7k|        let mut inner = XmlInnerQueryResultsParser {
  377|  17.7k|            state: ResultsState::Start,
  378|  17.7k|            variables: Vec::new(),
  379|  17.7k|            decoder: reader.decoder(),
  380|  17.7k|        };
  381|       |        loop {
  382|   678k|            reader_buffer.clear();
  383|   678k|            let event = reader.read_event_into(&mut reader_buffer)?;
  384|   668k|            if let Some(result) = inner.read_event(event)? {
  385|      0|                return Ok(match result {
  386|       |                    XmlInnerQueryResults::Solutions {
  387|      0|                        variables,
  388|      0|                        solutions,
  389|      0|                    } => Self::Solutions {
  390|      0|                        variables,
  391|      0|                        solutions: SliceXmlSolutionsParser {
  392|      0|                            reader,
  393|      0|                            inner: solutions,
  394|      0|                            reader_buffer,
  395|      0|                        },
  396|      0|                    },
  397|      0|                    XmlInnerQueryResults::Boolean(value) => Self::Boolean(value),
  398|       |                });
  399|   660k|            }
  400|       |        }
  401|  17.7k|    }
_RNvMs4_NtCskRNNzwwh1bl_10sparesults3xmlNtB5_26XmlInnerQueryResultsParser11set_options:
  458|  17.7k|    fn set_options(config: &mut Config) {
  459|  17.7k|        config.trim_text(true);
  460|  17.7k|        config.expand_empty_elements = true;
  461|  17.7k|    }
_RNvMs4_NtCskRNNzwwh1bl_10sparesults3xmlNtB5_26XmlInnerQueryResultsParser10read_event:
  463|   668k|    pub fn read_event(
  464|   668k|        &mut self,
  465|   668k|        event: Event<'_>,
  466|   668k|    ) -> Result<Option<XmlInnerQueryResults>, QueryResultsParseError> {
  467|   668k|        match event {
  468|    707|            Event::Start(event) => match self.state {
  469|       |                ResultsState::Start => {
  470|    707|                    if event.local_name().as_ref() == b"sparql" {
  471|      0|                        self.state = ResultsState::Sparql;
  472|      0|                        Ok(None)
  473|       |                    } else {
  474|    707|                        Err(QueryResultsSyntaxError::msg(format!("Expecting <sparql> tag, found <{}>", self.decoder.decode(event.name().as_ref())?)).into())
  475|       |                    }
  476|       |                }
  477|       |                ResultsState::Sparql => {
  478|      0|                    if event.local_name().as_ref() == b"head" {
  479|      0|                        self.state = ResultsState::Head;
  480|      0|                        Ok(None)
  481|       |                    } else {
  482|      0|                        Err(QueryResultsSyntaxError::msg(format!("Expecting <head> tag, found <{}>", self.decoder.decode(event.name().as_ref())?)).into())
  483|       |                    }
  484|       |                }
  485|       |                ResultsState::Head => {
  486|      0|                    if event.local_name().as_ref() == b"variable" {
  487|      0|                        let name = event.attributes()
  488|      0|                            .filter_map(Result::ok)
  489|      0|                            .find(|attr| attr.key.local_name().as_ref() == b"name")
  490|      0|                            .ok_or_else(|| QueryResultsSyntaxError::msg("No name attribute found for the <variable> tag"))?;
  491|      0|                        let name = unescape(&self.decoder.decode(&name.value)?)?.into_owned();
  492|      0|                        let variable = Variable::new(name).map_err(|e| QueryResultsSyntaxError::msg(format!("Invalid variable name: {e}")))?;
  493|      0|                        if self.variables.contains(&variable) {
  494|      0|                            return Err(QueryResultsSyntaxError::msg(format!(
  495|      0|                                "The variable {variable} is declared twice"
  496|      0|                            ))
  497|      0|                                .into());
  498|      0|                        }
  499|      0|                        self.variables.push(variable);
  500|      0|                        Ok(None)
  501|      0|                    } else if event.local_name().as_ref() == b"link" {
  502|       |                        // no op
  503|      0|                        Ok(None)
  504|       |                    } else {
  505|      0|                        Err(QueryResultsSyntaxError::msg(format!("Expecting <variable> or <link> tag, found <{}>", self.decoder.decode(event.name().as_ref())?)).into())
  506|       |                    }
  507|       |                }
  508|       |                ResultsState::AfterHead => {
  509|      0|                    if event.local_name().as_ref() == b"boolean" {
  510|      0|                        self.state = ResultsState::Boolean;
  511|      0|                        Ok(None)
  512|      0|                    } else if event.local_name().as_ref() == b"results" {
  513|      0|                        let mut mapping = BTreeMap::default();
  514|      0|                        for (i, var) in self.variables.iter().enumerate() {
  515|      0|                            mapping.insert(var.clone().into_string(), i);
  516|      0|                        }
  517|      0|                        Ok(Some(XmlInnerQueryResults::Solutions {
  518|      0|                            variables: take(&mut self.variables),
  519|      0|                            solutions: XmlInnerSolutionsParser {
  520|      0|                                decoder: self.decoder,
  521|      0|                                mapping,
  522|      0|                                state_stack: vec![State::Start, State::Start],
  523|      0|                                new_bindings: Vec::new(),
  524|      0|                                current_var: None,
  525|      0|                                term: None,
  526|      0|                                lang: None,
  527|      0|                                datatype: None,
  528|      0|                                subject_stack: Vec::new(),
  529|      0|                                predicate_stack: Vec::new(),
  530|      0|                                object_stack: Vec::new(),
  531|      0|                            },
  532|      0|                        }))
  533|      0|                    } else if event.local_name().as_ref() != b"link" && event.local_name().as_ref() != b"results" && event.local_name().as_ref() != b"boolean" {
  534|      0|                        Err(QueryResultsSyntaxError::msg(format!("Expecting sparql tag, found <{}>", self.decoder.decode(event.name().as_ref())?)).into())
  535|       |                    } else {
  536|      0|                        Ok(None)
  537|       |                    }
  538|       |                }
  539|      0|                ResultsState::Boolean => Err(QueryResultsSyntaxError::msg(format!("Unexpected tag inside of <boolean> tag: <{}>", self.decoder.decode(event.name().as_ref())?)).into())
  540|       |            },
  541|  4.83k|            Event::Text(event) => {
  542|  4.83k|                let value = event.unescape()?;
  543|  3.22k|                match self.state {
  544|       |                    ResultsState::Boolean => {
  545|      0|                        if value == "true" {
  546|      0|                            Ok(Some(XmlInnerQueryResults::Boolean(true)))
  547|      0|                        } else if value == "false" {
  548|      0|                            Ok(Some(XmlInnerQueryResults::Boolean(false)))
  549|       |                        } else {
  550|      0|                            Err(QueryResultsSyntaxError::msg(format!("Unexpected boolean value. Found '{value}'")).into())
  551|       |                        }
  552|       |                    }
  553|  3.22k|                    _ => Err(QueryResultsSyntaxError::msg(format!("Unexpected textual value found: '{value}'")).into())
  554|       |                }
  555|       |            }
  556|      0|            Event::End(event) => {
  557|      0|                if let ResultsState::Head = self.state {
  558|      0|                    if event.local_name().as_ref() == b"head" {
  559|      0|                        self.state = ResultsState::AfterHead
  560|      0|                    }
  561|      0|                    Ok(None)
  562|       |                } else {
  563|      0|                    Err(QueryResultsSyntaxError::msg("Unexpected early file end. All results file should have a <head> and a <result> or <boolean> tag").into())
  564|       |                }
  565|       |            }
  566|  2.34k|            Event::Eof => Err(QueryResultsSyntaxError::msg("Unexpected early file end. All results file should have a <head> and a <result> or <boolean> tag").into()),
  567|       |            Event::Comment(_) | Event::Decl(_) | Event::PI(_) | Event::DocType(_) => {
  568|   660k|                Ok(None)
  569|       |            }
  570|      0|            Event::Empty(_) => unreachable!("Empty events are expended"),
  571|       |            Event::CData(_) => {
  572|      5|                Err(QueryResultsSyntaxError::msg(
  573|      5|                    "<![CDATA[...]]> are not supported in SPARQL XML results",
  574|      5|                )
  575|      5|                    .into())
  576|       |            }
  577|       |        }
  578|   668k|    }
_RNCNvMs2_NtCskRNNzwwh1bl_10sparesults3xmlNtB7_32SliceXmlQueryResultsParserOutput4read0B9_:
  364|  17.7k|        Self::do_read(slice).map_err(|e| match e {
  365|  17.7k|            QueryResultsParseError::Syntax(e) => e,
  366|      0|            QueryResultsParseError::Io(e) => {
  367|      0|                unreachable!("I/O error are not possible for slice but found {e}")
  368|       |            }
  369|  17.7k|        })

