rust_fuzzer_test_input:
  209|    770|            pub extern "C" fn rust_fuzzer_test_input(bytes: &[u8]) -> i32 {
  210|       |                // When `RUST_LIBFUZZER_DEBUG_PATH` is set, write the debug
  211|       |                // formatting of the input to that file. This is only intended for
  212|       |                // `cargo fuzz`'s use!
  213|       |
  214|       |                // `RUST_LIBFUZZER_DEBUG_PATH` is set in initialization.
  215|    770|                if let Some(path) = $crate::RUST_LIBFUZZER_DEBUG_PATH.get() {
  216|       |                    use std::io::Write;
  217|      0|                    let mut file = std::fs::File::create(path)
  218|      0|                        .expect("failed to create `RUST_LIBFUZZER_DEBUG_PATH` file");
  219|      0|                    writeln!(&mut file, "{:?}", bytes)
  220|      0|                        .expect("failed to write to `RUST_LIBFUZZER_DEBUG_PATH` file");
  221|      0|                    return 0;
  222|    770|                }
  223|    770|
  224|    770|                __libfuzzer_sys_run(bytes);
  225|    770|                0
  226|       |            }
_RNvNvCs5kVP4BzcjI1_18sparql_results_xml1__19___libfuzzer_sys_run:
  241|    770|            fn __libfuzzer_sys_run($bytes: &[u8]) {
  242|    770|                $body
  243|    770|            }
LLVMFuzzerTestOneInput:
   58|    770|pub fn test_input_wrap(data: *const u8, size: usize) -> i32 {
   59|    770|    let test_input = ::std::panic::catch_unwind(|| unsafe {
   60|       |        let data_slice = ::std::slice::from_raw_parts(data, size);
   61|       |        rust_fuzzer_test_input(data_slice)
   62|    770|    });
   63|    770|
   64|    770|    match test_input {
   65|    770|        Ok(i) => i,
   66|       |        Err(_) => {
   67|       |            // hopefully the custom panic hook will be called before and abort the
   68|       |            // process before the stack frames are unwinded.
   69|      0|            ::std::process::abort();
   70|       |        }
   71|       |    }
   72|    770|}
_RNCNvCse1N9LuOeUrw_13libfuzzer_sys15test_input_wrap0B3_:
   59|    770|    let test_input = ::std::panic::catch_unwind(|| unsafe {
   60|    770|        let data_slice = ::std::slice::from_raw_parts(data, size);
   61|    770|        rust_fuzzer_test_input(data_slice)
   62|    770|    });
LLVMFuzzerInitialize:
   79|      2|pub fn initialize(_argc: *const isize, _argv: *const *const *const u8) -> isize {
   80|      2|    // Registers a panic hook that aborts the process before unwinding.
   81|      2|    // It is useful to abort before unwinding so that the fuzzer will then be
   82|      2|    // able to analyse the process stack frames to tell different bugs appart.
   83|      2|    //
   84|      2|    // HACK / FIXME: it would be better to use `-C panic=abort` but it's currently
   85|      2|    // impossible to build code using compiler plugins with this flag.
   86|      2|    // We will be able to remove this code when
   87|      2|    // https://github.com/rust-lang/cargo/issues/5423 is fixed.
   88|      2|    let default_hook = ::std::panic::take_hook();
   89|      2|    ::std::panic::set_hook(Box::new(move |panic_info| {
   90|       |        default_hook(panic_info);
   91|       |        ::std::process::abort();
   92|      2|    }));
   93|       |
   94|       |    // Initialize the `RUST_LIBFUZZER_DEBUG_PATH` cell with the path so it can be
   95|       |    // reused with little overhead.
   96|      2|    if let Ok(path) = std::env::var("RUST_LIBFUZZER_DEBUG_PATH") {
   97|      0|        RUST_LIBFUZZER_DEBUG_PATH
   98|      0|            .set(path)
   99|      0|            .expect("Since this is initialize it is only called once so can never fail");
  100|      2|    }
  101|      2|    0
  102|      2|}

_RINvMs3_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrNtB6_4Iter4nextNCNvXs7_NtBc_6memchrNtB1e_7Memchr3NtNtNtNtCsfWS17p17snN_4core4iter6traits8iterator8Iterator4next0ECs6Agad4Vg9Hx_13oxigraph_fuzz:
 1044|  1.85k|    pub(crate) unsafe fn next(
 1045|  1.85k|        &mut self,
 1046|  1.85k|        mut find_raw: impl FnMut(*const u8, *const u8) -> Option<*const u8>,
 1047|  1.85k|    ) -> Option<usize> {
 1048|       |        // SAFETY: Pointers are derived directly from the same &[u8] haystack.
 1049|       |        // We only ever modify start/end corresponding to a matching offset
 1050|       |        // found between start and end. Thus all changes to start/end maintain
 1051|       |        // our safety requirements.
 1052|       |        //
 1053|       |        // The only other assumption we rely on is that the pointer returned
 1054|       |        // by `find_raw` satisfies `self.start <= found < self.end`, and that
 1055|       |        // safety contract is forwarded to the caller.
 1056|  1.85k|        let found = find_raw(self.start, self.end)?;
 1057|  1.77k|        let result = found.distance(self.original_start);
 1058|  1.77k|        self.start = found.add(1);
 1059|  1.77k|        Some(result)
 1060|  1.85k|    }
_RINvMs3_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrNtB6_4Iter4nextNCNvXs_NtBc_6memchrNtB1d_6MemchrNtNtNtNtCsfWS17p17snN_4core4iter6traits8iterator8Iterator4next0ECs6Agad4Vg9Hx_13oxigraph_fuzz:
 1044|  6.24k|    pub(crate) unsafe fn next(
 1045|  6.24k|        &mut self,
 1046|  6.24k|        mut find_raw: impl FnMut(*const u8, *const u8) -> Option<*const u8>,
 1047|  6.24k|    ) -> Option<usize> {
 1048|       |        // SAFETY: Pointers are derived directly from the same &[u8] haystack.
 1049|       |        // We only ever modify start/end corresponding to a matching offset
 1050|       |        // found between start and end. Thus all changes to start/end maintain
 1051|       |        // our safety requirements.
 1052|       |        //
 1053|       |        // The only other assumption we rely on is that the pointer returned
 1054|       |        // by `find_raw` satisfies `self.start <= found < self.end`, and that
 1055|       |        // safety contract is forwarded to the caller.
 1056|  6.24k|        let found = find_raw(self.start, self.end)?;
 1057|  6.12k|        let result = found.distance(self.original_start);
 1058|  6.12k|        self.start = found.add(1);
 1059|  6.12k|        Some(result)
 1060|  6.24k|    }
_RINvNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchr21search_slice_with_rawNCNvNtB8_6memchr6memchr0ECs6Agad4Vg9Hx_13oxigraph_fuzz:
 1125|  1.06k|pub(crate) unsafe fn search_slice_with_raw(
 1126|  1.06k|    haystack: &[u8],
 1127|  1.06k|    mut find_raw: impl FnMut(*const u8, *const u8) -> Option<*const u8>,
 1128|  1.06k|) -> Option<usize> {
 1129|  1.06k|    // SAFETY: We rely on `find_raw` to return a correct and valid pointer, but
 1130|  1.06k|    // otherwise, `start` and `end` are valid due to the guarantees provided by
 1131|  1.06k|    // a &[u8].
 1132|  1.06k|    let start = haystack.as_ptr();
 1133|  1.06k|    let end = start.add(haystack.len());
 1134|  1.06k|    let found = find_raw(start, end)?;
 1135|    637|    Some(found.distance(start))
 1136|  1.06k|}
_RNvMs3_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrNtB5_4Iter3new:
 1027|  5.50k|    pub(crate) fn new(haystack: &'h [u8]) -> Iter<'h> {
 1028|  5.50k|        Iter {
 1029|  5.50k|            original_start: haystack.as_ptr(),
 1030|  5.50k|            start: haystack.as_ptr(),
 1031|  5.50k|            end: haystack.as_ptr().wrapping_add(haystack.len()),
 1032|  5.50k|            haystack: core::marker::PhantomData,
 1033|  5.50k|        }
 1034|  5.50k|    }
_RINvMs3_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrNtB6_4Iter4nextNCNvXs3_NtBc_6memchrNtB1e_7Memchr2NtNtNtNtCsfWS17p17snN_4core4iter6traits8iterator8Iterator4next0ECsa5xj4vgqoz3_9quick_xml:
 1044|   513k|    pub(crate) unsafe fn next(
 1045|   513k|        &mut self,
 1046|   513k|        mut find_raw: impl FnMut(*const u8, *const u8) -> Option<*const u8>,
 1047|   513k|    ) -> Option<usize> {
 1048|       |        // SAFETY: Pointers are derived directly from the same &[u8] haystack.
 1049|       |        // We only ever modify start/end corresponding to a matching offset
 1050|       |        // found between start and end. Thus all changes to start/end maintain
 1051|       |        // our safety requirements.
 1052|       |        //
 1053|       |        // The only other assumption we rely on is that the pointer returned
 1054|       |        // by `find_raw` satisfies `self.start <= found < self.end`, and that
 1055|       |        // safety contract is forwarded to the caller.
 1056|   513k|        let found = find_raw(self.start, self.end)?;
 1057|   509k|        let result = found.distance(self.original_start);
 1058|   509k|        self.start = found.add(1);
 1059|   509k|        Some(result)
 1060|   513k|    }
_RNvMNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE7needle1B8_:
  117|  3.74k|    pub(crate) fn needle1(&self) -> u8 {
  118|  3.74k|        self.s1
  119|  3.74k|    }
_RNvMNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE3newB8_:
  111|  7.31k|    pub(crate) unsafe fn new(needle: u8) -> One<V> {
  112|  7.31k|        One { s1: needle, v1: V::splat(needle) }
  113|  7.31k|    }
_RNvMNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iE3newB8_:
  111|  7.31k|    pub(crate) unsafe fn new(needle: u8) -> One<V> {
  112|  7.31k|        One { s1: needle, v1: V::splat(needle) }
  113|  7.31k|    }
_RNvMNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE8find_rawB8_:
  143|    618|    pub(crate) unsafe fn find_raw(
  144|    618|        &self,
  145|    618|        start: *const u8,
  146|    618|        end: *const u8,
  147|    618|    ) -> Option<*const u8> {
  148|    618|        // If we want to support vectors bigger than 256 bits, we probably
  149|    618|        // need to move up to using a u64 for the masks used below. Currently
  150|    618|        // they are 32 bits, which means we're SOL for vectors that need masks
  151|    618|        // bigger than 32 bits. Overall unclear until there's a use case.
  152|    618|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  153|       |
  154|    618|        let topos = V::Mask::first_offset;
  155|    618|        let len = end.distance(start);
  156|    618|        debug_assert!(
  157|      0|            len >= V::BYTES,
  158|      0|            "haystack has length {}, but must be at least {}",
  159|       |            len,
  160|       |            V::BYTES
  161|       |        );
  162|       |
  163|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  164|       |        // of the haystack prior to where aligned loads can start.
  165|    618|        if let Some(cur) = self.search_chunk(start, topos) {
  166|    520|            return Some(cur);
  167|     98|        }
  168|     98|        // Set `cur` to the first V-aligned pointer greater than `start`.
  169|     98|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  170|     98|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  171|     98|        if len >= Self::LOOP_SIZE {
  172|      0|            while cur <= end.sub(Self::LOOP_SIZE) {
  173|      0|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  174|       |
  175|      0|                let a = V::load_aligned(cur);
  176|      0|                let b = V::load_aligned(cur.add(1 * V::BYTES));
  177|      0|                let c = V::load_aligned(cur.add(2 * V::BYTES));
  178|      0|                let d = V::load_aligned(cur.add(3 * V::BYTES));
  179|      0|                let eqa = self.v1.cmpeq(a);
  180|      0|                let eqb = self.v1.cmpeq(b);
  181|      0|                let eqc = self.v1.cmpeq(c);
  182|      0|                let eqd = self.v1.cmpeq(d);
  183|      0|                let or1 = eqa.or(eqb);
  184|      0|                let or2 = eqc.or(eqd);
  185|      0|                let or3 = or1.or(or2);
  186|      0|                if or3.movemask_will_have_non_zero() {
  187|      0|                    let mask = eqa.movemask();
  188|      0|                    if mask.has_non_zero() {
  189|      0|                        return Some(cur.add(topos(mask)));
  190|      0|                    }
  191|      0|
  192|      0|                    let mask = eqb.movemask();
  193|      0|                    if mask.has_non_zero() {
  194|      0|                        return Some(cur.add(1 * V::BYTES).add(topos(mask)));
  195|      0|                    }
  196|      0|
  197|      0|                    let mask = eqc.movemask();
  198|      0|                    if mask.has_non_zero() {
  199|      0|                        return Some(cur.add(2 * V::BYTES).add(topos(mask)));
  200|      0|                    }
  201|      0|
  202|      0|                    let mask = eqd.movemask();
  203|      0|                    debug_assert!(mask.has_non_zero());
  204|      0|                    return Some(cur.add(3 * V::BYTES).add(topos(mask)));
  205|      0|                }
  206|      0|                cur = cur.add(Self::LOOP_SIZE);
  207|       |            }
  208|     98|        }
  209|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  210|       |        // loads here, but I believe we are guaranteed that they are aligned
  211|       |        // since `cur` is aligned.
  212|    112|        while cur <= end.sub(V::BYTES) {
  213|     21|            debug_assert!(end.distance(cur) >= V::BYTES);
  214|     21|            if let Some(cur) = self.search_chunk(cur, topos) {
  215|      7|                return Some(cur);
  216|     14|            }
  217|     14|            cur = cur.add(V::BYTES);
  218|       |        }
  219|       |        // Finally handle any remaining bytes less than the size of V. In this
  220|       |        // case, our pointer may indeed be unaligned and the load may overlap
  221|       |        // with the previous one. But that's okay since we know the previous
  222|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  223|     91|        if cur < end {
  224|     66|            debug_assert!(end.distance(cur) < V::BYTES);
  225|     66|            cur = cur.sub(V::BYTES - end.distance(cur));
  226|     66|            debug_assert_eq!(end.distance(cur), V::BYTES);
  227|     66|            return self.search_chunk(cur, topos);
  228|     25|        }
  229|     25|        None
  230|    618|    }
_RNvMNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB2_3OneNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iE8find_rawB8_:
  143|  5.32k|    pub(crate) unsafe fn find_raw(
  144|  5.32k|        &self,
  145|  5.32k|        start: *const u8,
  146|  5.32k|        end: *const u8,
  147|  5.32k|    ) -> Option<*const u8> {
  148|  5.32k|        // If we want to support vectors bigger than 256 bits, we probably
  149|  5.32k|        // need to move up to using a u64 for the masks used below. Currently
  150|  5.32k|        // they are 32 bits, which means we're SOL for vectors that need masks
  151|  5.32k|        // bigger than 32 bits. Overall unclear until there's a use case.
  152|  5.32k|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  153|       |
  154|  5.32k|        let topos = V::Mask::first_offset;
  155|  5.32k|        let len = end.distance(start);
  156|  5.32k|        debug_assert!(
  157|      0|            len >= V::BYTES,
  158|      0|            "haystack has length {}, but must be at least {}",
  159|       |            len,
  160|       |            V::BYTES
  161|       |        );
  162|       |
  163|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  164|       |        // of the haystack prior to where aligned loads can start.
  165|  5.32k|        if let Some(cur) = self.search_chunk(start, topos) {
  166|  4.55k|            return Some(cur);
  167|    765|        }
  168|    765|        // Set `cur` to the first V-aligned pointer greater than `start`.
  169|    765|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  170|    765|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  171|    765|        if len >= Self::LOOP_SIZE {
  172|    841|            while cur <= end.sub(Self::LOOP_SIZE) {
  173|    756|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  174|       |
  175|    756|                let a = V::load_aligned(cur);
  176|    756|                let b = V::load_aligned(cur.add(1 * V::BYTES));
  177|    756|                let c = V::load_aligned(cur.add(2 * V::BYTES));
  178|    756|                let d = V::load_aligned(cur.add(3 * V::BYTES));
  179|    756|                let eqa = self.v1.cmpeq(a);
  180|    756|                let eqb = self.v1.cmpeq(b);
  181|    756|                let eqc = self.v1.cmpeq(c);
  182|    756|                let eqd = self.v1.cmpeq(d);
  183|    756|                let or1 = eqa.or(eqb);
  184|    756|                let or2 = eqc.or(eqd);
  185|    756|                let or3 = or1.or(or2);
  186|    756|                if or3.movemask_will_have_non_zero() {
  187|    501|                    let mask = eqa.movemask();
  188|    501|                    if mask.has_non_zero() {
  189|    230|                        return Some(cur.add(topos(mask)));
  190|    271|                    }
  191|    271|
  192|    271|                    let mask = eqb.movemask();
  193|    271|                    if mask.has_non_zero() {
  194|    150|                        return Some(cur.add(1 * V::BYTES).add(topos(mask)));
  195|    121|                    }
  196|    121|
  197|    121|                    let mask = eqc.movemask();
  198|    121|                    if mask.has_non_zero() {
  199|     83|                        return Some(cur.add(2 * V::BYTES).add(topos(mask)));
  200|     38|                    }
  201|     38|
  202|     38|                    let mask = eqd.movemask();
  203|     38|                    debug_assert!(mask.has_non_zero());
  204|     38|                    return Some(cur.add(3 * V::BYTES).add(topos(mask)));
  205|    255|                }
  206|    255|                cur = cur.add(Self::LOOP_SIZE);
  207|       |            }
  208|    179|        }
  209|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  210|       |        // loads here, but I believe we are guaranteed that they are aligned
  211|       |        // since `cur` is aligned.
  212|    494|        while cur <= end.sub(V::BYTES) {
  213|    302|            debug_assert!(end.distance(cur) >= V::BYTES);
  214|    302|            if let Some(cur) = self.search_chunk(cur, topos) {
  215|     72|                return Some(cur);
  216|    230|            }
  217|    230|            cur = cur.add(V::BYTES);
  218|       |        }
  219|       |        // Finally handle any remaining bytes less than the size of V. In this
  220|       |        // case, our pointer may indeed be unaligned and the load may overlap
  221|       |        // with the previous one. But that's okay since we know the previous
  222|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  223|    192|        if cur < end {
  224|    170|            debug_assert!(end.distance(cur) < V::BYTES);
  225|    170|            cur = cur.sub(V::BYTES - end.distance(cur));
  226|    170|            debug_assert_eq!(end.distance(cur), V::BYTES);
  227|    170|            return self.search_chunk(cur, topos);
  228|     22|        }
  229|     22|        None
  230|  5.32k|    }
_RINvMNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB3_3OneNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE12search_chunkNvYNtNtB9_6vector16SensibleMoveMaskNtB24_8MoveMask12first_offsetEB9_:
  416|    705|    unsafe fn search_chunk(
  417|    705|        &self,
  418|    705|        cur: *const u8,
  419|    705|        mask_to_offset: impl Fn(V::Mask) -> usize,
  420|    705|    ) -> Option<*const u8> {
  421|    705|        let chunk = V::load_unaligned(cur);
  422|    705|        let mask = self.v1.cmpeq(chunk).movemask();
  423|    705|        if mask.has_non_zero() {
  424|    554|            Some(cur.add(mask_to_offset(mask)))
  425|       |        } else {
  426|    151|            None
  427|       |        }
  428|    705|    }
_RINvMNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB3_3OneNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iE12search_chunkNvYNtNtB9_6vector16SensibleMoveMaskNtB24_8MoveMask12first_offsetEB9_:
  416|  5.79k|    unsafe fn search_chunk(
  417|  5.79k|        &self,
  418|  5.79k|        cur: *const u8,
  419|  5.79k|        mask_to_offset: impl Fn(V::Mask) -> usize,
  420|  5.79k|    ) -> Option<*const u8> {
  421|  5.79k|        let chunk = V::load_unaligned(cur);
  422|  5.79k|        let mask = self.v1.cmpeq(chunk).movemask();
  423|  5.79k|        if mask.has_non_zero() {
  424|  4.66k|            Some(cur.add(mask_to_offset(mask)))
  425|       |        } else {
  426|  1.12k|            None
  427|       |        }
  428|  5.79k|    }
_RNvMs_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE3newBa_:
  450|   513k|    pub(crate) unsafe fn new(needle1: u8, needle2: u8) -> Two<V> {
  451|   513k|        Two {
  452|   513k|            s1: needle1,
  453|   513k|            s2: needle2,
  454|   513k|            v1: V::splat(needle1),
  455|   513k|            v2: V::splat(needle2),
  456|   513k|        }
  457|   513k|    }
_RNvMs_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iE3newBa_:
  450|   513k|    pub(crate) unsafe fn new(needle1: u8, needle2: u8) -> Two<V> {
  451|   513k|        Two {
  452|   513k|            s1: needle1,
  453|   513k|            s2: needle2,
  454|   513k|            v1: V::splat(needle1),
  455|   513k|            v2: V::splat(needle2),
  456|   513k|        }
  457|   513k|    }
_RNvMs_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE7needle1Ba_:
  461|  37.4k|    pub(crate) fn needle1(&self) -> u8 {
  462|  37.4k|        self.s1
  463|  37.4k|    }
_RNvMs_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE7needle2Ba_:
  467|  31.8k|    pub(crate) fn needle2(&self) -> u8 {
  468|  31.8k|        self.s2
  469|  31.8k|    }
_RNvMs_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE8find_rawBa_:
  493|  16.1k|    pub(crate) unsafe fn find_raw(
  494|  16.1k|        &self,
  495|  16.1k|        start: *const u8,
  496|  16.1k|        end: *const u8,
  497|  16.1k|    ) -> Option<*const u8> {
  498|  16.1k|        // If we want to support vectors bigger than 256 bits, we probably
  499|  16.1k|        // need to move up to using a u64 for the masks used below. Currently
  500|  16.1k|        // they are 32 bits, which means we're SOL for vectors that need masks
  501|  16.1k|        // bigger than 32 bits. Overall unclear until there's a use case.
  502|  16.1k|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  503|       |
  504|  16.1k|        let topos = V::Mask::first_offset;
  505|  16.1k|        let len = end.distance(start);
  506|  16.1k|        debug_assert!(
  507|      0|            len >= V::BYTES,
  508|      0|            "haystack has length {}, but must be at least {}",
  509|       |            len,
  510|       |            V::BYTES
  511|       |        );
  512|       |
  513|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  514|       |        // of the haystack prior to where aligned loads can start.
  515|  16.1k|        if let Some(cur) = self.search_chunk(start, topos) {
  516|  15.2k|            return Some(cur);
  517|    943|        }
  518|    943|        // Set `cur` to the first V-aligned pointer greater than `start`.
  519|    943|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  520|    943|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  521|    943|        if len >= Self::LOOP_SIZE {
  522|      0|            while cur <= end.sub(Self::LOOP_SIZE) {
  523|      0|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  524|       |
  525|      0|                let a = V::load_aligned(cur);
  526|      0|                let b = V::load_aligned(cur.add(V::BYTES));
  527|      0|                let eqa1 = self.v1.cmpeq(a);
  528|      0|                let eqb1 = self.v1.cmpeq(b);
  529|      0|                let eqa2 = self.v2.cmpeq(a);
  530|      0|                let eqb2 = self.v2.cmpeq(b);
  531|      0|                let or1 = eqa1.or(eqb1);
  532|      0|                let or2 = eqa2.or(eqb2);
  533|      0|                let or3 = or1.or(or2);
  534|      0|                if or3.movemask_will_have_non_zero() {
  535|      0|                    let mask = eqa1.movemask().or(eqa2.movemask());
  536|      0|                    if mask.has_non_zero() {
  537|      0|                        return Some(cur.add(topos(mask)));
  538|      0|                    }
  539|      0|
  540|      0|                    let mask = eqb1.movemask().or(eqb2.movemask());
  541|      0|                    debug_assert!(mask.has_non_zero());
  542|      0|                    return Some(cur.add(V::BYTES).add(topos(mask)));
  543|      0|                }
  544|      0|                cur = cur.add(Self::LOOP_SIZE);
  545|       |            }
  546|    943|        }
  547|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  548|       |        // loads here, but I believe we are guaranteed that they are aligned
  549|       |        // since `cur` is aligned.
  550|  1.28k|        while cur <= end.sub(V::BYTES) {
  551|    611|            debug_assert!(end.distance(cur) >= V::BYTES);
  552|    611|            if let Some(cur) = self.search_chunk(cur, topos) {
  553|    271|                return Some(cur);
  554|    340|            }
  555|    340|            cur = cur.add(V::BYTES);
  556|       |        }
  557|       |        // Finally handle any remaining bytes less than the size of V. In this
  558|       |        // case, our pointer may indeed be unaligned and the load may overlap
  559|       |        // with the previous one. But that's okay since we know the previous
  560|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  561|    672|        if cur < end {
  562|    619|            debug_assert!(end.distance(cur) < V::BYTES);
  563|    619|            cur = cur.sub(V::BYTES - end.distance(cur));
  564|    619|            debug_assert_eq!(end.distance(cur), V::BYTES);
  565|    619|            return self.search_chunk(cur, topos);
  566|     53|        }
  567|     53|        None
  568|  16.1k|    }
_RNvMs_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB4_3TwoNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iE8find_rawBa_:
  493|   468k|    pub(crate) unsafe fn find_raw(
  494|   468k|        &self,
  495|   468k|        start: *const u8,
  496|   468k|        end: *const u8,
  497|   468k|    ) -> Option<*const u8> {
  498|   468k|        // If we want to support vectors bigger than 256 bits, we probably
  499|   468k|        // need to move up to using a u64 for the masks used below. Currently
  500|   468k|        // they are 32 bits, which means we're SOL for vectors that need masks
  501|   468k|        // bigger than 32 bits. Overall unclear until there's a use case.
  502|   468k|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  503|       |
  504|   468k|        let topos = V::Mask::first_offset;
  505|   468k|        let len = end.distance(start);
  506|   468k|        debug_assert!(
  507|      0|            len >= V::BYTES,
  508|      0|            "haystack has length {}, but must be at least {}",
  509|       |            len,
  510|       |            V::BYTES
  511|       |        );
  512|       |
  513|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  514|       |        // of the haystack prior to where aligned loads can start.
  515|   468k|        if let Some(cur) = self.search_chunk(start, topos) {
  516|   459k|            return Some(cur);
  517|  9.53k|        }
  518|  9.53k|        // Set `cur` to the first V-aligned pointer greater than `start`.
  519|  9.53k|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  520|  9.53k|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  521|  9.53k|        if len >= Self::LOOP_SIZE {
  522|  8.94k|            while cur <= end.sub(Self::LOOP_SIZE) {
  523|  8.32k|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  524|       |
  525|  8.32k|                let a = V::load_aligned(cur);
  526|  8.32k|                let b = V::load_aligned(cur.add(V::BYTES));
  527|  8.32k|                let eqa1 = self.v1.cmpeq(a);
  528|  8.32k|                let eqb1 = self.v1.cmpeq(b);
  529|  8.32k|                let eqa2 = self.v2.cmpeq(a);
  530|  8.32k|                let eqb2 = self.v2.cmpeq(b);
  531|  8.32k|                let or1 = eqa1.or(eqb1);
  532|  8.32k|                let or2 = eqa2.or(eqb2);
  533|  8.32k|                let or3 = or1.or(or2);
  534|  8.32k|                if or3.movemask_will_have_non_zero() {
  535|  7.86k|                    let mask = eqa1.movemask().or(eqa2.movemask());
  536|  7.86k|                    if mask.has_non_zero() {
  537|  5.86k|                        return Some(cur.add(topos(mask)));
  538|  2.00k|                    }
  539|  2.00k|
  540|  2.00k|                    let mask = eqb1.movemask().or(eqb2.movemask());
  541|  2.00k|                    debug_assert!(mask.has_non_zero());
  542|  2.00k|                    return Some(cur.add(V::BYTES).add(topos(mask)));
  543|    463|                }
  544|    463|                cur = cur.add(Self::LOOP_SIZE);
  545|       |            }
  546|  1.05k|        }
  547|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  548|       |        // loads here, but I believe we are guaranteed that they are aligned
  549|       |        // since `cur` is aligned.
  550|  2.04k|        while cur <= end.sub(V::BYTES) {
  551|  1.06k|            debug_assert!(end.distance(cur) >= V::BYTES);
  552|  1.06k|            if let Some(cur) = self.search_chunk(cur, topos) {
  553|    695|                return Some(cur);
  554|    372|            }
  555|    372|            cur = cur.add(V::BYTES);
  556|       |        }
  557|       |        // Finally handle any remaining bytes less than the size of V. In this
  558|       |        // case, our pointer may indeed be unaligned and the load may overlap
  559|       |        // with the previous one. But that's okay since we know the previous
  560|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  561|    975|        if cur < end {
  562|    959|            debug_assert!(end.distance(cur) < V::BYTES);
  563|    959|            cur = cur.sub(V::BYTES - end.distance(cur));
  564|    959|            debug_assert_eq!(end.distance(cur), V::BYTES);
  565|    959|            return self.search_chunk(cur, topos);
  566|     16|        }
  567|     16|        None
  568|   468k|    }
_RINvMs_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB5_3TwoNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE12search_chunkNvYNtNtBb_6vector16SensibleMoveMaskNtB26_8MoveMask12first_offsetEBb_:
  670|  17.4k|    unsafe fn search_chunk(
  671|  17.4k|        &self,
  672|  17.4k|        cur: *const u8,
  673|  17.4k|        mask_to_offset: impl Fn(V::Mask) -> usize,
  674|  17.4k|    ) -> Option<*const u8> {
  675|  17.4k|        let chunk = V::load_unaligned(cur);
  676|  17.4k|        let eq1 = self.v1.cmpeq(chunk);
  677|  17.4k|        let eq2 = self.v2.cmpeq(chunk);
  678|  17.4k|        let mask = eq1.or(eq2).movemask();
  679|  17.4k|        if mask.has_non_zero() {
  680|  15.9k|            let mask1 = eq1.movemask();
  681|  15.9k|            let mask2 = eq2.movemask();
  682|  15.9k|            Some(cur.add(mask_to_offset(mask1.or(mask2))))
  683|       |        } else {
  684|  1.46k|            None
  685|       |        }
  686|  17.4k|    }
_RINvMs_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB5_3TwoNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iE12search_chunkNvYNtNtBb_6vector16SensibleMoveMaskNtB26_8MoveMask12first_offsetEBb_:
  670|   470k|    unsafe fn search_chunk(
  671|   470k|        &self,
  672|   470k|        cur: *const u8,
  673|   470k|        mask_to_offset: impl Fn(V::Mask) -> usize,
  674|   470k|    ) -> Option<*const u8> {
  675|   470k|        let chunk = V::load_unaligned(cur);
  676|   470k|        let eq1 = self.v1.cmpeq(chunk);
  677|   470k|        let eq2 = self.v2.cmpeq(chunk);
  678|   470k|        let mask = eq1.or(eq2).movemask();
  679|   470k|        if mask.has_non_zero() {
  680|   460k|            let mask1 = eq1.movemask();
  681|   460k|            let mask2 = eq2.movemask();
  682|   460k|            Some(cur.add(mask_to_offset(mask1.or(mask2))))
  683|       |        } else {
  684|  10.1k|            None
  685|       |        }
  686|   470k|    }
_RNvMs0_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE3newBb_:
  710|  1.85k|    pub(crate) unsafe fn new(
  711|  1.85k|        needle1: u8,
  712|  1.85k|        needle2: u8,
  713|  1.85k|        needle3: u8,
  714|  1.85k|    ) -> Three<V> {
  715|  1.85k|        Three {
  716|  1.85k|            s1: needle1,
  717|  1.85k|            s2: needle2,
  718|  1.85k|            s3: needle3,
  719|  1.85k|            v1: V::splat(needle1),
  720|  1.85k|            v2: V::splat(needle2),
  721|  1.85k|            v3: V::splat(needle3),
  722|  1.85k|        }
  723|  1.85k|    }
_RNvMs0_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iE3newBb_:
  710|  1.85k|    pub(crate) unsafe fn new(
  711|  1.85k|        needle1: u8,
  712|  1.85k|        needle2: u8,
  713|  1.85k|        needle3: u8,
  714|  1.85k|    ) -> Three<V> {
  715|  1.85k|        Three {
  716|  1.85k|            s1: needle1,
  717|  1.85k|            s2: needle2,
  718|  1.85k|            s3: needle3,
  719|  1.85k|            v1: V::splat(needle1),
  720|  1.85k|            v2: V::splat(needle2),
  721|  1.85k|            v3: V::splat(needle3),
  722|  1.85k|        }
  723|  1.85k|    }
_RNvMs0_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE7needle1Bb_:
  727|    473|    pub(crate) fn needle1(&self) -> u8 {
  728|    473|        self.s1
  729|    473|    }
_RNvMs0_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE7needle2Bb_:
  733|    396|    pub(crate) fn needle2(&self) -> u8 {
  734|    396|        self.s2
  735|    396|    }
_RNvMs0_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE7needle3Bb_:
  739|    277|    pub(crate) fn needle3(&self) -> u8 {
  740|    277|        self.s3
  741|    277|    }
_RNvMs0_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE8find_rawBb_:
  765|    230|    pub(crate) unsafe fn find_raw(
  766|    230|        &self,
  767|    230|        start: *const u8,
  768|    230|        end: *const u8,
  769|    230|    ) -> Option<*const u8> {
  770|    230|        // If we want to support vectors bigger than 256 bits, we probably
  771|    230|        // need to move up to using a u64 for the masks used below. Currently
  772|    230|        // they are 32 bits, which means we're SOL for vectors that need masks
  773|    230|        // bigger than 32 bits. Overall unclear until there's a use case.
  774|    230|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  775|       |
  776|    230|        let topos = V::Mask::first_offset;
  777|    230|        let len = end.distance(start);
  778|    230|        debug_assert!(
  779|      0|            len >= V::BYTES,
  780|      0|            "haystack has length {}, but must be at least {}",
  781|       |            len,
  782|       |            V::BYTES
  783|       |        );
  784|       |
  785|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  786|       |        // of the haystack prior to where aligned loads can start.
  787|    230|        if let Some(cur) = self.search_chunk(start, topos) {
  788|    219|            return Some(cur);
  789|     11|        }
  790|     11|        // Set `cur` to the first V-aligned pointer greater than `start`.
  791|     11|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  792|     11|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  793|     11|        if len >= Self::LOOP_SIZE {
  794|      0|            while cur <= end.sub(Self::LOOP_SIZE) {
  795|      0|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  796|       |
  797|      0|                let a = V::load_aligned(cur);
  798|      0|                let b = V::load_aligned(cur.add(V::BYTES));
  799|      0|                let eqa1 = self.v1.cmpeq(a);
  800|      0|                let eqb1 = self.v1.cmpeq(b);
  801|      0|                let eqa2 = self.v2.cmpeq(a);
  802|      0|                let eqb2 = self.v2.cmpeq(b);
  803|      0|                let eqa3 = self.v3.cmpeq(a);
  804|      0|                let eqb3 = self.v3.cmpeq(b);
  805|      0|                let or1 = eqa1.or(eqb1);
  806|      0|                let or2 = eqa2.or(eqb2);
  807|      0|                let or3 = eqa3.or(eqb3);
  808|      0|                let or4 = or1.or(or2);
  809|      0|                let or5 = or3.or(or4);
  810|      0|                if or5.movemask_will_have_non_zero() {
  811|      0|                    let mask = eqa1
  812|      0|                        .movemask()
  813|      0|                        .or(eqa2.movemask())
  814|      0|                        .or(eqa3.movemask());
  815|      0|                    if mask.has_non_zero() {
  816|      0|                        return Some(cur.add(topos(mask)));
  817|      0|                    }
  818|      0|
  819|      0|                    let mask = eqb1
  820|      0|                        .movemask()
  821|      0|                        .or(eqb2.movemask())
  822|      0|                        .or(eqb3.movemask());
  823|      0|                    debug_assert!(mask.has_non_zero());
  824|      0|                    return Some(cur.add(V::BYTES).add(topos(mask)));
  825|      0|                }
  826|      0|                cur = cur.add(Self::LOOP_SIZE);
  827|       |            }
  828|     11|        }
  829|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  830|       |        // loads here, but I believe we are guaranteed that they are aligned
  831|       |        // since `cur` is aligned.
  832|     19|        while cur <= end.sub(V::BYTES) {
  833|     10|            debug_assert!(end.distance(cur) >= V::BYTES);
  834|     10|            if let Some(cur) = self.search_chunk(cur, topos) {
  835|      2|                return Some(cur);
  836|      8|            }
  837|      8|            cur = cur.add(V::BYTES);
  838|       |        }
  839|       |        // Finally handle any remaining bytes less than the size of V. In this
  840|       |        // case, our pointer may indeed be unaligned and the load may overlap
  841|       |        // with the previous one. But that's okay since we know the previous
  842|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  843|      9|        if cur < end {
  844|      2|            debug_assert!(end.distance(cur) < V::BYTES);
  845|      2|            cur = cur.sub(V::BYTES - end.distance(cur));
  846|      2|            debug_assert_eq!(end.distance(cur), V::BYTES);
  847|      2|            return self.search_chunk(cur, topos);
  848|      7|        }
  849|      7|        None
  850|    230|    }
_RNvMs0_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB5_5ThreeNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iE8find_rawBb_:
  765|  1.21k|    pub(crate) unsafe fn find_raw(
  766|  1.21k|        &self,
  767|  1.21k|        start: *const u8,
  768|  1.21k|        end: *const u8,
  769|  1.21k|    ) -> Option<*const u8> {
  770|  1.21k|        // If we want to support vectors bigger than 256 bits, we probably
  771|  1.21k|        // need to move up to using a u64 for the masks used below. Currently
  772|  1.21k|        // they are 32 bits, which means we're SOL for vectors that need masks
  773|  1.21k|        // bigger than 32 bits. Overall unclear until there's a use case.
  774|  1.21k|        debug_assert!(V::BYTES <= 32, "vector cannot be bigger than 32 bytes");
  775|       |
  776|  1.21k|        let topos = V::Mask::first_offset;
  777|  1.21k|        let len = end.distance(start);
  778|  1.21k|        debug_assert!(
  779|      0|            len >= V::BYTES,
  780|      0|            "haystack has length {}, but must be at least {}",
  781|       |            len,
  782|       |            V::BYTES
  783|       |        );
  784|       |
  785|       |        // Search a possibly unaligned chunk at `start`. This covers any part
  786|       |        // of the haystack prior to where aligned loads can start.
  787|  1.21k|        if let Some(cur) = self.search_chunk(start, topos) {
  788|  1.03k|            return Some(cur);
  789|    186|        }
  790|    186|        // Set `cur` to the first V-aligned pointer greater than `start`.
  791|    186|        let mut cur = start.add(V::BYTES - (start.as_usize() & V::ALIGN));
  792|    186|        debug_assert!(cur > start && end.sub(V::BYTES) >= start);
  793|    186|        if len >= Self::LOOP_SIZE {
  794|    268|            while cur <= end.sub(Self::LOOP_SIZE) {
  795|    255|                debug_assert_eq!(0, cur.as_usize() % V::BYTES);
  796|       |
  797|    255|                let a = V::load_aligned(cur);
  798|    255|                let b = V::load_aligned(cur.add(V::BYTES));
  799|    255|                let eqa1 = self.v1.cmpeq(a);
  800|    255|                let eqb1 = self.v1.cmpeq(b);
  801|    255|                let eqa2 = self.v2.cmpeq(a);
  802|    255|                let eqb2 = self.v2.cmpeq(b);
  803|    255|                let eqa3 = self.v3.cmpeq(a);
  804|    255|                let eqb3 = self.v3.cmpeq(b);
  805|    255|                let or1 = eqa1.or(eqb1);
  806|    255|                let or2 = eqa2.or(eqb2);
  807|    255|                let or3 = eqa3.or(eqb3);
  808|    255|                let or4 = or1.or(or2);
  809|    255|                let or5 = or3.or(or4);
  810|    255|                if or5.movemask_will_have_non_zero() {
  811|    164|                    let mask = eqa1
  812|    164|                        .movemask()
  813|    164|                        .or(eqa2.movemask())
  814|    164|                        .or(eqa3.movemask());
  815|    164|                    if mask.has_non_zero() {
  816|     91|                        return Some(cur.add(topos(mask)));
  817|     73|                    }
  818|     73|
  819|     73|                    let mask = eqb1
  820|     73|                        .movemask()
  821|     73|                        .or(eqb2.movemask())
  822|     73|                        .or(eqb3.movemask());
  823|     73|                    debug_assert!(mask.has_non_zero());
  824|     73|                    return Some(cur.add(V::BYTES).add(topos(mask)));
  825|     91|                }
  826|     91|                cur = cur.add(Self::LOOP_SIZE);
  827|       |            }
  828|      9|        }
  829|       |        // Handle any leftovers after the aligned loop above. We use unaligned
  830|       |        // loads here, but I believe we are guaranteed that they are aligned
  831|       |        // since `cur` is aligned.
  832|     25|        while cur <= end.sub(V::BYTES) {
  833|      6|            debug_assert!(end.distance(cur) >= V::BYTES);
  834|      6|            if let Some(cur) = self.search_chunk(cur, topos) {
  835|      3|                return Some(cur);
  836|      3|            }
  837|      3|            cur = cur.add(V::BYTES);
  838|       |        }
  839|       |        // Finally handle any remaining bytes less than the size of V. In this
  840|       |        // case, our pointer may indeed be unaligned and the load may overlap
  841|       |        // with the previous one. But that's okay since we know the previous
  842|       |        // load didn't lead to a match (otherwise we wouldn't be here).
  843|     19|        if cur < end {
  844|     13|            debug_assert!(end.distance(cur) < V::BYTES);
  845|     13|            cur = cur.sub(V::BYTES - end.distance(cur));
  846|     13|            debug_assert_eq!(end.distance(cur), V::BYTES);
  847|     13|            return self.search_chunk(cur, topos);
  848|      6|        }
  849|      6|        None
  850|  1.21k|    }
_RINvMs0_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB6_5ThreeNtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iE12search_chunkNvYNtNtBc_6vector16SensibleMoveMaskNtB29_8MoveMask12first_offsetEBc_:
  962|    242|    unsafe fn search_chunk(
  963|    242|        &self,
  964|    242|        cur: *const u8,
  965|    242|        mask_to_offset: impl Fn(V::Mask) -> usize,
  966|    242|    ) -> Option<*const u8> {
  967|    242|        let chunk = V::load_unaligned(cur);
  968|    242|        let eq1 = self.v1.cmpeq(chunk);
  969|    242|        let eq2 = self.v2.cmpeq(chunk);
  970|    242|        let eq3 = self.v3.cmpeq(chunk);
  971|    242|        let mask = eq1.or(eq2).or(eq3).movemask();
  972|    242|        if mask.has_non_zero() {
  973|    221|            let mask1 = eq1.movemask();
  974|    221|            let mask2 = eq2.movemask();
  975|    221|            let mask3 = eq3.movemask();
  976|    221|            Some(cur.add(mask_to_offset(mask1.or(mask2).or(mask3))))
  977|       |        } else {
  978|     21|            None
  979|       |        }
  980|    242|    }
_RINvMs0_NtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchrINtB6_5ThreeNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iE12search_chunkNvYNtNtBc_6vector16SensibleMoveMaskNtB29_8MoveMask12first_offsetEBc_:
  962|  1.23k|    unsafe fn search_chunk(
  963|  1.23k|        &self,
  964|  1.23k|        cur: *const u8,
  965|  1.23k|        mask_to_offset: impl Fn(V::Mask) -> usize,
  966|  1.23k|    ) -> Option<*const u8> {
  967|  1.23k|        let chunk = V::load_unaligned(cur);
  968|  1.23k|        let eq1 = self.v1.cmpeq(chunk);
  969|  1.23k|        let eq2 = self.v2.cmpeq(chunk);
  970|  1.23k|        let eq3 = self.v3.cmpeq(chunk);
  971|  1.23k|        let mask = eq1.or(eq2).or(eq3).movemask();
  972|  1.23k|        if mask.has_non_zero() {
  973|  1.03k|            let mask1 = eq1.movemask();
  974|  1.03k|            let mask2 = eq2.movemask();
  975|  1.03k|            let mask3 = eq3.movemask();
  976|  1.03k|            Some(cur.add(mask_to_offset(mask1.or(mask2).or(mask3))))
  977|       |        } else {
  978|    200|            None
  979|       |        }
  980|  1.23k|    }
_RINvNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchr16fwd_byte_by_byteNCNvMNtNtNtB6_6x86_644avx26memchrNtB1a_3One8find_raw0EB8_:
 1148|  1.30k|pub(crate) unsafe fn fwd_byte_by_byte<F: Fn(u8) -> bool>(
 1149|  1.30k|    start: *const u8,
 1150|  1.30k|    end: *const u8,
 1151|  1.30k|    confirm: F,
 1152|  1.30k|) -> Option<*const u8> {
 1153|  1.30k|    debug_assert!(start <= end);
 1154|  1.30k|    let mut ptr = start;
 1155|  4.01k|    while ptr < end {
 1156|  3.74k|        if confirm(*ptr) {
 1157|  1.03k|            return Some(ptr);
 1158|  2.71k|        }
 1159|  2.71k|        ptr = ptr.offset(1);
 1160|       |    }
 1161|    269|    None
 1162|  1.30k|}
_RINvNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchr16fwd_byte_by_byteNCNvMs2_NtNtNtB6_6x86_644avx26memchrNtB1d_3Two8find_raw0EB8_:
 1148|  25.6k|pub(crate) unsafe fn fwd_byte_by_byte<F: Fn(u8) -> bool>(
 1149|  25.6k|    start: *const u8,
 1150|  25.6k|    end: *const u8,
 1151|  25.6k|    confirm: F,
 1152|  25.6k|) -> Option<*const u8> {
 1153|  25.6k|    debug_assert!(start <= end);
 1154|  25.6k|    let mut ptr = start;
 1155|  38.6k|    while ptr < end {
 1156|  37.4k|        if confirm(*ptr) {
 1157|  24.5k|            return Some(ptr);
 1158|  12.9k|        }
 1159|  12.9k|        ptr = ptr.offset(1);
 1160|       |    }
 1161|  1.14k|    None
 1162|  25.6k|}
_RINvNtNtNtCsd8Kpcw17VoO_6memchr4arch7generic6memchr16fwd_byte_by_byteNCNvMs6_NtNtNtB6_6x86_644avx26memchrNtB1d_5Three8find_raw0EB8_:
 1148|    375|pub(crate) unsafe fn fwd_byte_by_byte<F: Fn(u8) -> bool>(
 1149|    375|    start: *const u8,
 1150|    375|    end: *const u8,
 1151|    375|    confirm: F,
 1152|    375|) -> Option<*const u8> {
 1153|    375|    debug_assert!(start <= end);
 1154|    375|    let mut ptr = start;
 1155|    500|    while ptr < end {
 1156|    473|        if confirm(*ptr) {
 1157|    348|            return Some(ptr);
 1158|    125|        }
 1159|    125|        ptr = ptr.offset(1);
 1160|       |    }
 1161|     27|    None
 1162|    375|}

_RNvMNtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB2_3One13new_uncheckedBa_:
   69|  7.31k|    pub unsafe fn new_unchecked(needle: u8) -> One {
   70|  7.31k|        One {
   71|  7.31k|            sse2: generic::One::new(needle),
   72|  7.31k|            avx2: generic::One::new(needle),
   73|  7.31k|        }
   74|  7.31k|    }
_RNvMNtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB2_3One12is_availableBa_:
   86|      1|    pub fn is_available() -> bool {
   87|      1|        #[cfg(not(target_feature = "sse2"))]
   88|      1|        {
   89|      1|            false
   90|      1|        }
   91|      1|        #[cfg(target_feature = "sse2")]
   92|      1|        {
   93|      1|            #[cfg(target_feature = "avx2")]
   94|      1|            {
   95|      1|                true
   96|      1|            }
   97|      1|            #[cfg(not(target_feature = "avx2"))]
   98|      1|            {
   99|      1|                #[cfg(feature = "std")]
  100|      1|                {
  101|      1|                    std::is_x86_feature_detected!("avx2")
  102|       |                }
  103|       |                #[cfg(not(feature = "std"))]
  104|       |                {
  105|       |                    false
  106|       |                }
  107|       |            }
  108|       |        }
  109|      1|    }
_RNvMNtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB2_3One8find_rawBa_:
  179|  7.31k|    pub unsafe fn find_raw(
  180|  7.31k|        &self,
  181|  7.31k|        start: *const u8,
  182|  7.31k|        end: *const u8,
  183|  7.31k|    ) -> Option<*const u8> {
  184|  7.31k|        if start >= end {
  185|     69|            return None;
  186|  7.24k|        }
  187|  7.24k|        let len = end.distance(start);
  188|  7.24k|        if len < __m256i::BYTES {
  189|  1.92k|            return if len < __m128i::BYTES {
  190|       |                // SAFETY: We require the caller to pass valid start/end
  191|       |                // pointers.
  192|  1.30k|                generic::fwd_byte_by_byte(start, end, |b| {
  193|       |                    b == self.sse2.needle1()
  194|  1.30k|                })
  195|       |            } else {
  196|       |                // SAFETY: We require the caller to pass valid start/end
  197|       |                // pointers.
  198|    618|                self.find_raw_sse2(start, end)
  199|       |            };
  200|  5.32k|        }
  201|  5.32k|        // SAFETY: Building a `One` means it's safe to call both 'sse2' and
  202|  5.32k|        // 'avx2' routines. Also, we've checked that our haystack is big
  203|  5.32k|        // enough to run on the vector routine. Pointer validity is caller's
  204|  5.32k|        // responsibility.
  205|  5.32k|        //
  206|  5.32k|        // Note that we could call `self.avx2.find_raw` directly here. But that
  207|  5.32k|        // means we'd have to annotate this routine with `target_feature`.
  208|  5.32k|        // Which is fine, because this routine is `unsafe` anyway and the
  209|  5.32k|        // `target_feature` obligation is met by virtue of building a `One`.
  210|  5.32k|        // The real problem is that a routine with a `target_feature`
  211|  5.32k|        // annotation generally can't be inlined into caller code unless
  212|  5.32k|        // the caller code has the same target feature annotations. Namely,
  213|  5.32k|        // the common case (at time of writing) is for calling code to not
  214|  5.32k|        // have the `avx2` target feature enabled *at compile time*. Without
  215|  5.32k|        // `target_feature` on this routine, it can be inlined which will
  216|  5.32k|        // handle some of the short-haystack cases above without touching the
  217|  5.32k|        // architecture specific code.
  218|  5.32k|        self.find_raw_avx2(start, end)
  219|  7.31k|    }
_RNCNvMNtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB4_3One8find_raw0Bc_:
  192|  3.74k|                generic::fwd_byte_by_byte(start, end, |b| {
  193|  3.74k|                    b == self.sse2.needle1()
  194|  3.74k|                })
_RNvMNtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB2_3One13find_raw_sse2Ba_:
  336|    618|    unsafe fn find_raw_sse2(
  337|    618|        &self,
  338|    618|        start: *const u8,
  339|    618|        end: *const u8,
  340|    618|    ) -> Option<*const u8> {
  341|    618|        self.sse2.find_raw(start, end)
  342|    618|    }
_RNvMNtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB2_3One13find_raw_avx2Ba_:
  396|  5.32k|    unsafe fn find_raw_avx2(
  397|  5.32k|        &self,
  398|  5.32k|        start: *const u8,
  399|  5.32k|        end: *const u8,
  400|  5.32k|    ) -> Option<*const u8> {
  401|  5.32k|        self.avx2.find_raw(start, end)
  402|  5.32k|    }
_RNvMs2_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_3Two13new_uncheckedBd_:
  556|   513k|    pub unsafe fn new_unchecked(needle1: u8, needle2: u8) -> Two {
  557|   513k|        Two {
  558|   513k|            sse2: generic::Two::new(needle1, needle2),
  559|   513k|            avx2: generic::Two::new(needle1, needle2),
  560|   513k|        }
  561|   513k|    }
_RNvMs2_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_3Two12is_availableBd_:
  573|      1|    pub fn is_available() -> bool {
  574|      1|        #[cfg(not(target_feature = "sse2"))]
  575|      1|        {
  576|      1|            false
  577|      1|        }
  578|      1|        #[cfg(target_feature = "sse2")]
  579|      1|        {
  580|      1|            #[cfg(target_feature = "avx2")]
  581|      1|            {
  582|      1|                true
  583|      1|            }
  584|      1|            #[cfg(not(target_feature = "avx2"))]
  585|      1|            {
  586|      1|                #[cfg(feature = "std")]
  587|      1|                {
  588|      1|                    std::is_x86_feature_detected!("avx2")
  589|       |                }
  590|       |                #[cfg(not(feature = "std"))]
  591|       |                {
  592|       |                    false
  593|       |                }
  594|       |            }
  595|       |        }
  596|      1|    }
_RNvMs2_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_3Two8find_rawBd_:
  654|   513k|    pub unsafe fn find_raw(
  655|   513k|        &self,
  656|   513k|        start: *const u8,
  657|   513k|        end: *const u8,
  658|   513k|    ) -> Option<*const u8> {
  659|   513k|        if start >= end {
  660|  2.54k|            return None;
  661|   510k|        }
  662|   510k|        let len = end.distance(start);
  663|   510k|        if len < __m256i::BYTES {
  664|  41.8k|            return if len < __m128i::BYTES {
  665|       |                // SAFETY: We require the caller to pass valid start/end
  666|       |                // pointers.
  667|  25.6k|                generic::fwd_byte_by_byte(start, end, |b| {
  668|       |                    b == self.sse2.needle1() || b == self.sse2.needle2()
  669|  25.6k|                })
  670|       |            } else {
  671|       |                // SAFETY: We require the caller to pass valid start/end
  672|       |                // pointers.
  673|  16.1k|                self.find_raw_sse2(start, end)
  674|       |            };
  675|   468k|        }
  676|   468k|        // SAFETY: Building a `Two` means it's safe to call both 'sse2' and
  677|   468k|        // 'avx2' routines. Also, we've checked that our haystack is big
  678|   468k|        // enough to run on the vector routine. Pointer validity is caller's
  679|   468k|        // responsibility.
  680|   468k|        //
  681|   468k|        // Note that we could call `self.avx2.find_raw` directly here. But that
  682|   468k|        // means we'd have to annotate this routine with `target_feature`.
  683|   468k|        // Which is fine, because this routine is `unsafe` anyway and the
  684|   468k|        // `target_feature` obligation is met by virtue of building a `Two`.
  685|   468k|        // The real problem is that a routine with a `target_feature`
  686|   468k|        // annotation generally can't be inlined into caller code unless
  687|   468k|        // the caller code has the same target feature annotations. Namely,
  688|   468k|        // the common case (at time of writing) is for calling code to not
  689|   468k|        // have the `avx2` target feature enabled *at compile time*. Without
  690|   468k|        // `target_feature` on this routine, it can be inlined which will
  691|   468k|        // handle some of the short-haystack cases above without touching the
  692|   468k|        // architecture specific code.
  693|   468k|        self.find_raw_avx2(start, end)
  694|   513k|    }
_RNCNvMs2_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB7_3Two8find_raw0Bf_:
  667|  37.4k|                generic::fwd_byte_by_byte(start, end, |b| {
  668|  37.4k|                    b == self.sse2.needle1() || b == self.sse2.needle2()
  669|  37.4k|                })
_RNvMs2_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_3Two13find_raw_sse2Bd_:
  764|  16.1k|    unsafe fn find_raw_sse2(
  765|  16.1k|        &self,
  766|  16.1k|        start: *const u8,
  767|  16.1k|        end: *const u8,
  768|  16.1k|    ) -> Option<*const u8> {
  769|  16.1k|        self.sse2.find_raw(start, end)
  770|  16.1k|    }
_RNvMs2_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_3Two13find_raw_avx2Bd_:
  804|   468k|    unsafe fn find_raw_avx2(
  805|   468k|        &self,
  806|   468k|        start: *const u8,
  807|   468k|        end: *const u8,
  808|   468k|    ) -> Option<*const u8> {
  809|   468k|        self.avx2.find_raw(start, end)
  810|   468k|    }
_RNvMs6_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_5Three13new_uncheckedBd_:
  935|  1.85k|    pub unsafe fn new_unchecked(
  936|  1.85k|        needle1: u8,
  937|  1.85k|        needle2: u8,
  938|  1.85k|        needle3: u8,
  939|  1.85k|    ) -> Three {
  940|  1.85k|        Three {
  941|  1.85k|            sse2: generic::Three::new(needle1, needle2, needle3),
  942|  1.85k|            avx2: generic::Three::new(needle1, needle2, needle3),
  943|  1.85k|        }
  944|  1.85k|    }
_RNvMs6_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_5Three12is_availableBd_:
  956|      1|    pub fn is_available() -> bool {
  957|      1|        #[cfg(not(target_feature = "sse2"))]
  958|      1|        {
  959|      1|            false
  960|      1|        }
  961|      1|        #[cfg(target_feature = "sse2")]
  962|      1|        {
  963|      1|            #[cfg(target_feature = "avx2")]
  964|      1|            {
  965|      1|                true
  966|      1|            }
  967|      1|            #[cfg(not(target_feature = "avx2"))]
  968|      1|            {
  969|      1|                #[cfg(feature = "std")]
  970|      1|                {
  971|      1|                    std::is_x86_feature_detected!("avx2")
  972|       |                }
  973|       |                #[cfg(not(feature = "std"))]
  974|       |                {
  975|       |                    false
  976|       |                }
  977|       |            }
  978|       |        }
  979|      1|    }
_RNvMs6_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_5Three8find_rawBd_:
 1037|  1.85k|    pub unsafe fn find_raw(
 1038|  1.85k|        &self,
 1039|  1.85k|        start: *const u8,
 1040|  1.85k|        end: *const u8,
 1041|  1.85k|    ) -> Option<*const u8> {
 1042|  1.85k|        if start >= end {
 1043|     33|            return None;
 1044|  1.82k|        }
 1045|  1.82k|        let len = end.distance(start);
 1046|  1.82k|        if len < __m256i::BYTES {
 1047|    605|            return if len < __m128i::BYTES {
 1048|       |                // SAFETY: We require the caller to pass valid start/end
 1049|       |                // pointers.
 1050|    375|                generic::fwd_byte_by_byte(start, end, |b| {
 1051|       |                    b == self.sse2.needle1()
 1052|       |                        || b == self.sse2.needle2()
 1053|       |                        || b == self.sse2.needle3()
 1054|    375|                })
 1055|       |            } else {
 1056|       |                // SAFETY: We require the caller to pass valid start/end
 1057|       |                // pointers.
 1058|    230|                self.find_raw_sse2(start, end)
 1059|       |            };
 1060|  1.21k|        }
 1061|  1.21k|        // SAFETY: Building a `Three` means it's safe to call both 'sse2' and
 1062|  1.21k|        // 'avx2' routines. Also, we've checked that our haystack is big
 1063|  1.21k|        // enough to run on the vector routine. Pointer validity is caller's
 1064|  1.21k|        // responsibility.
 1065|  1.21k|        //
 1066|  1.21k|        // Note that we could call `self.avx2.find_raw` directly here. But that
 1067|  1.21k|        // means we'd have to annotate this routine with `target_feature`.
 1068|  1.21k|        // Which is fine, because this routine is `unsafe` anyway and the
 1069|  1.21k|        // `target_feature` obligation is met by virtue of building a `Three`.
 1070|  1.21k|        // The real problem is that a routine with a `target_feature`
 1071|  1.21k|        // annotation generally can't be inlined into caller code unless
 1072|  1.21k|        // the caller code has the same target feature annotations. Namely,
 1073|  1.21k|        // the common case (at time of writing) is for calling code to not
 1074|  1.21k|        // have the `avx2` target feature enabled *at compile time*. Without
 1075|  1.21k|        // `target_feature` on this routine, it can be inlined which will
 1076|  1.21k|        // handle some of the short-haystack cases above without touching the
 1077|  1.21k|        // architecture specific code.
 1078|  1.21k|        self.find_raw_avx2(start, end)
 1079|  1.85k|    }
_RNCNvMs6_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB7_5Three8find_raw0Bf_:
 1050|    473|                generic::fwd_byte_by_byte(start, end, |b| {
 1051|    473|                    b == self.sse2.needle1()
 1052|    396|                        || b == self.sse2.needle2()
 1053|    277|                        || b == self.sse2.needle3()
 1054|    473|                })
_RNvMs6_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_5Three13find_raw_sse2Bd_:
 1151|    230|    unsafe fn find_raw_sse2(
 1152|    230|        &self,
 1153|    230|        start: *const u8,
 1154|    230|        end: *const u8,
 1155|    230|    ) -> Option<*const u8> {
 1156|    230|        self.sse2.find_raw(start, end)
 1157|    230|    }
_RNvMs6_NtNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_644avx26memchrNtB5_5Three13find_raw_avx2Bd_:
 1191|  1.21k|    unsafe fn find_raw_avx2(
 1192|  1.21k|        &self,
 1193|  1.21k|        start: *const u8,
 1194|  1.21k|        end: *const u8,
 1195|  1.21k|    ) -> Option<*const u8> {
 1196|  1.21k|        self.avx2.find_raw(start, end)
 1197|  1.21k|    }

_RNvNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_646memchr10memchr_raw:
  174|  7.31k|pub(crate) fn memchr_raw(
  175|  7.31k|    n1: u8,
  176|  7.31k|    start: *const u8,
  177|  7.31k|    end: *const u8,
  178|  7.31k|) -> Option<*const u8> {
  179|  7.31k|    // SAFETY: We provide a valid function pointer type.
  180|  7.31k|    unsafe_ifunc!(
  181|  7.31k|        One,
  182|  7.31k|        find_raw,
  183|  7.31k|        unsafe fn(u8, *const u8, *const u8) -> Option<*const u8>,
  184|  7.31k|        Option<*const u8>,
  185|  7.31k|        start,
  186|  7.31k|        end,
  187|  7.31k|        n1
  188|  7.31k|    )
  189|  7.31k|}
_RNvNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_646memchr11memchr2_raw:
  220|   513k|pub(crate) fn memchr2_raw(
  221|   513k|    n1: u8,
  222|   513k|    n2: u8,
  223|   513k|    start: *const u8,
  224|   513k|    end: *const u8,
  225|   513k|) -> Option<*const u8> {
  226|   513k|    // SAFETY: We provide a valid function pointer type.
  227|   513k|    unsafe_ifunc!(
  228|   513k|        Two,
  229|   513k|        find_raw,
  230|   513k|        unsafe fn(u8, u8, *const u8, *const u8) -> Option<*const u8>,
  231|   513k|        Option<*const u8>,
  232|   513k|        start,
  233|   513k|        end,
  234|   513k|        n1,
  235|   513k|        n2
  236|   513k|    )
  237|   513k|}
_RNvNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_646memchr11memchr3_raw:
  270|  1.85k|pub(crate) fn memchr3_raw(
  271|  1.85k|    n1: u8,
  272|  1.85k|    n2: u8,
  273|  1.85k|    n3: u8,
  274|  1.85k|    start: *const u8,
  275|  1.85k|    end: *const u8,
  276|  1.85k|) -> Option<*const u8> {
  277|  1.85k|    // SAFETY: We provide a valid function pointer type.
  278|  1.85k|    unsafe_ifunc!(
  279|  1.85k|        Three,
  280|  1.85k|        find_raw,
  281|  1.85k|        unsafe fn(u8, u8, u8, *const u8, *const u8) -> Option<*const u8>,
  282|  1.85k|        Option<*const u8>,
  283|  1.85k|        start,
  284|  1.85k|        end,
  285|  1.85k|        n1,
  286|  1.85k|        n2,
  287|  1.85k|        n3
  288|  1.85k|    )
  289|  1.85k|}
_RNvNvNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_646memchr10memchr_raw9find_avx2:
   78|  7.31k|        unsafe fn find_avx2(
   79|  7.31k|            $($needle: u8),+,
   80|  7.31k|            $hay_start: *const u8,
   81|  7.31k|            $hay_end: *const u8,
   82|  7.31k|        ) -> $retty {
   83|  7.31k|            use crate::arch::x86_64::avx2::memchr::$memchrty;
   84|  7.31k|            $memchrty::new_unchecked($($needle),+)
   85|  7.31k|                .$memchrfind($hay_start, $hay_end)
   86|  7.31k|        }
_RNvNvNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_646memchr10memchr_raw6detect:
  109|      1|        unsafe fn detect(
  110|      1|            $($needle: u8),+,
  111|      1|            $hay_start: *const u8,
  112|      1|            $hay_end: *const u8,
  113|      1|        ) -> $retty {
  114|      1|            let fun = {
  115|       |                #[cfg(not(target_feature = "sse2"))]
  116|       |                {
  117|       |                    debug!(
  118|       |                        "no sse2 feature available, using fallback for {}",
  119|       |                        stringify!($memchrty),
  120|       |                    );
  121|       |                    find_fallback as RealFn
  122|       |                }
  123|       |                #[cfg(target_feature = "sse2")]
  124|       |                {
  125|       |                    use crate::arch::x86_64::{sse2, avx2};
  126|      1|                    if avx2::memchr::$memchrty::is_available() {
  127|       |                        debug!("chose AVX2 for {}", stringify!($memchrty));
  128|      1|                        find_avx2 as RealFn
  129|      0|                    } else if sse2::memchr::$memchrty::is_available() {
  130|       |                        debug!("chose SSE2 for {}", stringify!($memchrty));
  131|      0|                        find_sse2 as RealFn
  132|       |                    } else {
  133|       |                        debug!("chose fallback for {}", stringify!($memchrty));
  134|      0|                        find_fallback as RealFn
  135|       |                    }
  136|       |                }
  137|       |            };
  138|      1|            FN.store(fun as Fn, Ordering::Relaxed);
  139|      1|            // SAFETY: The only thing we need to uphold here is the
  140|      1|            // `#[target_feature]` requirements. Since we check is_available
  141|      1|            // above before using the corresponding implementation, we are
  142|      1|            // guaranteed to only call code that is supported on the current
  143|      1|            // CPU.
  144|      1|            fun($($needle),+, $hay_start, $hay_end)
  145|      1|        }
_RNvNvNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_646memchr11memchr2_raw9find_avx2:
   78|   513k|        unsafe fn find_avx2(
   79|   513k|            $($needle: u8),+,
   80|   513k|            $hay_start: *const u8,
   81|   513k|            $hay_end: *const u8,
   82|   513k|        ) -> $retty {
   83|   513k|            use crate::arch::x86_64::avx2::memchr::$memchrty;
   84|   513k|            $memchrty::new_unchecked($($needle),+)
   85|   513k|                .$memchrfind($hay_start, $hay_end)
   86|   513k|        }
_RNvNvNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_646memchr11memchr2_raw6detect:
  109|      1|        unsafe fn detect(
  110|      1|            $($needle: u8),+,
  111|      1|            $hay_start: *const u8,
  112|      1|            $hay_end: *const u8,
  113|      1|        ) -> $retty {
  114|      1|            let fun = {
  115|       |                #[cfg(not(target_feature = "sse2"))]
  116|       |                {
  117|       |                    debug!(
  118|       |                        "no sse2 feature available, using fallback for {}",
  119|       |                        stringify!($memchrty),
  120|       |                    );
  121|       |                    find_fallback as RealFn
  122|       |                }
  123|       |                #[cfg(target_feature = "sse2")]
  124|       |                {
  125|       |                    use crate::arch::x86_64::{sse2, avx2};
  126|      1|                    if avx2::memchr::$memchrty::is_available() {
  127|       |                        debug!("chose AVX2 for {}", stringify!($memchrty));
  128|      1|                        find_avx2 as RealFn
  129|      0|                    } else if sse2::memchr::$memchrty::is_available() {
  130|       |                        debug!("chose SSE2 for {}", stringify!($memchrty));
  131|      0|                        find_sse2 as RealFn
  132|       |                    } else {
  133|       |                        debug!("chose fallback for {}", stringify!($memchrty));
  134|      0|                        find_fallback as RealFn
  135|       |                    }
  136|       |                }
  137|       |            };
  138|      1|            FN.store(fun as Fn, Ordering::Relaxed);
  139|      1|            // SAFETY: The only thing we need to uphold here is the
  140|      1|            // `#[target_feature]` requirements. Since we check is_available
  141|      1|            // above before using the corresponding implementation, we are
  142|      1|            // guaranteed to only call code that is supported on the current
  143|      1|            // CPU.
  144|      1|            fun($($needle),+, $hay_start, $hay_end)
  145|      1|        }
_RNvNvNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_646memchr11memchr3_raw9find_avx2:
   78|  1.85k|        unsafe fn find_avx2(
   79|  1.85k|            $($needle: u8),+,
   80|  1.85k|            $hay_start: *const u8,
   81|  1.85k|            $hay_end: *const u8,
   82|  1.85k|        ) -> $retty {
   83|  1.85k|            use crate::arch::x86_64::avx2::memchr::$memchrty;
   84|  1.85k|            $memchrty::new_unchecked($($needle),+)
   85|  1.85k|                .$memchrfind($hay_start, $hay_end)
   86|  1.85k|        }
_RNvNvNtNtNtCsd8Kpcw17VoO_6memchr4arch6x86_646memchr11memchr3_raw6detect:
  109|      1|        unsafe fn detect(
  110|      1|            $($needle: u8),+,
  111|      1|            $hay_start: *const u8,
  112|      1|            $hay_end: *const u8,
  113|      1|        ) -> $retty {
  114|      1|            let fun = {
  115|       |                #[cfg(not(target_feature = "sse2"))]
  116|       |                {
  117|       |                    debug!(
  118|       |                        "no sse2 feature available, using fallback for {}",
  119|       |                        stringify!($memchrty),
  120|       |                    );
  121|       |                    find_fallback as RealFn
  122|       |                }
  123|       |                #[cfg(target_feature = "sse2")]
  124|       |                {
  125|       |                    use crate::arch::x86_64::{sse2, avx2};
  126|      1|                    if avx2::memchr::$memchrty::is_available() {
  127|       |                        debug!("chose AVX2 for {}", stringify!($memchrty));
  128|      1|                        find_avx2 as RealFn
  129|      0|                    } else if sse2::memchr::$memchrty::is_available() {
  130|       |                        debug!("chose SSE2 for {}", stringify!($memchrty));
  131|      0|                        find_sse2 as RealFn
  132|       |                    } else {
  133|       |                        debug!("chose fallback for {}", stringify!($memchrty));
  134|      0|                        find_fallback as RealFn
  135|       |                    }
  136|       |                }
  137|       |            };
  138|      1|            FN.store(fun as Fn, Ordering::Relaxed);
  139|      1|            // SAFETY: The only thing we need to uphold here is the
  140|      1|            // `#[target_feature]` requirements. Since we check is_available
  141|      1|            // above before using the corresponding implementation, we are
  142|      1|            // guaranteed to only call code that is supported on the current
  143|      1|            // CPU.
  144|      1|            fun($($needle),+, $hay_start, $hay_end)
  145|      1|        }

_RNvXNtCsd8Kpcw17VoO_6memchr3extPhNtB2_7Pointer8distanceB4_:
   21|  1.53M|    unsafe fn distance(self, origin: *const T) -> usize {
   22|  1.53M|        // TODO: Replace with `ptr::sub_ptr` once stabilized.
   23|  1.53M|        usize::try_from(self.offset_from(origin)).unwrap_unchecked()
   24|  1.53M|    }
_RNvXNtCsd8Kpcw17VoO_6memchr3extPhNtB2_7Pointer8as_usizeB4_:
   26|  11.5k|    fn as_usize(self) -> usize {
   27|  11.5k|        self as usize
   28|  11.5k|    }

_RNvMNtCsd8Kpcw17VoO_6memchr6memchrNtB2_6Memchr3newCs6Agad4Vg9Hx_13oxigraph_fuzz:
  300|  1.19k|    pub fn new(needle1: u8, haystack: &'h [u8]) -> Memchr<'h> {
  301|  1.19k|        Memchr {
  302|  1.19k|            needle1,
  303|  1.19k|            it: crate::arch::generic::memchr::Iter::new(haystack),
  304|  1.19k|        }
  305|  1.19k|    }
_RNvMs2_NtCsd8Kpcw17VoO_6memchr6memchrNtB5_7Memchr23newCs6Agad4Vg9Hx_13oxigraph_fuzz:
  377|  3.95k|    pub fn new(needle1: u8, needle2: u8, haystack: &'h [u8]) -> Memchr2<'h> {
  378|  3.95k|        Memchr2 {
  379|  3.95k|            needle1,
  380|  3.95k|            needle2,
  381|  3.95k|            it: crate::arch::generic::memchr::Iter::new(haystack),
  382|  3.95k|        }
  383|  3.95k|    }
_RNvMs6_NtCsd8Kpcw17VoO_6memchr6memchrNtB5_7Memchr33newCs6Agad4Vg9Hx_13oxigraph_fuzz:
  446|     90|    pub fn new(
  447|     90|        needle1: u8,
  448|     90|        needle2: u8,
  449|     90|        needle3: u8,
  450|     90|        haystack: &'h [u8],
  451|     90|    ) -> Memchr3<'h> {
  452|     90|        Memchr3 {
  453|     90|            needle1,
  454|     90|            needle2,
  455|     90|            needle3,
  456|     90|            it: crate::arch::generic::memchr::Iter::new(haystack),
  457|     90|        }
  458|     90|    }
_RNvNtCsd8Kpcw17VoO_6memchr6memchr11memchr_iterCs6Agad4Vg9Hx_13oxigraph_fuzz:
  216|  1.19k|pub fn memchr_iter<'h>(needle: u8, haystack: &'h [u8]) -> Memchr<'h> {
  217|  1.19k|    Memchr::new(needle, haystack)
  218|  1.19k|}
_RNvNtCsd8Kpcw17VoO_6memchr6memchr12memchr2_iterCs6Agad4Vg9Hx_13oxigraph_fuzz:
  232|  3.95k|pub fn memchr2_iter<'h>(
  233|  3.95k|    needle1: u8,
  234|  3.95k|    needle2: u8,
  235|  3.95k|    haystack: &'h [u8],
  236|  3.95k|) -> Memchr2<'h> {
  237|  3.95k|    Memchr2::new(needle1, needle2, haystack)
  238|  3.95k|}
_RNvNtCsd8Kpcw17VoO_6memchr6memchr12memchr3_iterCs6Agad4Vg9Hx_13oxigraph_fuzz:
  256|     90|pub fn memchr3_iter<'h>(
  257|     90|    needle1: u8,
  258|     90|    needle2: u8,
  259|     90|    needle3: u8,
  260|     90|    haystack: &'h [u8],
  261|     90|) -> Memchr3<'h> {
  262|     90|    Memchr3::new(needle1, needle2, needle3, haystack)
  263|     90|}
_RNvNtCsd8Kpcw17VoO_6memchr6memchr6memchrCs6Agad4Vg9Hx_13oxigraph_fuzz:
   27|  1.06k|pub fn memchr(needle: u8, haystack: &[u8]) -> Option<usize> {
   28|  1.06k|    // SAFETY: memchr_raw, when a match is found, always returns a valid
   29|  1.06k|    // pointer between start and end.
   30|  1.06k|    unsafe {
   31|  1.06k|        generic::search_slice_with_raw(haystack, |start, end| {
   32|       |            memchr_raw(needle, start, end)
   33|  1.06k|        })
   34|  1.06k|    }
   35|  1.06k|}
_RNvXs7_NtCsd8Kpcw17VoO_6memchr6memchrNtB5_7Memchr3NtNtNtNtCsfWS17p17snN_4core4iter6traits8iterator8Iterator4nextCs6Agad4Vg9Hx_13oxigraph_fuzz:
  465|  1.85k|    fn next(&mut self) -> Option<usize> {
  466|  1.85k|        // SAFETY: All of our implementations of memchr ensure that any
  467|  1.85k|        // pointers returns will fall within the start and end bounds, and this
  468|  1.85k|        // upholds the safety contract of `self.it.next`.
  469|  1.85k|        unsafe {
  470|  1.85k|            self.it.next(|s, e| {
  471|       |                memchr3_raw(self.needle1, self.needle2, self.needle3, s, e)
  472|  1.85k|            })
  473|  1.85k|        }
  474|  1.85k|    }
_RNvXs_NtCsd8Kpcw17VoO_6memchr6memchrNtB4_6MemchrNtNtNtNtCsfWS17p17snN_4core4iter6traits8iterator8Iterator4nextCs6Agad4Vg9Hx_13oxigraph_fuzz:
  312|  6.24k|    fn next(&mut self) -> Option<usize> {
  313|  6.24k|        // SAFETY: All of our implementations of memchr ensure that any
  314|  6.24k|        // pointers returns will fall within the start and end bounds, and this
  315|  6.24k|        // upholds the safety contract of `self.it.next`.
  316|  6.24k|        unsafe {
  317|  6.24k|            // NOTE: I attempted to define an enum of previously created
  318|  6.24k|            // searchers and then switch on those here instead of just
  319|  6.24k|            // calling `memchr_raw` (or `One::new(..).find_raw(..)`). But
  320|  6.24k|            // that turned out to have a fair bit of extra overhead when
  321|  6.24k|            // searching very small haystacks.
  322|  6.24k|            self.it.next(|s, e| memchr_raw(self.needle1, s, e))
  323|  6.24k|        }
  324|  6.24k|    }
_RNCNvXs3_NtCsd8Kpcw17VoO_6memchr6memchrNtB7_7Memchr2NtNtNtNtCsfWS17p17snN_4core4iter6traits8iterator8Iterator4next0Csa5xj4vgqoz3_9quick_xml:
  395|   513k|            self.it.next(|s, e| memchr2_raw(self.needle1, self.needle2, s, e))
_RNCNvXs7_NtCsd8Kpcw17VoO_6memchr6memchrNtB7_7Memchr3NtNtNtNtCsfWS17p17snN_4core4iter6traits8iterator8Iterator4next0Csa5xj4vgqoz3_9quick_xml:
  470|  1.85k|            self.it.next(|s, e| {
  471|  1.85k|                memchr3_raw(self.needle1, self.needle2, self.needle3, s, e)
  472|  1.85k|            })
_RNCNvXs_NtCsd8Kpcw17VoO_6memchr6memchrNtB6_6MemchrNtNtNtNtCsfWS17p17snN_4core4iter6traits8iterator8Iterator4next0Csa5xj4vgqoz3_9quick_xml:
  322|  6.24k|            self.it.next(|s, e| memchr_raw(self.needle1, s, e))
_RNvMs2_NtCsd8Kpcw17VoO_6memchr6memchrNtB5_7Memchr23newCsa5xj4vgqoz3_9quick_xml:
  377|    266|    pub fn new(needle1: u8, needle2: u8, haystack: &'h [u8]) -> Memchr2<'h> {
  378|    266|        Memchr2 {
  379|    266|            needle1,
  380|    266|            needle2,
  381|    266|            it: crate::arch::generic::memchr::Iter::new(haystack),
  382|    266|        }
  383|    266|    }
_RNvNtCsd8Kpcw17VoO_6memchr6memchr10memchr_rawCsa5xj4vgqoz3_9quick_xml:
  504|  6.24k|unsafe fn memchr_raw(
  505|  6.24k|    needle: u8,
  506|  6.24k|    start: *const u8,
  507|  6.24k|    end: *const u8,
  508|  6.24k|) -> Option<*const u8> {
  509|  6.24k|    #[cfg(target_arch = "x86_64")]
  510|  6.24k|    {
  511|  6.24k|        // x86_64 does CPU feature detection at runtime in order to use AVX2
  512|  6.24k|        // instructions even when the `avx2` feature isn't enabled at compile
  513|  6.24k|        // time. This function also handles using a fallback if neither AVX2
  514|  6.24k|        // nor SSE2 (unusual) are available.
  515|  6.24k|        crate::arch::x86_64::memchr::memchr_raw(needle, start, end)
  516|  6.24k|    }
  517|  6.24k|    #[cfg(target_arch = "wasm32")]
  518|  6.24k|    {
  519|  6.24k|        crate::arch::wasm32::memchr::memchr_raw(needle, start, end)
  520|  6.24k|    }
  521|  6.24k|    #[cfg(target_arch = "aarch64")]
  522|  6.24k|    {
  523|  6.24k|        crate::arch::aarch64::memchr::memchr_raw(needle, start, end)
  524|  6.24k|    }
  525|  6.24k|    #[cfg(not(any(
  526|  6.24k|        target_arch = "x86_64",
  527|  6.24k|        target_arch = "wasm32",
  528|  6.24k|        target_arch = "aarch64"
  529|  6.24k|    )))]
  530|  6.24k|    {
  531|  6.24k|        crate::arch::all::memchr::One::new(needle).find_raw(start, end)
  532|  6.24k|    }
  533|  6.24k|}
_RNvNtCsd8Kpcw17VoO_6memchr6memchr11memchr2_rawCsa5xj4vgqoz3_9quick_xml:
  574|   513k|unsafe fn memchr2_raw(
  575|   513k|    needle1: u8,
  576|   513k|    needle2: u8,
  577|   513k|    start: *const u8,
  578|   513k|    end: *const u8,
  579|   513k|) -> Option<*const u8> {
  580|   513k|    #[cfg(target_arch = "x86_64")]
  581|   513k|    {
  582|   513k|        crate::arch::x86_64::memchr::memchr2_raw(needle1, needle2, start, end)
  583|   513k|    }
  584|   513k|    #[cfg(target_arch = "wasm32")]
  585|   513k|    {
  586|   513k|        crate::arch::wasm32::memchr::memchr2_raw(needle1, needle2, start, end)
  587|   513k|    }
  588|   513k|    #[cfg(target_arch = "aarch64")]
  589|   513k|    {
  590|   513k|        crate::arch::aarch64::memchr::memchr2_raw(needle1, needle2, start, end)
  591|   513k|    }
  592|   513k|    #[cfg(not(any(
  593|   513k|        target_arch = "x86_64",
  594|   513k|        target_arch = "wasm32",
  595|   513k|        target_arch = "aarch64"
  596|   513k|    )))]
  597|   513k|    {
  598|   513k|        crate::arch::all::memchr::Two::new(needle1, needle2)
  599|   513k|            .find_raw(start, end)
  600|   513k|    }
  601|   513k|}
_RNvNtCsd8Kpcw17VoO_6memchr6memchr11memchr3_rawCsa5xj4vgqoz3_9quick_xml:
  646|  1.85k|unsafe fn memchr3_raw(
  647|  1.85k|    needle1: u8,
  648|  1.85k|    needle2: u8,
  649|  1.85k|    needle3: u8,
  650|  1.85k|    start: *const u8,
  651|  1.85k|    end: *const u8,
  652|  1.85k|) -> Option<*const u8> {
  653|  1.85k|    #[cfg(target_arch = "x86_64")]
  654|  1.85k|    {
  655|  1.85k|        crate::arch::x86_64::memchr::memchr3_raw(
  656|  1.85k|            needle1, needle2, needle3, start, end,
  657|  1.85k|        )
  658|  1.85k|    }
  659|  1.85k|    #[cfg(target_arch = "wasm32")]
  660|  1.85k|    {
  661|  1.85k|        crate::arch::wasm32::memchr::memchr3_raw(
  662|  1.85k|            needle1, needle2, needle3, start, end,
  663|  1.85k|        )
  664|  1.85k|    }
  665|  1.85k|    #[cfg(target_arch = "aarch64")]
  666|  1.85k|    {
  667|  1.85k|        crate::arch::aarch64::memchr::memchr3_raw(
  668|  1.85k|            needle1, needle2, needle3, start, end,
  669|  1.85k|        )
  670|  1.85k|    }
  671|  1.85k|    #[cfg(not(any(
  672|  1.85k|        target_arch = "x86_64",
  673|  1.85k|        target_arch = "wasm32",
  674|  1.85k|        target_arch = "aarch64"
  675|  1.85k|    )))]
  676|  1.85k|    {
  677|  1.85k|        crate::arch::all::memchr::Three::new(needle1, needle2, needle3)
  678|  1.85k|            .find_raw(start, end)
  679|  1.85k|    }
  680|  1.85k|}
_RNvNtCsd8Kpcw17VoO_6memchr6memchr12memchr2_iterCsa5xj4vgqoz3_9quick_xml:
  232|    266|pub fn memchr2_iter<'h>(
  233|    266|    needle1: u8,
  234|    266|    needle2: u8,
  235|    266|    haystack: &'h [u8],
  236|    266|) -> Memchr2<'h> {
  237|    266|    Memchr2::new(needle1, needle2, haystack)
  238|    266|}
_RNvXs3_NtCsd8Kpcw17VoO_6memchr6memchrNtB5_7Memchr2NtNtNtNtCsfWS17p17snN_4core4iter6traits8iterator8Iterator4nextCsa5xj4vgqoz3_9quick_xml:
  390|   513k|    fn next(&mut self) -> Option<usize> {
  391|   513k|        // SAFETY: All of our implementations of memchr ensure that any
  392|   513k|        // pointers returns will fall within the start and end bounds, and this
  393|   513k|        // upholds the safety contract of `self.it.next`.
  394|   513k|        unsafe {
  395|   513k|            self.it.next(|s, e| memchr2_raw(self.needle1, self.needle2, s, e))
  396|   513k|        }
  397|   513k|    }
_RNCNvNtCsd8Kpcw17VoO_6memchr6memchr6memchr0B5_:
   31|  1.06k|        generic::search_slice_with_raw(haystack, |start, end| {
   32|  1.06k|            memchr_raw(needle, start, end)
   33|  1.06k|        })
_RNvNtCsd8Kpcw17VoO_6memchr6memchr10memchr_rawB3_:
  504|  1.06k|unsafe fn memchr_raw(
  505|  1.06k|    needle: u8,
  506|  1.06k|    start: *const u8,
  507|  1.06k|    end: *const u8,
  508|  1.06k|) -> Option<*const u8> {
  509|  1.06k|    #[cfg(target_arch = "x86_64")]
  510|  1.06k|    {
  511|  1.06k|        // x86_64 does CPU feature detection at runtime in order to use AVX2
  512|  1.06k|        // instructions even when the `avx2` feature isn't enabled at compile
  513|  1.06k|        // time. This function also handles using a fallback if neither AVX2
  514|  1.06k|        // nor SSE2 (unusual) are available.
  515|  1.06k|        crate::arch::x86_64::memchr::memchr_raw(needle, start, end)
  516|  1.06k|    }
  517|  1.06k|    #[cfg(target_arch = "wasm32")]
  518|  1.06k|    {
  519|  1.06k|        crate::arch::wasm32::memchr::memchr_raw(needle, start, end)
  520|  1.06k|    }
  521|  1.06k|    #[cfg(target_arch = "aarch64")]
  522|  1.06k|    {
  523|  1.06k|        crate::arch::aarch64::memchr::memchr_raw(needle, start, end)
  524|  1.06k|    }
  525|  1.06k|    #[cfg(not(any(
  526|  1.06k|        target_arch = "x86_64",
  527|  1.06k|        target_arch = "wasm32",
  528|  1.06k|        target_arch = "aarch64"
  529|  1.06k|    )))]
  530|  1.06k|    {
  531|  1.06k|        crate::arch::all::memchr::One::new(needle).find_raw(start, end)
  532|  1.06k|    }
  533|  1.06k|}

_RNvMNtCsd8Kpcw17VoO_6memchr6vectorNtB2_16SensibleMoveMask14get_for_offset:
  128|   491k|    fn get_for_offset(self) -> u32 {
  129|   491k|        #[cfg(target_endian = "big")]
  130|   491k|        {
  131|   491k|            self.0.swap_bytes()
  132|   491k|        }
  133|   491k|        #[cfg(target_endian = "little")]
  134|   491k|        {
  135|   491k|            self.0
  136|   491k|        }
  137|   491k|    }
_RNvXs_NtCsd8Kpcw17VoO_6memchr6vectorNtB4_16SensibleMoveMaskNtB4_8MoveMask12has_non_zero:
  148|   514k|    fn has_non_zero(self) -> bool {
  149|   514k|        self.0 != 0
  150|   514k|    }
_RNvXs_NtCsd8Kpcw17VoO_6memchr6vectorNtB4_16SensibleMoveMaskNtB4_8MoveMask12first_offset:
  173|   491k|    fn first_offset(self) -> usize {
  174|   491k|        // We are dealing with little endian here (and if we aren't, we swap
  175|   491k|        // the bytes so we are in practice), where the most significant byte
  176|   491k|        // is at a higher address. That means the least significant bit that
  177|   491k|        // is set corresponds to the position of our first matching byte.
  178|   491k|        // That position corresponds to the number of zeros after the least
  179|   491k|        // significant bit.
  180|   491k|        self.get_for_offset().trailing_zeros() as usize
  181|   491k|    }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86sse2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iNtB4_6Vector14load_unaligned:
  220|  18.3k|        unsafe fn load_unaligned(data: *const u8) -> __m128i {
  221|  18.3k|            _mm_loadu_si128(data as *const __m128i)
  222|  18.3k|        }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86sse2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iNtB4_6Vector8movemask:
  225|  50.8k|        unsafe fn movemask(self) -> SensibleMoveMask {
  226|  50.8k|            SensibleMoveMask(_mm_movemask_epi8(self) as u32)
  227|  50.8k|        }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86sse2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iNtB4_6Vector5cmpeq:
  230|  36.2k|        unsafe fn cmpeq(self, vector2: Self) -> __m128i {
  231|  36.2k|            _mm_cmpeq_epi8(self, vector2)
  232|  36.2k|        }
_RNvYNtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iNtNtCsd8Kpcw17VoO_6memchr6vector6Vector27movemask_will_have_non_zeroBS_:
   65|  9.33k|    unsafe fn movemask_will_have_non_zero(self) -> bool {
   66|  9.33k|        self.movemask().has_non_zero()
   67|  9.33k|    }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86avx2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iNtB4_6Vector8movemask:
  275|  1.43M|        unsafe fn movemask(self) -> SensibleMoveMask {
  276|  1.43M|            SensibleMoveMask(_mm256_movemask_epi8(self) as u32)
  277|  1.43M|        }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86avx2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iNtB4_6Vector14load_unaligned:
  270|   477k|        unsafe fn load_unaligned(data: *const u8) -> __m256i {
  271|   477k|            _mm256_loadu_si256(data as *const __m256i)
  272|   477k|        }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86avx2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iNtB4_6Vector5cmpeq:
  280|   989k|        unsafe fn cmpeq(self, vector2: Self) -> __m256i {
  281|   989k|            _mm256_cmpeq_epi8(self, vector2)
  282|   989k|        }
_RNvXs_NtCsd8Kpcw17VoO_6memchr6vectorNtB4_16SensibleMoveMaskNtB4_8MoveMask2or:
  163|   489k|    fn or(self, other: SensibleMoveMask) -> SensibleMoveMask {
  164|   489k|        SensibleMoveMask(self.0 | other.0)
  165|   489k|    }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86sse2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iNtB4_6Vector5splat:
  210|  1.03M|        unsafe fn splat(byte: u8) -> __m128i {
  211|  1.03M|            _mm_set1_epi8(byte as i8)
  212|  1.03M|        }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86sse2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m128iNtB4_6Vector2or:
  240|  17.8k|        unsafe fn or(self, vector2: Self) -> __m128i {
  241|  17.8k|            _mm_or_si128(self, vector2)
  242|  17.8k|        }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86avx2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iNtB4_6Vector5splat:
  260|  1.03M|        unsafe fn splat(byte: u8) -> __m256i {
  261|  1.03M|            _mm256_set1_epi8(byte as i8)
  262|  1.03M|        }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86avx2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iNtB4_6Vector12load_aligned:
  265|  20.1k|        unsafe fn load_aligned(data: *const u8) -> __m256i {
  266|  20.1k|            _mm256_load_si256(data as *const __m256i)
  267|  20.1k|        }
_RNvXNtNtCsd8Kpcw17VoO_6memchr6vector7x86avx2NtNtNtCsfWS17p17snN_4core9core_arch3x867___m256iNtB4_6Vector2or:
  290|   501k|        unsafe fn or(self, vector2: Self) -> __m256i {
  291|   501k|            _mm256_or_si256(self, vector2)
  292|   501k|        }

_RNvMs2_NtCs1qB4fTFwVYW_9once_cell3impINtB5_8OnceCellNtNtCsj6RlT1QFsHj_5alloc6string6StringE14is_initializedCse1N9LuOeUrw_13libfuzzer_sys:
   49|    770|    pub(crate) fn is_initialized(&self) -> bool {
   50|    770|        // An `Acquire` load is enough because that makes all the initialization
   51|    770|        // operations visible to us, and, this being a fast path, weaker
   52|    770|        // ordering helps with performance. This `Acquire` synchronizes with
   53|    770|        // `SeqCst` operations on the slow path.
   54|    770|        self.queue.load(Ordering::Acquire) == COMPLETE_PTR
   55|    770|    }

_RNvMs4_NtCs1qB4fTFwVYW_9once_cell4syncINtB5_8OnceCellNtNtCsj6RlT1QFsHj_5alloc6string6StringE3getCse1N9LuOeUrw_13libfuzzer_sys:
  963|    770|        pub fn get(&self) -> Option<&T> {
  964|    770|            if self.0.is_initialized() {
  965|       |                // Safe b/c value is initialized.
  966|      0|                Some(unsafe { self.get_unchecked() })
  967|       |            } else {
  968|    770|                None
  969|       |            }
  970|    770|        }

_RNvMs_NtCsa5xj4vgqoz3_9quick_xml8encodingNtB4_7Decoder6decode:
   82|    420|    pub fn decode<'b>(&self, bytes: &'b [u8]) -> Result<Cow<'b, str>> {
   83|       |        #[cfg(not(feature = "encoding"))]
   84|    420|        let decoded = Ok(Cow::Borrowed(std::str::from_utf8(bytes)?));
   85|       |
   86|       |        #[cfg(feature = "encoding")]
   87|       |        let decoded = decode(bytes, self.encoding);
   88|       |
   89|    351|        decoded
   90|    420|    }

_RNvXs_NtCsa5xj4vgqoz3_9quick_xml6errorsNtB4_5ErrorINtNtCsfWS17p17snN_4core7convert4FromNtNtNtBR_3str5error9Utf8ErrorE4fromB6_:
   81|     69|    fn from(error: Utf8Error) -> Error {
   82|     69|        Error::NonDecodable(Some(error))
   83|     69|    }
_RNvXs1_NtCsa5xj4vgqoz3_9quick_xml6errorsNtB5_5ErrorINtNtCsfWS17p17snN_4core7convert4FromNtNtB7_7escapei11EscapeErrorE4fromB7_:
   97|     71|    fn from(error: EscapeError) -> Error {
   98|     71|        Error::EscapeError(error)
   99|     71|    }

_RINvNtCsa5xj4vgqoz3_9quick_xml7escapei13unescape_withNCNvMs7_NtB4_6eventsNtBX_9BytesText8unescape0EB4_:
  162|    266|pub fn unescape_with<'input, 'entity, F>(
  163|    266|    raw: &'input str,
  164|    266|    mut resolve_entity: F,
  165|    266|) -> Result<Cow<'input, str>, EscapeError>
  166|    266|where
  167|    266|    // the lifetime of the output comes from a capture or is `'static`
  168|    266|    F: FnMut(&str) -> Option<&'entity str>,
  169|    266|{
  170|    266|    let bytes = raw.as_bytes();
  171|    266|    let mut unescaped = None;
  172|    266|    let mut last_end = 0;
  173|    266|    let mut iter = memchr2_iter(b'&', b';', bytes);
  174|  2.89k|    while let Some(start) = iter.by_ref().find(|p| bytes[*p] == b'&') {
  175|  2.70k|        match iter.next() {
  176|  2.69k|            Some(end) if bytes[end] == b';' => {
  177|  2.69k|                // append valid data
  178|  2.69k|                if unescaped.is_none() {
  179|    194|                    unescaped = Some(String::with_capacity(raw.len()));
  180|  2.49k|                }
  181|  2.69k|                let unescaped = unescaped.as_mut().expect("initialized");
  182|  2.69k|                unescaped.push_str(&raw[last_end..start]);
  183|  2.69k|
  184|  2.69k|                // search for character correctness
  185|  2.69k|                let pat = &raw[start + 1..end];
  186|  2.69k|                if let Some(entity) = pat.strip_prefix('#') {
  187|  2.17k|                    let codepoint = parse_number(entity, start..end)?;
  188|  2.15k|                    unescaped.push_str(codepoint.encode_utf8(&mut [0u8; 4]));
  189|    521|                } else if let Some(value) = named_entity(pat) {
  190|    482|                    unescaped.push_str(value);
  191|    482|                } else if let Some(value) = resolve_entity(pat) {
  192|      0|                    unescaped.push_str(value);
  193|      0|                } else {
  194|     39|                    return Err(EscapeError::UnrecognizedSymbol(
  195|     39|                        start + 1..end,
  196|     39|                        pat.to_string(),
  197|     39|                    ));
  198|       |                }
  199|       |
  200|  2.63k|                last_end = end + 1;
  201|       |            }
  202|     10|            _ => return Err(EscapeError::UnterminatedEntity(start..raw.len())),
  203|       |        }
  204|       |    }
  205|       |
  206|    195|    if let Some(mut unescaped) = unescaped {
  207|    128|        if let Some(raw) = raw.get(last_end..) {
  208|    128|            unescaped.push_str(raw);
  209|    128|        }
  210|    128|        Ok(Cow::Owned(unescaped))
  211|       |    } else {
  212|     67|        Ok(Cow::Borrowed(raw))
  213|       |    }
  214|    266|}
_RNCINvNtCsa5xj4vgqoz3_9quick_xml7escapei13unescape_withNCNvMs7_NtB6_6eventsNtBZ_9BytesText8unescape0E0B6_:
  174|  4.28k|    while let Some(start) = iter.by_ref().find(|p| bytes[*p] == b'&') {
_RNvNtCsa5xj4vgqoz3_9quick_xml7escapei12named_entity:
  217|    521|fn named_entity(name: &str) -> Option<&str> {
  218|       |    // match over strings are not allowed in const functions
  219|    521|    let s = match name.as_bytes() {
  220|    521|        b"lt" => "<",
  221|     78|        b"gt" => ">",
  222|    234|        b"amp" => "&",
  223|    158|        b"apos" => "'",
  224|     66|        b"quot" => "\"",
  225|     39|        _ => return None,
  226|       |    };
  227|    482|    Some(s)
  228|    521|}
_RNvNtCsa5xj4vgqoz3_9quick_xml7escapei12parse_number:
 1694|  2.17k|fn parse_number(bytes: &str, range: Range<usize>) -> Result<char, EscapeError> {
 1695|  2.17k|    let code = if let Some(hex_digits) = bytes.strip_prefix('x') {
 1696|    485|        parse_hexadecimal(hex_digits)
 1697|       |    } else {
 1698|  1.68k|        parse_decimal(bytes)
 1699|     15|    }?;
 1700|  2.15k|    if code == 0 {
 1701|      4|        return Err(EscapeError::EntityWithNull(range));
 1702|  2.15k|    }
 1703|  2.15k|    match std::char::from_u32(code) {
 1704|  2.15k|        Some(c) => Ok(c),
 1705|      3|        None => Err(EscapeError::InvalidCodepoint(code)),
 1706|       |    }
 1707|  2.17k|}
_RNvNtCsa5xj4vgqoz3_9quick_xml7escapei17parse_hexadecimal:
 1709|    485|fn parse_hexadecimal(bytes: &str) -> Result<u32, EscapeError> {
 1710|    485|    // maximum code is 0x10FFFF => 6 characters
 1711|    485|    if bytes.len() > 6 {
 1712|      1|        return Err(EscapeError::TooLongHexadecimal);
 1713|    484|    }
 1714|    484|    let mut code = 0;
 1715|  1.48k|    for b in bytes.bytes() {
 1716|  1.48k|        code <<= 4;
 1717|  1.48k|        code += match b {
 1718|  1.48k|            b'0'..=b'9' => b - b'0',
 1719|     66|            b'a'..=b'f' => b - b'a' + 10,
 1720|     71|            b'A'..=b'F' => b - b'A' + 10,
 1721|      4|            b => return Err(EscapeError::InvalidHexadecimal(b as char)),
 1722|       |        } as u32;
 1723|       |    }
 1724|    480|    Ok(code)
 1725|    485|}
_RNvNtCsa5xj4vgqoz3_9quick_xml7escapei13parse_decimal:
 1727|  1.68k|fn parse_decimal(bytes: &str) -> Result<u32, EscapeError> {
 1728|  1.68k|    // maximum code is 0x10FFFF = 1114111 => 7 characters
 1729|  1.68k|    if bytes.len() > 7 {
 1730|      1|        return Err(EscapeError::TooLongDecimal);
 1731|  1.68k|    }
 1732|  1.68k|    let mut code = 0;
 1733|  8.47k|    for b in bytes.bytes() {
 1734|  8.47k|        code *= 10;
 1735|  8.47k|        code += match b {
 1736|  8.46k|            b'0'..=b'9' => b - b'0',
 1737|      9|            b => return Err(EscapeError::InvalidDecimal(b as char)),
 1738|       |        } as u32;
 1739|       |    }
 1740|  1.67k|    Ok(code)
 1741|  1.68k|}

_RNvMNtCsa5xj4vgqoz3_9quick_xml6eventsNtB2_10BytesStart10local_nameCs6Agad4Vg9Hx_13oxigraph_fuzz:
  179|     90|    pub fn local_name(&self) -> LocalName {
  180|     90|        self.name().into()
  181|     90|    }
_RNvMNtCsa5xj4vgqoz3_9quick_xml6eventsNtB2_10BytesStart4nameCs6Agad4Vg9Hx_13oxigraph_fuzz:
  170|    180|    pub fn name(&self) -> QName {
  171|    180|        QName(&self.buf[..self.name_len])
  172|    180|    }
_RNvMNtCsa5xj4vgqoz3_9quick_xml6eventsNtB2_10BytesStart4wrapB4_:
   79|     90|    pub(crate) fn wrap(content: &'a [u8], name_len: usize) -> Self {
   80|     90|        BytesStart {
   81|     90|            buf: Cow::Borrowed(content),
   82|     90|            name_len,
   83|     90|        }
   84|     90|    }
_RINvMs7_NtCsa5xj4vgqoz3_9quick_xml6eventsNtB6_9BytesText4wrapRShEB8_:
  684|  1.66k|    pub(crate) fn wrap<C: Into<Cow<'a, [u8]>>>(content: C, decoder: Decoder) -> Self {
  685|  1.66k|        Self {
  686|  1.66k|            content: content.into(),
  687|  1.66k|            decoder,
  688|  1.66k|        }
  689|  1.66k|    }
_RNvMs7_NtCsa5xj4vgqoz3_9quick_xml6eventsNtB5_9BytesText8unescape:
  733|    291|    pub fn unescape(&self) -> Result<Cow<'a, str>> {
  734|    291|        self.unescape_with(|_| None)
  735|    291|    }
_RNCNvMs7_NtCsa5xj4vgqoz3_9quick_xml6eventsNtB7_9BytesText8unescape0B9_:
  734|     39|        self.unescape_with(|_| None)
_RINvMs7_NtCsa5xj4vgqoz3_9quick_xml6eventsNtB6_9BytesText13unescape_withNCNvB2_8unescape0EB8_:
  741|    291|    pub fn unescape_with<'entity>(
  742|    291|        &self,
  743|    291|        resolve_entity: impl FnMut(&str) -> Option<&'entity str>,
  744|    291|    ) -> Result<Cow<'a, str>> {
  745|    291|        let decoded = match &self.content {
  746|    291|            Cow::Borrowed(bytes) => self.decoder.decode(bytes)?,
  747|       |            // Convert to owned, because otherwise Cow will be bound with wrong lifetime
  748|      0|            Cow::Owned(bytes) => self.decoder.decode(bytes)?.into_owned().into(),
  749|       |        };
  750|       |
  751|    266|        match unescape_with(&decoded, resolve_entity)? {
  752|       |            // Because result is borrowed, no replacements was done and we can use original string
  753|     67|            Cow::Borrowed(_) => Ok(decoded),
  754|    128|            Cow::Owned(s) => Ok(s.into()),
  755|       |        }
  756|    291|    }
_RINvMsa_NtCsa5xj4vgqoz3_9quick_xml6eventsNtB6_10BytesCData4wrapRShEB8_:
  823|    194|    pub(crate) fn wrap<C: Into<Cow<'a, [u8]>>>(content: C, decoder: Decoder) -> Self {
  824|    194|        Self {
  825|    194|            content: content.into(),
  826|    194|            decoder,
  827|    194|        }
  828|    194|    }

_RNCNvXs4_NtCsa5xj4vgqoz3_9quick_xml4nameNtB7_9LocalNameINtNtCsfWS17p17snN_4core7convert4FromNtB7_5QNameE4from0Cs6Agad4Vg9Hx_13oxigraph_fuzz:
  174|      3|        Self(name.index().map_or(name.0, |i| &name.0[i + 1..]))
_RNvMNtCsa5xj4vgqoz3_9quick_xml4nameNtB2_5QName5index:
  111|     90|    fn index(&self) -> Option<usize> {
  112|     90|        memchr(b':', self.0)
  113|     90|    }
_RNvXs0_NtCsa5xj4vgqoz3_9quick_xml4nameNtB5_5QNameINtNtCsfWS17p17snN_4core7convert5AsRefShE6as_refCs6Agad4Vg9Hx_13oxigraph_fuzz:
  124|     90|    fn as_ref(&self) -> &[u8] {
  125|     90|        self.0
  126|     90|    }
_RNvXs3_NtCsa5xj4vgqoz3_9quick_xml4nameNtB5_9LocalNameINtNtCsfWS17p17snN_4core7convert5AsRefShE6as_refCs6Agad4Vg9Hx_13oxigraph_fuzz:
  154|     90|    fn as_ref(&self) -> &[u8] {
  155|     90|        self.0
  156|     90|    }
_RNvXs4_NtCsa5xj4vgqoz3_9quick_xml4nameNtB5_9LocalNameINtNtCsfWS17p17snN_4core7convert4FromNtB5_5QNameE4fromCs6Agad4Vg9Hx_13oxigraph_fuzz:
  173|     90|    fn from(name: QName<'a>) -> Self {
  174|     90|        Self(name.index().map_or(name.0, |i| &name.0[i + 1..]))
  175|     90|    }

_RNCNvXNtNtCsa5xj4vgqoz3_9quick_xml6reader15buffered_readerINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEINtB6_9XmlSourceQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEE15skip_whitespace0Cs6Agad4Vg9Hx_13oxigraph_fuzz:
  252|  3.28k|    impl_buffered_source!();
_RNvMs_NtNtCsa5xj4vgqoz3_9quick_xml6reader15buffered_readerINtB6_6ReaderINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEE15read_event_intoCs6Agad4Vg9Hx_13oxigraph_fuzz:
  304|  2.34k|    pub fn read_event_into<'b>(&mut self, buf: &'b mut Vec<u8>) -> Result<Event<'b>> {
  305|  2.34k|        self.read_event_impl(buf)
  306|  2.34k|    }
_RNvXNtNtCsa5xj4vgqoz3_9quick_xml6reader15buffered_readerINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEINtB4_9XmlSourceQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEE12read_elementCs6Agad4Vg9Hx_13oxigraph_fuzz:
  154|     90|        $($async)? fn read_element $(<$lf>)? (
  155|     90|            &mut self,
  156|     90|            buf: &'b mut Vec<u8>,
  157|     90|            position: &mut usize,
  158|     90|        ) -> Result<Option<&'b [u8]>> {
  159|     90|            let mut state = ReadElementState::Elem;
  160|     90|            let mut read = 0;
  161|     90|
  162|     90|            let start = buf.len();
  163|       |            loop {
  164|    176|                match self $(.$reader)? .fill_buf() $(.$await)? {
  165|    176|                    Ok(n) if n.is_empty() => break,
  166|     90|                    Ok(available) => {
  167|     90|                        if let Some((consumed, used)) = state.change(available) {
  168|      4|                            buf.extend_from_slice(consumed);
  169|      4|
  170|      4|                            self $(.$reader)? .consume(used);
  171|      4|                            read += used;
  172|      4|
  173|      4|                            // Position now just after the `>` symbol
  174|      4|                            *position += read;
  175|      4|                            break;
  176|     86|                        } else {
  177|     86|                            // The `>` symbol not yet found, continue reading
  178|     86|                            buf.extend_from_slice(available);
  179|     86|
  180|     86|                            let used = available.len();
  181|     86|                            self $(.$reader)? .consume(used);
  182|     86|                            read += used;
  183|     86|                        }
  184|       |                    }
  185|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
  186|      0|                    Err(e) => {
  187|      0|                        *position += read;
  188|      0|                        return Err(Error::Io(e.into()));
  189|       |                    }
  190|       |                };
  191|       |            }
  192|       |
  193|     90|            if read == 0 {
  194|      0|                Ok(None)
  195|       |            } else {
  196|     90|                Ok(Some(&buf[start..]))
  197|       |            }
  198|     90|        }
_RNvXNtNtCsa5xj4vgqoz3_9quick_xml6reader15buffered_readerINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEINtB4_9XmlSourceQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEE15remove_utf8_bomCs6Agad4Vg9Hx_13oxigraph_fuzz:
   18|    770|        $($async)? fn remove_utf8_bom(&mut self) -> Result<()> {
   19|       |            use crate::encoding::UTF8_BOM;
   20|       |
   21|       |            loop {
   22|    770|                break match self $(.$reader)? .fill_buf() $(.$await)? {
   23|    770|                    Ok(n) => {
   24|    770|                        if n.starts_with(UTF8_BOM) {
   25|      1|                            self $(.$reader)? .consume(UTF8_BOM.len());
   26|    769|                        }
   27|    770|                        Ok(())
   28|       |                    },
   29|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
   30|      0|                    Err(e) => Err(Error::Io(e.into())),
   31|       |                };
   32|       |            }
   33|    770|        }
_RNvXNtNtCsa5xj4vgqoz3_9quick_xml6reader15buffered_readerINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEINtB4_9XmlSourceQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEE15skip_whitespaceCs6Agad4Vg9Hx_13oxigraph_fuzz:
  200|  2.34k|        $($async)? fn skip_whitespace(&mut self, position: &mut usize) -> Result<()> {
  201|       |            loop {
  202|  2.45k|                break match self $(.$reader)? .fill_buf() $(.$await)? {
  203|  2.45k|                    Ok(n) => {
  204|  2.45k|                        let count = n.iter().position(|b| !is_whitespace(*b)).unwrap_or(n.len());
  205|  2.45k|                        if count > 0 {
  206|    115|                            self $(.$reader)? .consume(count);
  207|    115|                            *position += count;
  208|    115|                            continue;
  209|       |                        } else {
  210|  2.34k|                            Ok(())
  211|       |                        }
  212|       |                    }
  213|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
  214|      0|                    Err(e) => Err(Error::Io(e.into())),
  215|       |                };
  216|       |            }
  217|  2.34k|        }
_RNvXNtNtCsa5xj4vgqoz3_9quick_xml6reader15buffered_readerINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEINtB4_9XmlSourceQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEE16read_bytes_untilCs6Agad4Vg9Hx_13oxigraph_fuzz:
   52|  1.04k|        $($async)? fn read_bytes_until $(<$lf>)? (
   53|  1.04k|            &mut self,
   54|  1.04k|            byte: u8,
   55|  1.04k|            buf: &'b mut Vec<u8>,
   56|  1.04k|            position: &mut usize,
   57|  1.04k|        ) -> Result<Option<&'b [u8]>> {
   58|  1.04k|            // search byte must be within the ascii range
   59|  1.04k|            debug_assert!(byte.is_ascii());
   60|       |
   61|  1.04k|            let mut read = 0;
   62|  1.04k|            let mut done = false;
   63|  1.04k|            let start = buf.len();
   64|  2.02k|            while !done {
   65|    977|                let used = {
   66|  1.38k|                    let available = match self $(.$reader)? .fill_buf() $(.$await)? {
   67|  1.38k|                        Ok(n) if n.is_empty() => break,
   68|    977|                        Ok(n) => n,
   69|      0|                        Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
   70|      0|                        Err(e) => {
   71|      0|                            *position += read;
   72|      0|                            return Err(Error::Io(e.into()));
   73|       |                        }
   74|       |                    };
   75|       |
   76|    977|                    match memchr::memchr(byte, available) {
   77|    634|                        Some(i) => {
   78|    634|                            buf.extend_from_slice(&available[..i]);
   79|    634|                            done = true;
   80|    634|                            i + 1
   81|       |                        }
   82|       |                        None => {
   83|    343|                            buf.extend_from_slice(available);
   84|    343|                            available.len()
   85|       |                        }
   86|       |                    }
   87|       |                };
   88|    977|                self $(.$reader)? .consume(used);
   89|    977|                read += used;
   90|       |            }
   91|  1.04k|            *position += read;
   92|  1.04k|
   93|  1.04k|            if read == 0 {
   94|     67|                Ok(None)
   95|       |            } else {
   96|    977|                Ok(Some(&buf[start..]))
   97|       |            }
   98|  1.04k|        }
_RNvXNtNtCsa5xj4vgqoz3_9quick_xml6reader15buffered_readerINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEINtB4_9XmlSourceQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEE17read_bang_elementCs6Agad4Vg9Hx_13oxigraph_fuzz:
  100|  1.20k|        $($async)? fn read_bang_element $(<$lf>)? (
  101|  1.20k|            &mut self,
  102|  1.20k|            buf: &'b mut Vec<u8>,
  103|  1.20k|            position: &mut usize,
  104|  1.20k|        ) -> Result<Option<(BangType, &'b [u8])>> {
  105|  1.20k|            // Peeked one bang ('!') before being called, so it's guaranteed to
  106|  1.20k|            // start with it.
  107|  1.20k|            let start = buf.len();
  108|  1.20k|            let mut read = 1;
  109|  1.20k|            buf.push(b'!');
  110|  1.20k|            self $(.$reader)? .consume(1);
  111|       |
  112|  1.20k|            let bang_type = BangType::new(self.peek_one() $(.$await)? ?)?;
  113|       |
  114|       |            loop {
  115|  1.32k|                match self $(.$reader)? .fill_buf() $(.$await)? {
  116|       |                    // Note: Do not update position, so the error points to
  117|       |                    // somewhere sane rather than at the EOF
  118|  1.32k|                    Ok(n) if n.is_empty() => return Err(bang_type.to_err()),
  119|  1.19k|                    Ok(available) => {
  120|       |                        // We only parse from start because we don't want to consider
  121|       |                        // whatever is in the buffer before the bang element
  122|  1.19k|                        if let Some((consumed, used)) = bang_type.parse(&buf[start..], available) {
  123|  1.07k|                            buf.extend_from_slice(consumed);
  124|  1.07k|
  125|  1.07k|                            self $(.$reader)? .consume(used);
  126|  1.07k|                            read += used;
  127|  1.07k|
  128|  1.07k|                            *position += read;
  129|  1.07k|                            break;
  130|    124|                        } else {
  131|    124|                            buf.extend_from_slice(available);
  132|    124|
  133|    124|                            let used = available.len();
  134|    124|                            self $(.$reader)? .consume(used);
  135|    124|                            read += used;
  136|    124|                        }
  137|       |                    }
  138|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
  139|      0|                    Err(e) => {
  140|      0|                        *position += read;
  141|      0|                        return Err(Error::Io(e.into()));
  142|       |                    }
  143|       |                }
  144|       |            }
  145|       |
  146|  1.07k|            if read == 0 {
  147|      0|                Ok(None)
  148|       |            } else {
  149|  1.07k|                Ok(Some((bang_type, &buf[start..])))
  150|       |            }
  151|  1.20k|        }
_RNvXNtNtCsa5xj4vgqoz3_9quick_xml6reader15buffered_readerINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEINtB4_9XmlSourceQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEE8peek_oneCs6Agad4Vg9Hx_13oxigraph_fuzz:
  233|  5.52k|        $($async)? fn peek_one(&mut self) -> Result<Option<u8>> {
  234|       |            loop {
  235|  5.52k|                break match self $(.$reader)? .fill_buf() $(.$await)? {
  236|  5.52k|                    Ok(n) if n.is_empty() => Ok(None),
  237|  5.45k|                    Ok(n) => Ok(Some(n[0])),
  238|      0|                    Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
  239|      0|                    Err(e) => Err(Error::Io(e.into())),
  240|       |                };
  241|       |            }
  242|  5.52k|        }
_RNvXNtNtCsa5xj4vgqoz3_9quick_xml6reader15buffered_readerINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEINtB4_9XmlSourceQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEE8skip_oneCs6Agad4Vg9Hx_13oxigraph_fuzz:
  219|  2.34k|        $($async)? fn skip_one(&mut self, byte: u8, position: &mut usize) -> Result<bool> {
  220|  2.34k|            // search byte must be within the ascii range
  221|  2.34k|            debug_assert!(byte.is_ascii());
  222|       |
  223|  2.34k|            match self.peek_one() $(.$await)? ? {
  224|  2.27k|                Some(b) if b == byte => {
  225|  1.98k|                    *position += 1;
  226|  1.98k|                    self $(.$reader)? .consume(1);
  227|  1.98k|                    Ok(true)
  228|       |                }
  229|    358|                _ => Ok(false),
  230|       |            }
  231|  2.34k|        }

_RINvMs0_NtCsa5xj4vgqoz3_9quick_xml6readerINtB6_6ReaderINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEE15read_event_implQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEECs6Agad4Vg9Hx_13oxigraph_fuzz:
  645|  2.34k|    fn read_event_impl<'i, B>(&mut self, mut buf: B) -> Result<Event<'i>>
  646|  2.34k|    where
  647|  2.34k|        R: XmlSource<'i, B>,
  648|  2.34k|    {
  649|  4.32k|        read_event_impl!(self, buf, self.reader, read_until_open, read_until_close)
  650|  2.34k|    }
_RINvMs0_NtCsa5xj4vgqoz3_9quick_xml6readerINtB6_6ReaderINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEE15read_until_openQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEECs6Agad4Vg9Hx_13oxigraph_fuzz:
  656|  2.34k|    fn read_until_open<'i, B>(&mut self, buf: B) -> Result<std::result::Result<Event<'i>, B>>
  657|  2.34k|    where
  658|  2.34k|        R: XmlSource<'i, B>,
  659|  2.34k|    {
  660|  2.34k|        read_until_open!(self, buf, self.reader, read_event_impl)
  661|  2.34k|    }
_RINvMs0_NtCsa5xj4vgqoz3_9quick_xml6readerINtB6_6ReaderINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEE16read_until_closeQINtNtCsj6RlT1QFsHj_5alloc3vec3VechEECs6Agad4Vg9Hx_13oxigraph_fuzz:
  665|  1.98k|    fn read_until_close<'i, B>(&mut self, buf: B) -> Result<Event<'i>>
  666|  1.98k|    where
  667|  1.98k|        R: XmlSource<'i, B>,
  668|  1.98k|    {
  669|  1.98k|        read_until_close!(self, buf, self.reader)
  670|  1.98k|    }
_RNvMNtCsa5xj4vgqoz3_9quick_xml6readerINtB2_6ReaderINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEE11from_readerCs6Agad4Vg9Hx_13oxigraph_fuzz:
  533|    770|    pub fn from_reader(reader: R) -> Self {
  534|    770|        Self {
  535|    770|            reader,
  536|    770|            state: ReaderState::default(),
  537|    770|        }
  538|    770|    }
_RNvMNtCsa5xj4vgqoz3_9quick_xml6readerINtB2_6ReaderINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEE21expand_empty_elementsCs6Agad4Vg9Hx_13oxigraph_fuzz:
   33|    770|        pub fn expand_empty_elements(&mut self, val: bool) -> &mut Self {
   34|    770|            self $(.$holder)? .state.expand_empty_elements = val;
   35|    770|            self
   36|    770|        }
_RNvMNtCsa5xj4vgqoz3_9quick_xml6readerINtB2_6ReaderINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEE9trim_textCs6Agad4Vg9Hx_13oxigraph_fuzz:
   60|    770|        pub fn trim_text(&mut self, val: bool) -> &mut Self {
   61|    770|            self $(.$holder)? .state.trim_text_start = val;
   62|    770|            self $(.$holder)? .state.trim_text_end = val;
   63|    770|            self
   64|    770|        }
_RNvMs_NtCsa5xj4vgqoz3_9quick_xml6readerINtB4_6ReaderINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShEE7decoderCs6Agad4Vg9Hx_13oxigraph_fuzz:
  635|     90|    pub fn decoder(&self) -> Decoder {
  636|     90|        self.state.decoder()
  637|     90|    }
_RNvMs1_NtCsa5xj4vgqoz3_9quick_xml6readerNtB5_8BangType3new:
  807|  1.20k|    fn new(byte: Option<u8>) -> Result<Self> {
  808|  1.20k|        Ok(match byte {
  809|    245|            Some(b'[') => Self::CData,
  810|    522|            Some(b'-') => Self::Comment,
  811|    432|            Some(b'D') | Some(b'd') => Self::DocType,
  812|      2|            Some(b) => return Err(Error::UnexpectedBang(b)),
  813|      4|            None => return Err(Error::UnexpectedEof("Bang".to_string())),
  814|       |        })
  815|  1.20k|    }
_RNvMs1_NtCsa5xj4vgqoz3_9quick_xml6readerNtB5_8BangType5parse:
  824|  1.19k|    fn parse<'b>(&self, buf: &[u8], chunk: &'b [u8]) -> Option<(&'b [u8], usize)> {
  825|  6.12k|        for i in memchr::memchr_iter(b'>', chunk) {
  826|    944|            match self {
  827|    944|                // Need to read at least 6 symbols (`!---->`) for properly finished comment
  828|    944|                // <!----> - XML comment
  829|    944|                //  012345 - i
  830|    944|                Self::Comment if buf.len() + i > 4 => {
  831|    727|                    if chunk[..i].ends_with(b"--") {
  832|       |                        // We cannot strip last `--` from the buffer because we need it in case of
  833|       |                        // check_comments enabled option. XML standard requires that comment
  834|       |                        // will not end with `--->` sequence because this is a special case of
  835|       |                        // `--` in the comment (https://www.w3.org/TR/xml11/#sec-comments)
  836|    502|                        return Some((&chunk[..i], i + 1)); // +1 for `>`
  837|    225|                    }
  838|    225|                    // End sequence `-|->` was splitted at |
  839|    225|                    //        buf --/   \-- chunk
  840|    225|                    if i == 1 && buf.ends_with(b"-") && chunk[0] == b'-' {
  841|      0|                        return Some((&chunk[..i], i + 1)); // +1 for `>`
  842|    225|                    }
  843|    225|                    // End sequence `--|>` was splitted at |
  844|    225|                    //         buf --/   \-- chunk
  845|    225|                    if i == 0 && buf.ends_with(b"--") {
  846|      0|                        return Some((&[], i + 1)); // +1 for `>`
  847|    225|                    }
  848|       |                }
  849|    217|                Self::Comment => {}
  850|       |                Self::CData => {
  851|  1.22k|                    if chunk[..i].ends_with(b"]]") {
  852|    201|                        return Some((&chunk[..i], i + 1)); // +1 for `>`
  853|  1.02k|                    }
  854|  1.02k|                    // End sequence `]|]>` was splitted at |
  855|  1.02k|                    //        buf --/   \-- chunk
  856|  1.02k|                    if i == 1 && buf.ends_with(b"]") && chunk[0] == b']' {
  857|      0|                        return Some((&chunk[..i], i + 1)); // +1 for `>`
  858|  1.02k|                    }
  859|  1.02k|                    // End sequence `]]|>` was splitted at |
  860|  1.02k|                    //         buf --/   \-- chunk
  861|  1.02k|                    if i == 0 && buf.ends_with(b"]]") {
  862|      0|                        return Some((&[], i + 1)); // +1 for `>`
  863|  1.02k|                    }
  864|       |                }
  865|       |                Self::DocType => {
  866|  3.95k|                    let content = &chunk[..i];
  867|  3.95k|                    let balance = memchr::memchr2_iter(b'<', b'>', content)
  868|  3.95k|                        .map(|p| if content[p] == b'<' { 1i32 } else { -1 })
  869|  3.95k|                        .sum::<i32>();
  870|  3.95k|                    if balance == 0 {
  871|    372|                        return Some((content, i + 1)); // +1 for `>`
  872|  3.57k|                    }
  873|       |                }
  874|       |            }
  875|       |        }
  876|    124|        None
  877|  1.19k|    }
_RNvMs2_NtCsa5xj4vgqoz3_9quick_xml6readerNtB5_16ReadElementState6change:
  904|     90|    fn change<'b>(&mut self, chunk: &'b [u8]) -> Option<(&'b [u8], usize)> {
  905|  1.77k|        for i in memchr::memchr3_iter(b'>', b'\'', b'"', chunk) {
  906|  1.77k|            *self = match (*self, chunk[i]) {
  907|       |                // only allowed to match `>` while we are in state `Elem`
  908|      4|                (Self::Elem, b'>') => return Some((&chunk[..i], i + 1)),
  909|    407|                (Self::Elem, b'\'') => Self::SingleQ,
  910|    253|                (Self::Elem, b'\"') => Self::DoubleQ,
  911|       |
  912|       |                // the only end_byte that gets us out if the same character
  913|    624|                (Self::SingleQ, b'\'') | (Self::DoubleQ, b'"') => Self::Elem,
  914|       |
  915|       |                // all other bytes: no state change
  916|    482|                _ => *self,
  917|       |            };
  918|       |        }
  919|     86|        None
  920|     90|    }
_RNvMs1_NtCsa5xj4vgqoz3_9quick_xml6readerNtB5_8BangType6to_errCs6Agad4Vg9Hx_13oxigraph_fuzz:
  879|    124|    fn to_err(&self) -> Error {
  880|    124|        let bang_str = match self {
  881|     44|            Self::CData => "CData",
  882|     20|            Self::Comment => "Comment",
  883|     60|            Self::DocType => "DOCTYPE",
  884|       |        };
  885|    124|        Error::UnexpectedEof(bang_str.to_string())
  886|    124|    }
_RNvNtCsa5xj4vgqoz3_9quick_xml6reader13is_whitespaceCs6Agad4Vg9Hx_13oxigraph_fuzz:
  925|  3.28k|pub(crate) const fn is_whitespace(b: u8) -> bool {
  926|  3.28k|    matches!(b, b' ' | b'\r' | b'\n' | b'\t')
  927|  3.28k|}
_RNCNvMs1_NtCsa5xj4vgqoz3_9quick_xml6readerNtB7_8BangType5parse0B9_:
  868|   502k|                        .map(|p| if content[p] == b'<' { 1i32 } else { -1 })
_RNvMs1_NtCsa5xj4vgqoz3_9quick_xml6readerNtB5_8BangType6to_errB7_:
  879|     99|    fn to_err(&self) -> Error {
  880|     99|        let bang_str = match self {
  881|      7|            Self::CData => "CData",
  882|      2|            Self::Comment => "Comment",
  883|     90|            Self::DocType => "DOCTYPE",
  884|       |        };
  885|     99|        Error::UnexpectedEof(bang_str.to_string())
  886|     99|    }
_RNvNtCsa5xj4vgqoz3_9quick_xml6reader13is_whitespaceB3_:
  925|  7.74k|pub(crate) const fn is_whitespace(b: u8) -> bool {
  926|  7.74k|    matches!(b, b' ' | b'\r' | b'\n' | b'\t')
  927|  7.74k|}

_RNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB2_11ReaderState9emit_text:
   68|    291|    pub fn emit_text<'b>(&mut self, bytes: &'b [u8]) -> Result<Event<'b>> {
   69|    291|        let mut content = bytes;
   70|    291|
   71|    291|        if self.trim_text_end {
   72|    291|            // Skip the ending '<'
   73|    291|            let len = bytes
   74|    291|                .iter()
   75|    291|                .rposition(|&b| !is_whitespace(b))
   76|    291|                .map_or_else(|| bytes.len(), |p| p + 1);
   77|    291|            content = &bytes[..len];
   78|    291|        }
   79|       |
   80|    291|        Ok(Event::Text(BytesText::wrap(content, self.decoder())))
   81|    291|    }
_RNCNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB4_11ReaderState9emit_text0B8_:
   75|  1.08k|                .rposition(|&b| !is_whitespace(b))
_RNCNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB4_11ReaderState9emit_texts0_0B8_:
   76|    291|                .map_or_else(|| bytes.len(), |p| p + 1);
_RNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB2_11ReaderState9emit_bang:
   85|  1.07k|    pub fn emit_bang<'b>(&mut self, bang_type: BangType, buf: &'b [u8]) -> Result<Event<'b>> {
   86|  1.07k|        let uncased_starts_with = |string: &[u8], prefix: &[u8]| {
   87|       |            string.len() >= prefix.len() && string[..prefix.len()].eq_ignore_ascii_case(prefix)
   88|       |        };
   89|       |
   90|  1.07k|        let len = buf.len();
   91|    573|        match bang_type {
   92|    502|            BangType::Comment if buf.starts_with(b"!--") => {
   93|    500|                debug_assert!(buf.ends_with(b"--"));
   94|    500|                if self.check_comments {
   95|       |                    // search if '--' not in comments
   96|      0|                    if let Some(p) = memchr::memchr_iter(b'-', &buf[3..len - 2])
   97|      0|                        .position(|p| buf[3 + p + 1] == b'-')
   98|       |                    {
   99|      0|                        self.offset += len - p;
  100|      0|                        return Err(Error::UnexpectedToken("--".to_string()));
  101|      0|                    }
  102|    500|                }
  103|    500|                Ok(Event::Comment(BytesText::wrap(
  104|    500|                    &buf[3..len - 2],
  105|    500|                    self.decoder(),
  106|    500|                )))
  107|       |            }
  108|    201|            BangType::CData if uncased_starts_with(buf, b"![CDATA[") => {
  109|    194|                debug_assert!(buf.ends_with(b"]]"));
  110|    194|                Ok(Event::CData(BytesCData::wrap(
  111|    194|                    &buf[8..len - 2],
  112|    194|                    self.decoder(),
  113|    194|                )))
  114|       |            }
  115|    372|            BangType::DocType if uncased_starts_with(buf, b"!DOCTYPE") => {
  116|    282|                let start = buf[8..]
  117|    282|                    .iter()
  118|    282|                    .position(|b| !is_whitespace(*b))
  119|    282|                    .unwrap_or(len - 8);
  120|    282|                if start + 8 >= len {
  121|     33|                    return Err(Error::EmptyDocType);
  122|    249|                }
  123|    249|                Ok(Event::DocType(BytesText::wrap(
  124|    249|                    &buf[8 + start..],
  125|    249|                    self.decoder(),
  126|    249|                )))
  127|       |            }
  128|     99|            _ => Err(bang_type.to_err()),
  129|       |        }
  130|  1.07k|    }
_RNCNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB4_11ReaderState9emit_bang0B8_:
   86|    573|        let uncased_starts_with = |string: &[u8], prefix: &[u8]| {
   87|    573|            string.len() >= prefix.len() && string[..prefix.len()].eq_ignore_ascii_case(prefix)
   88|    573|        };
_RNCNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB4_11ReaderState9emit_bangs0_0B8_:
  118|  1.64k|                    .position(|b| !is_whitespace(*b))
_RNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB2_11ReaderState8emit_end:
  134|     39|    pub fn emit_end<'b>(&mut self, buf: &'b [u8]) -> Result<Event<'b>> {
  135|     39|        // Strip the `/` character. `content` contains data between `</` and `>`
  136|     39|        let content = &buf[1..];
  137|       |        // XML standard permits whitespaces after the markup name in closing tags.
  138|       |        // Let's strip them from the buffer before comparing tag names.
  139|     39|        let name = if self.trim_markup_names_in_closing_tags {
  140|     39|            if let Some(pos_end_name) = content.iter().rposition(|&b| !is_whitespace(b)) {
  141|      8|                &content[..pos_end_name + 1]
  142|       |            } else {
  143|     31|                content
  144|       |            }
  145|       |        } else {
  146|      0|            content
  147|       |        };
  148|       |
  149|     39|        let decoder = self.decoder();
  150|     39|        let mismatch_err = |expected: String, found: &[u8], offset: &mut usize| {
  151|       |            *offset -= buf.len();
  152|       |            Err(Error::EndEventMismatch {
  153|       |                expected,
  154|       |                found: decoder.decode(found).unwrap_or_default().into_owned(),
  155|       |            })
  156|       |        };
  157|       |
  158|       |        // Get the index in self.opened_buffer of the name of the last opened tag
  159|     39|        match self.opened_starts.pop() {
  160|      0|            Some(start) => {
  161|      0|                if self.check_end_names {
  162|      0|                    let expected = &self.opened_buffer[start..];
  163|      0|                    if name != expected {
  164|      0|                        let expected = decoder.decode(expected).unwrap_or_default().into_owned();
  165|      0|                        // #513: In order to allow error recovery we should drop content of the buffer
  166|      0|                        self.opened_buffer.truncate(start);
  167|      0|
  168|      0|                        return mismatch_err(expected, name, &mut self.offset);
  169|      0|                    }
  170|      0|                }
  171|       |
  172|      0|                self.opened_buffer.truncate(start);
  173|       |            }
  174|       |            None => {
  175|     39|                if self.check_end_names {
  176|     39|                    return mismatch_err("".to_string(), &buf[1..], &mut self.offset);
  177|      0|                }
  178|       |            }
  179|       |        }
  180|       |
  181|      0|        Ok(Event::End(BytesEnd::wrap(name.into())))
  182|     39|    }
_RNCNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB4_11ReaderState8emit_end0B8_:
  140|    851|            if let Some(pos_end_name) = content.iter().rposition(|&b| !is_whitespace(b)) {
_RNCNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB4_11ReaderState8emit_ends_0B8_:
  150|     39|        let mismatch_err = |expected: String, found: &[u8], offset: &mut usize| {
  151|     39|            *offset -= buf.len();
  152|     39|            Err(Error::EndEventMismatch {
  153|     39|                expected,
  154|     39|                found: decoder.decode(found).unwrap_or_default().into_owned(),
  155|     39|            })
  156|     39|        };
_RNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB2_11ReaderState18emit_question_mark:
  186|    647|    pub fn emit_question_mark<'b>(&mut self, buf: &'b [u8]) -> Result<Event<'b>> {
  187|    647|        let len = buf.len();
  188|    647|        if len > 2 && buf[len - 1] == b'?' {
  189|    628|            if len > 5 && &buf[1..4] == b"xml" && is_whitespace(buf[4]) {
  190|      0|                let event = BytesDecl::from_start(BytesStart::wrap(&buf[1..len - 1], 3));
  191|      0|
  192|      0|                // Try getting encoding from the declaration event
  193|      0|                #[cfg(feature = "encoding")]
  194|      0|                if self.encoding.can_be_refined() {
  195|      0|                    if let Some(encoding) = event.encoder() {
  196|      0|                        self.encoding = EncodingRef::XmlDetected(encoding);
  197|      0|                    }
  198|      0|                }
  199|      0|
  200|      0|                Ok(Event::Decl(event))
  201|       |            } else {
  202|    628|                Ok(Event::PI(BytesText::wrap(&buf[1..len - 1], self.decoder())))
  203|       |            }
  204|       |        } else {
  205|     19|            self.offset -= len;
  206|     19|            Err(Error::UnexpectedEof("XmlDecl".to_string()))
  207|       |        }
  208|    647|    }
_RNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB2_11ReaderState10emit_start:
  214|     90|    pub fn emit_start<'b>(&mut self, content: &'b [u8]) -> Result<Event<'b>> {
  215|     90|        let len = content.len();
  216|     90|        let name_end = content
  217|     90|            .iter()
  218|     90|            .position(|&b| is_whitespace(b))
  219|     90|            .unwrap_or(len);
  220|     90|        if let Some(&b'/') = content.last() {
  221|       |            // This is self-closed tag `<something/>`
  222|      2|            let name_len = if name_end < len { name_end } else { len - 1 };
  223|      2|            let event = BytesStart::wrap(&content[..len - 1], name_len);
  224|      2|
  225|      2|            if self.expand_empty_elements {
  226|      2|                self.state = ParseState::Empty;
  227|      2|                self.opened_starts.push(self.opened_buffer.len());
  228|      2|                self.opened_buffer.extend(&content[..name_len]);
  229|      2|                Ok(Event::Start(event))
  230|       |            } else {
  231|      0|                Ok(Event::Empty(event))
  232|       |            }
  233|       |        } else {
  234|       |            // #514: Always store names event when .check_end_names == false,
  235|       |            // because checks can be temporary disabled and when they would be
  236|       |            // enabled, we should have that information
  237|     88|            self.opened_starts.push(self.opened_buffer.len());
  238|     88|            self.opened_buffer.extend(&content[..name_end]);
  239|     88|            Ok(Event::Start(BytesStart::wrap(content, name_end)))
  240|       |        }
  241|     90|    }
_RNCNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB4_11ReaderState10emit_start0B8_:
  218|  4.17k|            .position(|&b| is_whitespace(b))
_RNvMNtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB2_11ReaderState7decoder:
  261|  1.99k|    pub fn decoder(&self) -> Decoder {
  262|  1.99k|        Decoder {
  263|  1.99k|            #[cfg(feature = "encoding")]
  264|  1.99k|            encoding: self.encoding.encoding(),
  265|  1.99k|        }
  266|  1.99k|    }
_RNvXs_NtNtCsa5xj4vgqoz3_9quick_xml6reader5stateNtB4_11ReaderStateNtNtCsfWS17p17snN_4core7default7Default7default:
  270|    770|    fn default() -> Self {
  271|    770|        Self {
  272|    770|            offset: 0,
  273|    770|            state: ParseState::Init,
  274|    770|            expand_empty_elements: false,
  275|    770|            trim_text_start: false,
  276|    770|            trim_text_end: false,
  277|    770|            trim_markup_names_in_closing_tags: true,
  278|    770|            check_end_names: true,
  279|    770|            check_comments: false,
  280|    770|            opened_buffer: Vec::new(),
  281|    770|            opened_starts: Vec::new(),
  282|    770|
  283|    770|            #[cfg(feature = "encoding")]
  284|    770|            encoding: EncodingRef::Implicit(UTF_8),
  285|    770|        }
  286|    770|    }

_RNvNtCs6Agad4Vg9Hx_13oxigraph_fuzz13result_format18fuzz_result_format:
    6|    770|pub fn fuzz_result_format(format: QueryResultsFormat, data: &[u8]) {
    7|    770|    let parser = QueryResultsParser::from_format(format);
    8|    770|    let serializer = QueryResultsSerializer::from_format(format);
    9|       |
   10|    770|    let Ok(reader) = parser.parse_read(data) else {
   11|    770|        return;
   12|       |    };
   13|      0|    match reader {
   14|      0|        FromReadQueryResultsReader::Solutions(solutions) => {
   15|      0|            let Ok(solutions) = solutions.collect::<Result<Vec<_>, _>>() else {
   16|      0|                return;
   17|       |            };
   18|       |
   19|       |            // We try to write again
   20|      0|            let mut writer = serializer
   21|      0|                .serialize_solutions_to_write(
   22|      0|                    Vec::new(),
   23|      0|                    solutions
   24|      0|                        .get(0)
   25|      0|                        .map_or_else(Vec::new, |s| s.variables().to_vec()),
   26|      0|                )
   27|      0|                .unwrap();
   28|      0|            for solution in &solutions {
   29|      0|                writer.write(solution).unwrap();
   30|      0|            }
   31|      0|            let serialized = String::from_utf8(writer.finish().unwrap()).unwrap();
   32|       |
   33|       |            // And to parse again
   34|      0|            if let FromReadQueryResultsReader::Solutions(roundtrip_solutions) = parser
   35|      0|                .parse_read(serialized.as_bytes())
   36|      0|                .with_context(|| format!("Parsing {:?}", &serialized))
   37|      0|                .unwrap()
   38|       |            {
   39|      0|                assert_eq!(
   40|      0|                    roundtrip_solutions
   41|      0|                        .collect::<Result<Vec<_>, _>>()
   42|      0|                        .with_context(|| format!("Parsing {:?}", &serialized))
   43|      0|                        .unwrap(),
   44|      0|                    solutions
   45|      0|                )
   46|      0|            }
   47|       |        }
   48|      0|        FromReadQueryResultsReader::Boolean(value) => {
   49|      0|            // We try to write again
   50|      0|            let mut serialized = Vec::new();
   51|      0|            serializer
   52|      0|                .serialize_boolean_to_write(&mut serialized, value)
   53|      0|                .unwrap();
   54|       |
   55|       |            // And to parse again
   56|      0|            if let FromReadQueryResultsReader::Boolean(roundtrip_value) =
   57|      0|                parser.parse_read(serialized.as_slice()).unwrap()
   58|       |            {
   59|      0|                assert_eq!(roundtrip_value, value)
   60|      0|            }
   61|       |        }
   62|       |    }
   63|    770|}

_RINvMs5_NtCsbc0ed0dKf9v_10sparesults5errorNtB6_11SyntaxError3msgNtNtCsj6RlT1QFsHj_5alloc6string6StringECs6Agad4Vg9Hx_13oxigraph_fuzz:
  108|    245|    pub(crate) fn msg(msg: impl Into<String>) -> Self {
  109|    245|        Self {
  110|    245|            inner: SyntaxErrorKind::Msg {
  111|    245|                msg: msg.into(),
  112|    245|                location: None,
  113|    245|            },
  114|    245|        }
  115|    245|    }
_RINvMs5_NtCsbc0ed0dKf9v_10sparesults5errorNtB6_11SyntaxError3msgReECs6Agad4Vg9Hx_13oxigraph_fuzz:
  108|     69|    pub(crate) fn msg(msg: impl Into<String>) -> Self {
  109|     69|        Self {
  110|     69|            inner: SyntaxErrorKind::Msg {
  111|     69|                msg: msg.into(),
  112|     69|                location: None,
  113|     69|            },
  114|     69|        }
  115|     69|    }
_RNvXs4_NtCsbc0ed0dKf9v_10sparesults5errorNtB5_10ParseErrorINtNtCsfWS17p17snN_4core7convert4FromNtNtCsa5xj4vgqoz3_9quick_xml6errors5ErrorE4fromCs6Agad4Vg9Hx_13oxigraph_fuzz:
   71|    456|    fn from(error: quick_xml::Error) -> Self {
   72|    456|        match error {
   73|      0|            quick_xml::Error::Io(error) => Self::Io(match Arc::try_unwrap(error) {
   74|      0|                Ok(error) => error,
   75|      0|                Err(error) => io::Error::new(error.kind(), error),
   76|       |            }),
   77|    456|            _ => Self::Syntax(SyntaxError {
   78|    456|                inner: SyntaxErrorKind::Xml(error),
   79|    456|            }),
   80|       |        }
   81|    456|    }
_RNvXs1_NtCsbc0ed0dKf9v_10sparesults5errorNtB5_10ParseErrorINtNtCsfWS17p17snN_4core7convert4FromNtB5_11SyntaxErrorE4fromB7_:
   45|    314|    fn from(error: SyntaxError) -> Self {
   46|    314|        Self::Syntax(error)
   47|    314|    }

_RNvMNtCsbc0ed0dKf9v_10sparesults6parserNtB2_18QueryResultsParser11from_formatCs6Agad4Vg9Hx_13oxigraph_fuzz:
   44|    770|    pub fn from_format(format: QueryResultsFormat) -> Self {
   45|    770|        Self { format }
   46|    770|    }
_RINvMNtCsbc0ed0dKf9v_10sparesults6parserNtB3_18QueryResultsParser10parse_readRShECs6Agad4Vg9Hx_13oxigraph_fuzz:
   73|    770|    pub fn parse_read<R: Read>(
   74|    770|        &self,
   75|    770|        reader: R,
   76|    770|    ) -> Result<FromReadQueryResultsReader<R>, ParseError> {
   77|    770|        Ok(match self.format {
   78|    770|            QueryResultsFormat::Xml => match XmlQueryResultsReader::read(reader)? {
   79|      0|                XmlQueryResultsReader::Boolean(r) => FromReadQueryResultsReader::Boolean(r),
   80|       |                XmlQueryResultsReader::Solutions {
   81|      0|                    solutions,
   82|      0|                    variables,
   83|      0|                } => FromReadQueryResultsReader::Solutions(FromReadSolutionsReader {
   84|      0|                    variables: variables.into(),
   85|      0|                    solutions: SolutionsReaderKind::Xml(solutions),
   86|      0|                }),
   87|       |            },
   88|      0|            QueryResultsFormat::Json => match JsonQueryResultsReader::read(reader)? {
   89|      0|                JsonQueryResultsReader::Boolean(r) => FromReadQueryResultsReader::Boolean(r),
   90|       |                JsonQueryResultsReader::Solutions {
   91|      0|                    solutions,
   92|      0|                    variables,
   93|      0|                } => FromReadQueryResultsReader::Solutions(FromReadSolutionsReader {
   94|      0|                    variables: variables.into(),
   95|      0|                    solutions: SolutionsReaderKind::Json(solutions),
   96|      0|                }),
   97|       |            },
   98|      0|            QueryResultsFormat::Csv => return Err(SyntaxError::msg("CSV SPARQL results syntax is lossy and can't be parsed to a proper RDF representation").into()),
   99|      0|            QueryResultsFormat::Tsv => match TsvQueryResultsReader::read(reader)? {
  100|      0|                TsvQueryResultsReader::Boolean(r) => FromReadQueryResultsReader::Boolean(r),
  101|       |                TsvQueryResultsReader::Solutions {
  102|      0|                    solutions,
  103|      0|                    variables,
  104|      0|                } => FromReadQueryResultsReader::Solutions(FromReadSolutionsReader {
  105|      0|                    variables: variables.into(),
  106|      0|                    solutions: SolutionsReaderKind::Tsv(solutions),
  107|      0|                }),
  108|       |            },
  109|       |        })
  110|    770|    }

_RNvMNtCsbc0ed0dKf9v_10sparesults10serializerNtB2_22QueryResultsSerializer11from_formatCs6Agad4Vg9Hx_13oxigraph_fuzz:
   55|    770|    pub fn from_format(format: QueryResultsFormat) -> Self {
   56|    770|        Self { format }
   57|    770|    }

_RINvNtCsbc0ed0dKf9v_10sparesults3xml6decodeINtNtNtNtCseHEU5y4mM7P_3std2io8buffered9bufreader9BufReaderRShENtNtCsa5xj4vgqoz3_9quick_xml4name5QNameECs6Agad4Vg9Hx_13oxigraph_fuzz:
  660|     90|fn decode<'a, T>(
  661|     90|    reader: &Reader<T>,
  662|     90|    data: &'a impl AsRef<[u8]>,
  663|     90|) -> Result<Cow<'a, str>, ParseError> {
  664|     90|    Ok(reader.decoder().decode(data.as_ref())?)
  665|     90|}
_RNvMs0_NtCsbc0ed0dKf9v_10sparesults3xmlINtB5_21XmlQueryResultsReaderRShE4readCs6Agad4Vg9Hx_13oxigraph_fuzz:
  231|    770|    pub fn read(source: R) -> Result<Self, ParseError> {
  232|    770|        enum State {
  233|    770|            Start,
  234|    770|            Sparql,
  235|    770|            Head,
  236|    770|            AfterHead,
  237|    770|            Boolean,
  238|    770|        }
  239|    770|
  240|    770|        let mut reader = Reader::from_reader(BufReader::new(source));
  241|    770|        reader.trim_text(true);
  242|    770|        reader.expand_empty_elements(true);
  243|    770|
  244|    770|        let mut buffer = Vec::default();
  245|    770|        let mut variables = Vec::default();
  246|    770|        let mut state = State::Start;
  247|       |
  248|       |        //Read header
  249|  2.34k|        loop {
  250|  2.34k|            buffer.clear();
  251|  2.34k|            let event = reader.read_event_into(&mut buffer)?;
  252|  2.02k|            match event {
  253|     90|                Event::Start(event) => match state {
  254|       |                    State::Start => {
  255|     90|                        if event.local_name().as_ref() == b"sparql" {
  256|      0|                            state = State::Sparql;
  257|      0|                        } else {
  258|     90|                            return Err(SyntaxError::msg(format!("Expecting <sparql> tag, found <{}>", decode(&reader, &event.name())?)).into());
  259|       |                        }
  260|       |                    }
  261|       |                    State::Sparql => {
  262|      0|                        if event.local_name().as_ref() == b"head" {
  263|      0|                            state = State::Head;
  264|      0|                        } else {
  265|      0|                            return Err(SyntaxError::msg(format!("Expecting <head> tag, found <{}>",decode(&reader, &event.name())?)).into());
  266|       |                        }
  267|       |                    }
  268|       |                    State::Head => {
  269|      0|                        if event.local_name().as_ref() == b"variable" {
  270|      0|                            let name = event.attributes()
  271|      0|                                .filter_map(Result::ok)
  272|      0|                                .find(|attr| attr.key.local_name().as_ref() == b"name")
  273|      0|                                .ok_or_else(|| SyntaxError::msg("No name attribute found for the <variable> tag"))?
  274|      0|                                .decode_and_unescape_value(&reader)?;
  275|      0|                            let variable = Variable::new(name).map_err(|e| SyntaxError::msg(format!("Invalid variable name: {e}")))?;
  276|      0|                            if variables.contains(&variable) {
  277|      0|                                return Err(SyntaxError::msg(format!(
  278|      0|                                    "The variable {variable} is declared twice"
  279|      0|                                ))
  280|      0|                                    .into());
  281|      0|                            }
  282|      0|                            variables.push(variable);
  283|      0|                        } else if event.local_name().as_ref() == b"link" {
  284|      0|                            // no op
  285|      0|                        } else {
  286|      0|                            return Err(SyntaxError::msg(format!("Expecting <variable> or <link> tag, found <{}>", decode(&reader, &event.name())?)).into());
  287|       |                        }
  288|       |                    }
  289|       |                    State::AfterHead => {
  290|      0|                        if event.local_name().as_ref() == b"boolean" {
  291|      0|                            state = State::Boolean
  292|      0|                        } else if event.local_name().as_ref() == b"results" {
  293|      0|                            let mut mapping = BTreeMap::default();
  294|      0|                            for (i, var) in variables.iter().enumerate() {
  295|      0|                                mapping.insert(var.clone().into_string(), i);
  296|      0|                            }
  297|      0|                            return Ok(Self::Solutions { variables,
  298|      0|                                solutions: XmlSolutionsReader {
  299|      0|                                    reader,
  300|      0|                                    buffer,
  301|      0|                                    mapping,
  302|      0|                                    stack: Vec::new(),
  303|      0|                                    subject_stack: Vec::new(),
  304|      0|                                    predicate_stack: Vec::new(),
  305|      0|                                    object_stack: Vec::new(),
  306|      0|                                }});
  307|      0|                        } else if event.local_name().as_ref() != b"link" && event.local_name().as_ref() != b"results" && event.local_name().as_ref() != b"boolean" {
  308|      0|                            return Err(SyntaxError::msg(format!("Expecting sparql tag, found <{}>", decode(&reader, &event.name())?)).into());
  309|      0|                        }
  310|       |                    }
  311|      0|                    State::Boolean => return Err(SyntaxError::msg(format!("Unexpected tag inside of <boolean> tag: <{}>", decode(&reader, &event.name())?)).into())
  312|       |                },
  313|    291|                Event::Text(event) => {
  314|    291|                    let value = event.unescape()?;
  315|    195|                    return match state {
  316|       |                        State::Boolean => {
  317|      0|                            return if value == "true" {
  318|      0|                                Ok(Self::Boolean(true))
  319|      0|                            } else if value == "false" {
  320|      0|                                Ok(Self::Boolean(false))
  321|       |                            } else {
  322|      0|                                Err(SyntaxError::msg(format!("Unexpected boolean value. Found '{value}'")).into())
  323|       |                            };
  324|       |                        }
  325|    195|                        _ => Err(SyntaxError::msg(format!("Unexpected textual value found: '{value}'")).into())
  326|       |                    };
  327|       |                },
  328|      0|                Event::End(event) => {
  329|      0|                    if let State::Head = state {
  330|      0|                        if event.local_name().as_ref() == b"head" {
  331|      0|                            state = State::AfterHead
  332|      0|                        }
  333|       |                    } else {
  334|      0|                        return Err(SyntaxError::msg("Unexpected early file end. All results file should have a <head> and a <result> or <boolean> tag").into());
  335|       |                    }
  336|       |                },
  337|     69|                Event::Eof => return Err(SyntaxError::msg("Unexpected early file end. All results file should have a <head> and a <result> or <boolean> tag").into()),
  338|  1.57k|                _ => (),
  339|       |            }
  340|       |        }
  341|    770|    }

